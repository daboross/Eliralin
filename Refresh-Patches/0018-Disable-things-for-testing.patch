From 2798b3730f4e8c3421449b51f3699bb3deff2cf4 Mon Sep 17 00:00:00 2001
From: Dabo Ross <daboross@daboross.net>
Date: Mon, 12 May 2014 15:37:15 -0700
Subject: [PATCH] Disable things for testing


diff --git a/disabled/attacks.py b/disabled/attacks.py
new file mode 100644
index 0000000..39a3bb7
--- /dev/null
+++ b/disabled/attacks.py
@@ -0,0 +1,90 @@
+import random
+import re
+
+from util import hook
+
+with open("data/larts.txt") as f:
+    larts = [line.strip() for line in f.readlines()
+             if not line.startswith("//")]
+
+with open("data/insults.txt") as f:
+    insults = [line.strip() for line in f.readlines()
+               if not line.startswith("//")]
+
+with open("data/flirts.txt") as f:
+    flirts = [line.strip() for line in f.readlines()
+              if not line.startswith("//")]
+
+
+def is_self(conn, target):
+    """
+    :type conn: core.irc.BotConnection
+    :type target: str
+    """
+    if re.search("(^..?.?.?self|{})".format(re.escape(conn.nick.lower())), target.lower()):
+        return True
+    else:
+        return False
+
+
+@hook.command(threaded=False)
+def lart(text, conn, nick, notice, action):
+    """lart <user> -- LARTs <user>.
+    :type text: str
+    :type conn: core.irc.BotConnection
+    :type nick: str
+    """
+    target = text.strip()
+
+    if " " in target:
+        notice("Invalid username!")
+        return
+
+    # if the user is trying to make the bot target itself, target them
+    if is_self(conn, target):
+        target = nick
+
+    phrase = random.choice(larts)
+
+    # act out the message
+    action(phrase.format(user=target))
+
+
+@hook.command(threaded=False)
+def insult(text, conn, nick, notice, message):
+    """insult <user> -- Makes the bot insult <user>.
+    :type text: str
+    :type conn: core.irc.BotConnection
+    :type nick: str
+    """
+    target = text.strip()
+
+    if " " in target:
+        notice("Invalid username!")
+        return
+
+    # if the user is trying to make the bot target itself, target them
+    if is_self(conn, target):
+        target = nick
+
+    message("{}, {}".format(target, random.choice(insults)))
+
+
+@hook.command(threaded=False)
+def flirt(text, conn, nick, notice, message):
+    """flirt <user> -- Makes the bot flirt with <user>.
+    :type text: str
+    :type conn: core.irc.BotConnection
+    :type nick: str
+    """
+    target = text.strip()
+
+    # if the user is trying to make the bot target itself, target them
+    if " " in target:
+        notice("Invalid username!")
+        return
+
+    if is_self(conn, target):
+        target = nick
+
+    message('{}, {}'.format(target, random.choice(flirts)))
diff --git a/disabled/brainfuck.py b/disabled/brainfuck.py
new file mode 100644
index 0000000..9f04bcc
--- /dev/null
+++ b/disabled/brainfuck.py
@@ -0,0 +1,89 @@
+"""brainfuck interpreter adapted from (public domain) code at
+http://brainfuck.sourceforge.net/brain.py"""
+
+import re
+import random
+
+from util import hook
+
+BUFFER_SIZE = 5000
+MAX_STEPS = 1000000
+
+
+@hook.command(["brainfuck", "bf"], threaded=False)
+def bf(text):
+    """bf <prog> -- Executes <prog> as Brainfuck code.
+    :type text: str
+    """
+
+    program = re.sub('[^][<>+-.,]', '', text)
+
+    # create a dict of brackets pairs, for speed later on
+    brackets = {}
+    open_brackets = []
+    for pos in range(len(program)):
+        if program[pos] == '[':
+            open_brackets.append(pos)
+        elif program[pos] == ']':
+            if len(open_brackets) > 0:
+                brackets[pos] = open_brackets[-1]
+                brackets[open_brackets[-1]] = pos
+                open_brackets.pop()
+            else:
+                return "Unbalanced brackets"
+    if len(open_brackets) != 0:
+        return "Unbalanced brackets"
+
+    # now we can start interpreting
+    ip = 0  # instruction pointer
+    mp = 0  # memory pointer
+    steps = 0
+    memory = [0] * BUFFER_SIZE  # initial memory area
+    rightmost = 0
+    output = ""  # we'll save the output here
+
+    # the main program loop:
+    while ip < len(program):
+        c = program[ip]
+        if c == '+':
+            memory[mp] += 1 % 256
+        elif c == '-':
+            memory[mp] -= 1 % 256
+        elif c == '>':
+            mp += 1
+            if mp > rightmost:
+                rightmost = mp
+                if mp >= len(memory):
+                    # no restriction on memory growth!
+                    memory.extend([0] * BUFFER_SIZE)
+        elif c == '<':
+            mp -= 1 % len(memory)
+        elif c == '.':
+            output += chr(memory[mp])
+            if len(output) > 500:
+                break
+        elif c == ',':
+            memory[mp] = random.randint(1, 255)
+        elif c == '[':
+            if memory[mp] == 0:
+                ip = brackets[ip]
+        elif c == ']':
+            if memory[mp] != 0:
+                ip = brackets[ip]
+
+        ip += 1
+        steps += 1
+        if steps > MAX_STEPS:
+            if not output:
+                output = "(no output)"
+            output += "(exceeded {} iterations)".format(MAX_STEPS)
+            break
+
+    stripped_output = re.sub(r'[\x00-\x1F]', '', output)
+
+    if not stripped_output:
+        if output:
+            return "No printable output"
+        return "No output"
+
+    return stripped_output[:430]
diff --git a/disabled/cake.py b/disabled/cake.py
new file mode 100644
index 0000000..c6f81c9
--- /dev/null
+++ b/disabled/cake.py
@@ -0,0 +1,24 @@
+# coding=utf-8
+import re
+import random
+
+from util import hook
+
+cakes = ['Chocolate', 'Ice Cream', 'Angel', 'Boston Cream', 'Birthday', 'Bundt', 'Carrot', 'Coffee', 'Devils', 'Fruit', 'Gingerbread', 'Pound', 'Red Velvet', 'Stack', 'Welsh', 'Yokan']
+
+
+@hook.command(threaded=False)
+def cake(inp, action=None):
+    """cake <user> - Gives <user> an awesome cake."""
+    inp = inp.strip()
+
+    if not re.match("^[A-Za-z0-9_|.-\]\[]*$", inp.lower()):
+        return "I can't give an awesome cake to that user!"
+
+    cake_type = random.choice(cakes)
+    size = random.choice(['small', 'little', 'mid-sized', 'medium-sized', 'large', 'gigantic'])
+    flavor = random.choice(['tasty', 'delectable', 'delicious', 'yummy', 'toothsome', 'scrumptious', 'luscious'])
+    method = random.choice(['makes', 'gives', 'gets', 'buys'])
+    side_dish = random.choice(['glass of chocolate milk', 'bowl of ice cream', 'jar of cookies', 'bowl of chocolate sauce'])
+
+    action("{} {} a {} {} {} cake and serves it with a small {}!".format(method, inp, flavor, size, cake_type, side_dish))
diff --git a/disabled/choose.py b/disabled/choose.py
new file mode 100644
index 0000000..2fba5cc
--- /dev/null
+++ b/disabled/choose.py
@@ -0,0 +1,16 @@
+import re
+import random
+
+from util import hook
+
+
+@hook.command(threaded=False)
+def choose(text, notice):
+    """choose <choice1>, [choice2], [choice3], etc. -- Randomly picks one of the given choices.
+    :type text: str
+    """
+    choices = re.findall(r'([^,\s]+)', text)
+    if len(choices) == 1:
+        notice(choose.__doc__)
+        return
+    return random.choice(choices)
diff --git a/disabled/coin.py b/disabled/coin.py
new file mode 100644
index 0000000..a55fc2e
--- /dev/null
+++ b/disabled/coin.py
@@ -0,0 +1,28 @@
+import random
+
+from util import hook
+
+
+@hook.command(threaded=False, autohelp=False)
+def coin(text, notice, action):
+    """coin [amount] -- Flips [amount] of coins.
+    :type text: str
+    """
+
+    if text:
+        try:
+            amount = int(text)
+        except (ValueError, TypeError):
+            notice("Invalid input '{}': not a number".format(text))
+            return
+    else:
+        amount = 1
+
+    if amount == 1:
+        action("flips a coin and gets {}.".format(random.choice(["heads", "tails"])))
+    elif amount == 0:
+        action("makes a coin flipping motion")
+    else:
+        heads = int(random.normalvariate(.5 * amount, (.75 * amount) ** .5))
+        tails = amount - heads
+        action("flips {} coins and gets {} heads and {} tails.".format(amount, heads, tails))
diff --git a/disabled/correction.py b/disabled/correction.py
new file mode 100644
index 0000000..c5c574c
--- /dev/null
+++ b/disabled/correction.py
@@ -0,0 +1,40 @@
+import re
+
+from util import hook
+
+correction_re = re.compile(r"^[sS]/([^/]*)/([^/]*)(/.*)?\s*$")
+
+
+@hook.regex(correction_re, threaded=False)
+def correction(match, conn, chan, message):
+    """
+    :type match: re.__Match
+    :type conn: core.irc.BotConnection
+    :type chan: str
+    """
+    print(match.groups())
+    to_find, replacement, find_nick = match.groups()
+    if find_nick:
+        find_nick = find_nick[1:].lower()  # Remove the '/'
+
+    find_re = re.compile("(?i){}".format(re.escape(to_find)))
+
+    for item in conn.history[chan].__reversed__():
+        nick, timestamp, msg = item
+        if correction_re.match(msg):
+            # don't correct corrections, it gets really confusing
+            continue
+        if find_nick:
+            if find_nick != nick.lower():
+                continue
+        if find_re.search(msg):
+            if "\x01ACTION" in msg:
+                msg = msg.replace("\x01ACTION ", "/me ").replace("\x01", "")
+            message("Correction, <{}> {}".format(nick, find_re.sub("\x02" + replacement + "\x02", msg)))
+            return
+        else:
+            continue
+    if find_nick:
+        return "Did not find {} in any recent messages from {}.".format(to_find, find_nick)
+    else:
+        return "Did not find {} in any recent messages.".format(to_find)
diff --git a/disabled/cryptocoins.py b/disabled/cryptocoins.py
new file mode 100644
index 0000000..6a449a6
--- /dev/null
+++ b/disabled/cryptocoins.py
@@ -0,0 +1,63 @@
+from util import http, hook
+
+## CONSTANTS
+
+exchanges = {
+    "blockchain": {
+        "api_url": "https://blockchain.info/ticker",
+        "func": lambda data: "Blockchain // Buy: \x0307${:,.2f}\x0f -"
+                             " Sell: \x0307${:,.2f}\x0f".format(data["USD"]["buy"], data["USD"]["sell"])
+    },
+    "coinbase": {
+        "api_url": "https://coinbase.com/api/v1/prices/spot_rate",
+        "func": lambda data: "Coinbase // Current: \x0307${:,.2f}\x0f".format(float(data['amount']))
+    },
+    "bitpay": {
+        "api_url": "https://bitpay.com/api/rates",
+        "func": lambda data: "Bitpay // Current: \x0307${:,.2f}\x0f".format(data[0]['rate'])
+    },
+    "bitstamp": {
+        "api_url": "https://www.bitstamp.net/api/ticker/",
+        "func": lambda data: "BitStamp // Current: \x0307${:,.2f}\x0f - High: \x0307${:,.2f}\x0f -"
+                             " Low: \x0307${:,.2f}\x0f - Volume: {:,.2f} BTC".format(float(data['last']),
+                                                                                     float(data['high']),
+                                                                                     float(data['low']),
+                                                                                     float(data['volume']))
+    }
+}
+
+
+## HOOK FUNCTIONS
+
+@hook.command(["btc", "bitcoin"], threaded=True, autohelp=False)
+def bitcoin(text, notice):
+    """bitcoin <exchange> -- Gets current exchange rate for bitcoins from several exchanges, default is Blockchain.
+    Supports MtGox, Bitpay, Coinbase and BitStamp.
+    :type text: str
+    """
+    text = text.lower()
+
+    if text:
+        if text in exchanges:
+            exchange = exchanges[text]
+        else:
+            valid_exchanges = list(exchanges.keys())
+            notice("Invalid exchange '{}', valid exchanges are {} and {}".format(text, ", ".join(valid_exchanges[:-1]),
+                                                                                 valid_exchanges[-1]))
+            return
+    else:
+        exchange = exchanges["blockchain"]
+
+    data = http.get_json(exchange["api_url"])
+    func = exchange["func"]
+    return func(data)
+
+
+@hook.command(["ltc", "litecoin"], threaded=True, autohelp=False)
+def litecoin(message):
+    """litecoin -- gets current exchange rate for litecoins from BTC-E"""
+    data = http.get_json("https://btc-e.com/api/2/ltc_usd/ticker")
+    ticker = data['ticker']
+    message("Current: \x0307${:,.2f}\x0f - High: \x0307${:,.2f}\x0f"
+            " - Low: \x0307${:,.2f}\x0f - Volume: {:,.2f} LTC".format(ticker['buy'], ticker['high'], ticker['low'],
+                                                                      ticker['vol_cur']))
diff --git a/disabled/cypher.py b/disabled/cypher.py
new file mode 100644
index 0000000..e2fcc7e
--- /dev/null
+++ b/disabled/cypher.py
@@ -0,0 +1,63 @@
+import base64
+import binascii
+
+from util import hook
+
+
+def encode(password, text):
+    """
+    :type password: str
+    :type text: str
+    """
+    enc = []
+    for i in range(len(text)):
+        key_c = password[i % len(password)]
+        enc_c = chr((ord(text[i]) + ord(key_c)) % 256)
+        enc.append(enc_c)
+    return base64.urlsafe_b64encode("".join(enc).encode()).decode()
+
+
+def decode(password, encoded, notice):
+    """
+    :type password: str
+    :type encoded: str
+    """
+    dec = []
+    try:
+        encoded_bytes = base64.urlsafe_b64decode(encoded.encode()).decode()
+    except binascii.Error:
+        notice("Invalid input '{}'".format(encoded))
+        return
+    for i in range(len(encoded_bytes)):
+        key_c = password[i % len(password)]
+        dec_c = chr((256 + ord(encoded_bytes[i]) - ord(key_c)) % 256)
+        dec.append(dec_c)
+    return "".join(dec)
+
+
+@hook.command(threaded=False)
+def cypher(text, notice):
+    """cypher <pass> <string> -- Cyphers <string> with <password>.
+    :type text: str
+    """
+    split = text.split(None, 1)
+    if len(split) < 2:
+        notice(cypher.__doc__)
+        return
+    password = split[0]
+    plaintext = split[1]
+    return encode(password, plaintext)
+
+
+@hook.command(threaded=False)
+def decypher(text, notice):
+    """decypher <pass> <string> -- Decyphers <string> with <password>.
+    :type text: str
+    """
+    split = text.split(None, 1)
+    if len(split) < 2:
+        notice(decypher.__doc__)
+        return
+    password = split[0]
+    encoded = split[1]
+    return decode(password, encoded, notice)
diff --git a/disabled/dbtest.py b/disabled/dbtest.py
new file mode 100644
index 0000000..1fe7a98
--- /dev/null
+++ b/disabled/dbtest.py
@@ -0,0 +1,36 @@
+from sqlalchemy import Table, Column, String
+
+from util import hook, botvars
+
+users = Table(
+    'user_table', botvars.metadata,
+    Column('name', String),
+    Column('phone', String)
+)
+
+
+@hook.command(threaded=True)
+def dbadduser(text, db):
+    """
+    :type text: str
+    :type db: sqlalchemy.orm.Session
+    """
+
+    data = text.split()
+    values = {
+        "name": data[0],
+        "phone": data[1]
+    }
+
+    query = users.insert(values=values)
+    # OR users.insert().values(**values) - http://docs.sqlalchemy.org/en/rel_0_9/core/tutorial.html
+
+    db.execute(query)
+    db.commit()
+
+
+@hook.command(threaded=True, autohelp=False)
+def select(db, message):
+    results = db.execute(users.select())
+    for row in results:
+        message("name: {}, phone: {}".format(row.name, row.phone))
diff --git a/disabled/dice.py b/disabled/dice.py
new file mode 100644
index 0000000..bafb513
--- /dev/null
+++ b/disabled/dice.py
@@ -0,0 +1,97 @@
+# Written by Scaevolus, updated by Lukeroge
+
+
+import re
+import random
+
+from util import hook
+
+whitespace_re = re.compile(r'\s+')
+valid_diceroll = re.compile(r'^([+-]?(?:\d+|\d*d(?:\d+|F))(?:[+-](?:\d+|\d*d(?:\d+|F)))*)( .+)?$', re.I)
+sign_re = re.compile(r'[+-]?(?:\d*d)?(?:\d+|F)', re.I)
+split_re = re.compile(r'([\d+-]*)d?(F|\d*)', re.I)
+
+
+def n_rolls(count, n):
+    """roll an n-sided die count times
+    :type count: int | str
+    :type n: int
+    """
+    if n == "F":
+        return [random.randint(-1, 1) for x in range(min(count, 100))]
+    if n < 2:  # it's a coin
+        if count < 100:
+            return [random.randint(0, 1) for x in range(count)]
+        else:  # fake it
+            return [int(random.normalvariate(.5 * count, (.75 * count) ** .5))]
+    else:
+        if count < 100:
+            return [random.randint(1, n) for x in range(count)]
+        else:  # fake it
+            return [int(random.normalvariate(.5 * (1 + n) * count,
+                                             (((n + 1) * (2 * n + 1) / 6. -
+                                               (.5 * (1 + n)) ** 2) * count) ** .5))]
+
+
+#@hook.regex(valid_diceroll, re.I)
+@hook.command(["roll", "dice"], threaded=False)
+def dice(text, notice):
+    """dice <dice roll> -- Simulates dice rolls. Example: 'dice 2d20-d5+4 roll 2': D20s, subtract 1D5, add 4
+    :type text: str
+    """
+
+    if hasattr(text, "groups"):
+        text, desc = text.groups()
+    else:  # type(text) == str
+        match = valid_diceroll.match(whitespace_re.sub("", text))
+        if match:
+            text, desc = match.groups()
+        else:
+            notice("Invalid dice roll '{}'".format(text))
+            return
+
+    if "d" not in text:
+        return
+
+    spec = whitespace_re.sub('', text)
+    if not valid_diceroll.match(spec):
+        notice("Invalid dice roll '{}'".format(text))
+        return
+    groups = sign_re.findall(spec)
+
+    total = 0
+    rolls = []
+
+    for roll in groups:
+        count, side = split_re.match(roll).groups()
+        count = int(count) if count not in " +-" else 1
+        if side.upper() == "F":  # fudge dice are basically 1d3-2
+            for fudge in n_rolls(count, "F"):
+                if fudge == 1:
+                    rolls.append("\x033+\x0F")
+                elif fudge == -1:
+                    rolls.append("\x034-\x0F")
+                else:
+                    rolls.append("0")
+                total += fudge
+        elif side == "":
+            total += count
+        else:
+            side = int(side)
+            try:
+                if count > 0:
+                    d = n_rolls(count, side)
+                    rolls += list(map(str, d))
+                    total += sum(d)
+                else:
+                    d = n_rolls(-count, side)
+                    rolls += [str(-x) for x in d]
+                    total -= sum(d)
+            except OverflowError:
+                # I have never seen this happen. If you make this happen, you win a cookie
+                return "Thanks for overflowing a float, jerk >:["
+
+    if desc:
+        return "{}: {} ({})".format(desc.strip(), total, ", ".join(rolls))
+    else:
+        return "{} ({})".format(total, ", ".join(rolls))
diff --git a/disabled/dictionary.py b/disabled/dictionary.py
new file mode 100644
index 0000000..10a4fee
--- /dev/null
+++ b/disabled/dictionary.py
@@ -0,0 +1,96 @@
+# Plugin by GhettoWizard and Scaevolus
+import re
+
+from util import hook
+from util import http
+
+
+def format_output(h, definition, show_examples):
+    """
+    :type h: lxml.etree._Element._Element
+    :type definition: tuple
+    """
+    result = '{}: '.format(h.xpath('//dt[@class="title-word"]/a/text()')[0])
+
+    correction = h.xpath('//span[@class="correct-word"]/text()')
+    if correction:
+        result = 'Definition for "{}": '.format(correction[0])
+
+    sections = []
+    for section in definition:
+        if section.attrib['class'] == 'article':
+            sections += [[section.text_content() + ': ']]
+        elif section.attrib['class'] == 'example':
+            if show_examples:
+                sections[-1][-1] += ' ' + section.text_content()
+        else:
+            sections[-1] += [section.text_content()]
+
+    for article in sections:
+        result += article[0]
+        if len(article) > 2:
+            result += ' '.join('{}. {}'.format(n + 1, section)
+                               for n, section in enumerate(article[1:]))
+        else:
+            result += article[1] + ' '
+
+    synonyms = h.xpath('//dd[@class="synonyms"]')
+    if synonyms:
+        result += synonyms[0].text_content()
+
+    result = re.sub(r'\s+', ' ', result)
+    result = re.sub('\xb0', '', result)
+    return result
+
+
+@hook.command(["dictionary", "define"], threaded=True)
+def define(text):
+    """define <word> -- Fetches definition of <word>.
+    :type text: str
+    """
+
+    url = 'http://ninjawords.com/'
+
+    h = http.get_html(url + http.quote_plus(text))
+
+    definition = h.xpath('//dd[@class="article"] | '
+                         '//div[@class="definition"] |'
+                         '//div[@class="example"]')
+
+    if not definition:
+        return 'No results for ' + text + ' :('
+
+    result = format_output(h, definition, True)
+    if len(result) > 450:
+        result = format_output(h, definition, False)
+
+    if len(result) > 450:
+        result = result[:result.rfind(' ', 0, 450)]
+        result = re.sub(r'[^A-Za-z]+\.?$', '', result) + ' ...'
+
+    return result
+
+
+@hook.command(["e", "etymology"], threaded=True)
+def etymology(text):
+    """etymology <word> -- Retrieves the etymology of <word>.
+    :type text: str
+    """
+
+    url = 'http://www.etymonline.com/index.php'
+
+    h = http.get_html(url, term=text)
+
+    etym = h.xpath('//dl')
+
+    if not etym:
+        return 'No etymology found for {} :('.format(text)
+
+    etym = etym[0].text_content()
+
+    etym = ' '.join(etym.split())
+
+    if len(etym) > 400:
+        etym = etym[:etym.rfind(' ', 0, 400)] + ' ...'
+
+    return etym
diff --git a/disabled/domainr.py b/disabled/domainr.py
new file mode 100644
index 0000000..4707dc9
--- /dev/null
+++ b/disabled/domainr.py
@@ -0,0 +1,34 @@
+from util import hook, http
+
+formats = {
+    "taken": "\x034{domain}\x0f{path}",
+    "available": "\x033{domain}\x0f{path}",
+    "other": "\x031{domain}\x0f{path}"
+}
+
+
+def format_domain(domain):
+    """
+    :type domain: dict[str, str]
+    """
+    if domain["availability"] in formats:
+        domainformat = formats[domain["availability"]]
+    else:
+        domainformat = formats["other"]
+    return domainformat.format(**domain)
+
+
+@hook.command(["domain", "domainr"], threaded=True)
+def domainr(text):
+    """domainr <domain> - Use domain.nr's API to search for a domain, and similar domains.
+    :type text: str
+    """
+    try:
+        data = http.get_json('http://domai.nr/api/json/search?q=' + text)
+    except (http.URLError, http.HTTPError):
+        return "Unable to get data for some reason. Try again later."
+    if data['query'] == "":
+        return "An error occurred: {status} - {message}".format(**data['error'])
+
+    domains = [format_domain(domain) for domain in data["results"]]
+    return "Domains: {}".format(", ".join(domains))
diff --git a/disabled/drama.py b/disabled/drama.py
new file mode 100644
index 0000000..f41b34b
--- /dev/null
+++ b/disabled/drama.py
@@ -0,0 +1,32 @@
+import re
+from urllib import parse
+
+from util import hook, http, formatting
+
+
+api_url = "http://encyclopediadramatica.se/api.php?action=opensearch"
+ed_url = "http://encyclopediadramatica.se/"
+
+
+@hook.command(threaded=True)
+def drama(text):
+    """drama <phrase> -- Gets the first paragraph of
+    the Encyclopedia Dramatica article on <phrase>."""
+
+    data = http.get_json(api_url, search=text)
+
+    if not data[1]:
+        return "No results found."
+    article_name = data[1][0].replace(' ', '_')
+
+    url = ed_url + parse.quote(article_name, '')
+    page = http.get_html(url)
+
+    for p in page.xpath('//div[@id="bodyContent"]/p'):
+        if p.text_content():
+            summary = " ".join(p.text_content().splitlines())
+            summary = re.sub("\[\d+\]", "", summary)
+            summary = formatting.truncate_str(summary, 220)
+            return "{} - {}".format(summary, url)
+
+    return "Unknown Error."
diff --git a/disabled/eightball.py b/disabled/eightball.py
new file mode 100644
index 0000000..dd3e316
--- /dev/null
+++ b/disabled/eightball.py
@@ -0,0 +1,27 @@
+import os
+import random
+
+from util import hook, formatting
+
+color_codes = {
+    "<r>": "\x02\x0305",
+    "<g>": "\x02\x0303",
+    "<y>": "\x02"
+}
+
+
+@hook.onload()
+def load_responses(bot):
+    path = os.path.join(bot.data_dir, "8ball_responses.txt")
+    global responses
+    with open(path) as f:
+        responses = [line.strip() for line in
+                     f.readlines() if not line.startswith("//")]
+
+
+@hook.command(["8ball", "8", "eightball"], threaded=False)
+def eightball(action):
+    """8ball <question> -- The all knowing magic eight ball, in electronic form. Ask and it shall be answered!"""
+
+    magic = formatting.multiword_replace(random.choice(responses), color_codes)
+    action("shakes the magic 8 ball... {}".format(magic))
diff --git a/disabled/eliralin_teamcity.py b/disabled/eliralin_teamcity.py
new file mode 100644
index 0000000..2e5ecf1
--- /dev/null
+++ b/disabled/eliralin_teamcity.py
@@ -0,0 +1,158 @@
+from xml.etree.ElementTree import ParseError
+import traceback
+from xml.etree import ElementTree
+import time
+
+import requests
+from requests.auth import HTTPBasicAuth
+
+from util import hook
+
+teamcity_url = "http://ci.daboross.net/ci"
+
+
+class ProjectDatabase:
+    def __init__(self):
+        self.reload_timestamp = 0
+        self.projects = []
+        self.username = "default"
+        self.password = "default"
+        self.teamcity_url = teamcity_url
+        self.loaded_key = False
+
+    def download(self, url):
+        if url.startswith("/httpAuth"):
+            data = requests.get(self.teamcity_url + url, auth=HTTPBasicAuth(self.username, self.password)).text
+        elif url.startswith("/guestAuth"):
+            data = requests.get(self.teamcity_url + url).text
+        elif self.loaded_key:
+            data = requests.get("{}/httpAuth{}".format(self.teamcity_url, url),
+                                auth=HTTPBasicAuth(self.username, self.password)).text
+        else:
+            data = requests.get("{}/guestAuth{}".format(self.teamcity_url, url)).text
+        try:
+            return ElementTree.fromstring(data)
+        except ParseError:
+            print("Error loading {} ({})".format(url, data))
+            raise
+
+    def load_key(self, bot):
+        if not self.loaded_key:
+            api_keys = bot.config.get("api_keys", None)
+            if api_keys:
+                self.username = api_keys.get("teamcity_username")
+                self.password = api_keys.get("teamcity_password")
+                self.loaded_key = True
+            else:
+                print("Warning, couldn't find teamcity api key")
+
+    def reload_database(self):
+        self.reload_timestamp = time.time()
+        self.projects = []
+        root = self.download("/app/rest/projects")
+        for project in root:
+            if project.get("id") != "_Root":
+                self.projects.append(Project(project))
+
+    def ensure_loaded(self, bot=None):
+        if bot and not self.loaded_key:
+            self.load_key(bot)
+        if self.reload_timestamp == 0:
+            self.reload_database()
+
+    def after_check(self):
+        if time.time() > self.reload_timestamp + 300:
+            self.reload_database()
+
+
+class Project:
+    def __init__(self, project):
+        self.name = project.get("name")
+        self.project_id = project.get("id")
+        self.project_url = project.get("href")
+        self.downloads = []
+        project_element = database.download(self.project_url)
+        build_types = project_element.find("buildTypes")
+        if build_types and len(build_types) > 0:
+            for build_type in build_types.findall("buildType"):
+                download = find_download_url(build_type)
+                if download:
+                    self.downloads.append(download)
+
+        self.search_name = self.name.lower()
+        self.search_id = self.project_id.lower()
+
+    def search(self, search):
+        if search == self.search_name or search == self.search_id:
+            return 2
+        elif search in self.search_name or search in self.search_id:
+            return 1
+        return 0
+
+
+def find_download_url(build_type_element):
+    try:
+        build_type_id = build_type_element.get("id")
+        href = build_type_element.get("href")
+        builds_url = database.download(href).find("builds").get("href")
+        build_url = database.download(builds_url).find("build").get("href")
+        artifacts_url = database.download(build_url).find("artifacts").get("href")
+        files = database.download(artifacts_url).findall("file")
+        filenames = [download_file.get("name") for download_file in files]
+        return {"id": build_type_id, "files": filenames}
+    except AttributeError:
+        traceback.print_exc()
+        return None
+    except ParseError:
+        traceback.print_exc()
+        return None
+
+
+database = ProjectDatabase()
+
+
+@hook.command(["teamcity", "ci"])
+def teamcity(inp, bot, reply, message):
+    """teamcity [project] - Searches for project on teamcity, and displays project URL and download"""
+    database.ensure_loaded(bot=bot)
+    search = inp.lower()
+    level_found = 0
+    project_found = None
+    other_matches = []
+    for project in database.projects:
+        level = project.search(search)
+        if level > level_found:
+            if project_found:
+                other_matches.append(project_found.name)
+            project_found = project
+            level_found = level
+        elif level > 0:
+            other_matches.append(project.name)
+
+    if project_found is not None:
+        reply("{} - Project: http://ci.daboross.net/p/{}".format(project_found.name, project_found.project_id))
+        for download in project_found.downloads:
+            for download_file in download["files"]:
+                message("Download: http://ci.daboross.net/d/{}/{}".format(download["id"], download_file))
+        if len(other_matches) > 0:
+            message("(Other matches: {})".format(", ".join(other_matches)))
+    else:
+        reply("No projects found matching '{}'".format(inp))
+    database.after_check()
+
+
+@hook.command(["reloadci", "reload_teamcity"], permissions=["botcontrol"], autohelp=False)
+def reload_teamcity(bot, reply):
+    """reloadci - Reloads teamcity database manually"""
+    database.load_key(bot)
+    database.reload_database()
+    reply("Reloaded teamcity, found {} projects.".format(len(database.projects)))
+    database.after_check()
+
+
+@hook.command(["listci", "list_teamcity"], permissions=["botcontrol"], autohelp=False)
+def list_teamcity(bot, reply):
+    """listci - Lists all projects loaded into database from teamcity"""
+    database.ensure_loaded(bot=bot)
+    reply("Projects: {}".format(", ".join([project.name for project in database.projects])))
+    database.after_check()
diff --git a/disabled/eliralin_utility.py b/disabled/eliralin_utility.py
new file mode 100644
index 0000000..6de03eb
--- /dev/null
+++ b/disabled/eliralin_utility.py
@@ -0,0 +1,118 @@
+from random import random
+import socket
+
+from util import hook
+
+
+@hook.command(["josephus", "jose"])
+def josephus(text):
+    """jose [size] [every x] [starting person] - Calculates who dies last """
+    split = text.split()
+    if len(split) != 3:
+        return "Not enough / too many arguments. {}".format(len(split))
+    size, every_x, current = [int(x) for x in split]
+    alive, till_kill = [True] * size, 0
+    while True:
+        if alive[current]:
+            if sum(alive) == 1:
+                break
+            elif till_kill == 0:
+                alive[current] = False
+                till_kill = every_x - 1
+            else:
+                till_kill -= 1
+        current += 1 if current < size - 1 else 1 - size
+    return "Josephus should be at position {} to survive.".format(current)
+
+
+@hook.regex("(?i)(^ )*pets Eliralin *$")
+def pet(action, nick):
+    r = random()
+    if r > 0.7:
+        action("huggles {}".format(nick))
+
+
+@hook.command(["hug", "huggle"])
+def huggle(text, action, nick):
+    if text:
+        action("huggles {}".format(text))
+    else:
+        action("huggles {}".format(nick))
+
+
+@hook.command()
+def colors(text):
+    if text:
+        intinp = int(text)
+        if intinp > 70:
+            return "Please use a number smaller than or equal to 70"
+        forrange = range(intinp)
+    else:
+        forrange = range(30)
+    result = ""
+    for i in forrange if text else range(30):
+        result += "\x03{0:02d} {0}".format(i)
+    return result
+
+
+@hook.command(permissions=["adminonly"])
+def tree(text, message, notice):
+    """tree [type] [text] - Tree text"""
+    type_input = text.split(None, 1)
+    if len(type_input) < 2:
+        notice("tree [type] [text] - Tree text")
+        return
+    tree_type = type_input[0]
+    if tree_type == "1":
+        func = lambda c: c[1:-1]
+    elif tree_type == "2":
+        func = lambda c: c[2:]
+    elif tree_type == "3":
+        func = lambda c: c[:-2]
+    else:
+        return "Invalid tree type '{}'.".format(tree_type)
+    current = type_input[1]
+    spaces = 7
+    while len(current) > 0:
+        spaces += 1
+        message(spaces * ' ' + current)
+        current = func(current)
+
+    message((spaces - 1) * ' ' + ('----' if len(type_input[1]) % 2 == 0 else '---'))
+
+
+@hook.command
+def dns(text):
+    """dns [domain] - Resolves the IP of a domain"""
+    try:
+        socket.setdefaulttimeout(5)
+        ip = None
+        for info in socket.getaddrinfo(text, 80, 0, 0, socket.SOL_TCP):
+            print(info)
+            if ip is None:
+                ip = info[-1][0]
+            else:
+                ip = "{}, {}".format(ip, info[-1][0])
+        return "{} resolves to {}".format(text, ip)
+    except socket.gaierror:
+        return "Resolve Failed!"
+
+
+@hook.command
+def rdns(inp):
+    """rdns [ip] - Resolves the hostname of an IP"""
+    try:
+        socket.setdefaulttimeout(5)
+        domain = socket.gethostbyaddr(inp)[0]
+        return "{} resolves to {}".format(inp, domain)
+    except socket.gaierror:
+        return "Resolve Failed!"
+
+
+@hook.command("unicode")
+def unicodecommand(inp, reply):
+    try:
+        return "'{}'".format(chr(int(inp)))
+    except ValueError:
+        reply("Failed")
+        raise
diff --git a/disabled/encrypt.py b/disabled/encrypt.py
new file mode 100644
index 0000000..f441a1b
--- /dev/null
+++ b/disabled/encrypt.py
@@ -0,0 +1,139 @@
+import os
+import base64
+import hashlib
+import traceback
+
+from pbkdf2 import PBKDF2
+
+from Crypto import Random
+from Crypto.Cipher import AES
+
+from util import hook
+
+BS = AES.block_size
+
+# helper functions to pad and unpad a string to a specified block size
+# <http://stackoverflow.com/questions/12524994/encrypt-decrypt-using-pycrypto-aes-256>
+
+
+def pad(s):
+    return s + (BS - len(s) % BS) * chr(BS - len(s) % BS)
+
+
+def unpad(s):
+    return s[0:-ord(s[-1])]
+
+
+# helper functions to encrypt and encode a string with AES and base64
+
+def encode_aes(c, s):
+    return base64.b64encode(c.encrypt(pad(s)))
+
+
+def decode_aes(c, s):
+    decoded = c.decrypt(base64.b64decode(s))
+    try:
+        return unpad(decoded.decode())
+    except UnicodeDecodeError:
+        print("Failed to encode an encrypted message result as UTF-8")
+        traceback.print_exc()
+        # This usually happens if password is invalid
+        return "Invalid password for the given message (couldn't encode result as utf-8)"
+
+
+@hook.onload()
+def create_db(db):
+    """check to see that our db has the the encryption table.
+    :type db: sqlalchemy.orm.session.Session
+    """
+    db.execute("create table if not exists encryption(encrypted, iv, "
+               "primary key(encrypted))")
+    db.commit()
+
+
+def get_salt(bot):
+    """generate an encryption salt if none exists, then returns the salt
+    :type bot: core.bot.CloudBot
+    """
+    if not bot.config.get("random_salt", False):
+        bot.config["random_salt"] = hashlib.md5(os.urandom(16)).hexdigest()
+        bot.config.save_config()
+    return bot.config.get("random_salt")
+
+
+@hook.command(threaded=False)
+def encrypt(text, bot, db, notice):
+    """encrypt <pass> <string> -- Encrypts <string> with <pass>. (<string> can only be decrypted using this bot)
+    :type text: str
+    :type bot: core.bot.CloudBot
+    :type db: sqlalchemy.orm.session.Session
+    """
+
+    text_split = text.split(" ")
+
+    # if there is only one argument, return the help message
+    if len(text_split) == 1:
+        notice(encrypt.__doc__)
+        return
+
+    # generate the key from the password and salt
+    password = text_split[0]
+    salt = get_salt(bot)
+    key = PBKDF2(password, salt).read(32)
+
+    # generate the IV and encode it to store in the database
+    iv = Random.new().read(AES.block_size)
+    iv_encoded = base64.b64encode(iv)
+
+    # create the AES cipher and encrypt/encode the text with it
+    text = " ".join(text_split[1:])
+    cipher = AES.new(key, AES.MODE_CBC, iv)
+    encoded = encode_aes(cipher, text)
+
+    # store the encoded text and IV in the DB for decoding later
+    db.execute("insert or replace into encryption(encrypted, iv)"
+               "values(:encoded,:iv)", {'encoded': encoded,
+                                        'iv': iv_encoded})
+    db.commit()
+
+    return encoded.decode()
+
+
+@hook.command(threaded=False)
+def decrypt(text, bot, db, notice):
+    """decrypt <pass> <string> -- Decrypts <string> with <pass>. (can only decrypt strings encrypted on this bot)
+    :type bot: core.bot.CloudBot
+    :type db: sqlalchemy.orm.session.Session
+    """
+
+    inp_split = text.split(" ")
+
+    # if there is only one argument, return the help message
+    if len(inp_split) == 1:
+        notice(decrypt.__doc__)
+        return
+
+    encrypted_str = " ".join(inp_split[1:])
+
+    # generate the key from the password and salt
+    password = inp_split[0]
+    salt = get_salt(bot)
+    key = PBKDF2(password, salt).read(32)
+
+    encrypted_bytes = encrypted_str.encode("utf-8")
+
+    # get the encoded IV from the database
+    database_result = db.execute("select iv from encryption where"
+                                 " encrypted=:key", {'key': encrypted_bytes}).fetchone()
+
+    if database_result is None:
+        notice("Unknown encrypted string '{}'".format(encrypted_str))
+        return
+
+    # decode the IV
+    iv_encoded = database_result[0]
+    iv = base64.b64decode(iv_encoded)
+
+    # create AES cipher, decode text, decrypt text, and unpad it
+    cipher = AES.new(key, AES.MODE_CBC, iv)
+    return decode_aes(cipher, encrypted_bytes)
diff --git a/disabled/fact.py b/disabled/fact.py
new file mode 100644
index 0000000..48501a7
--- /dev/null
+++ b/disabled/fact.py
@@ -0,0 +1,37 @@
+from util import hook, http, web
+
+
+@hook.command(autohelp=False, threaded=True)
+def fact():
+    """fact -- Gets a random fact from OMGFACTS."""
+
+    attempts = 0
+
+    # all of this is because omgfacts is fail
+    while True:
+        try:
+            soup = http.get_soup('http://www.omg-facts.com/random')
+        except (http.HTTPError, http.URLError):
+            if attempts > 2:
+                return "Could not find a fact!"
+            else:
+                attempts += 1
+                continue
+
+        response = soup.find('a', {'class': 'surprise'})
+        link = response['href']
+        fact_data = ''.join(response.find(text=True))
+
+        if fact_data:
+            fact_data = fact_data.strip()
+            break
+        else:
+            if attempts > 2:
+                return "Could not find a fact!"
+            else:
+                attempts += 1
+                continue
+
+    url = web.try_isgd(link)
+
+    return "{} - {}".format(fact_data, url)
diff --git a/disabled/factoids.py b/disabled/factoids.py
new file mode 100644
index 0000000..eee1d46
--- /dev/null
+++ b/disabled/factoids.py
@@ -0,0 +1,188 @@
+# Written by Scaevolus 2010
+import string
+import re
+
+from sqlalchemy import Table, Column, String
+
+from util import hook, botvars, http, formatting, pyexec
+
+re_lineends = re.compile(r'[\r\n]*')
+
+
+# some simple "shortcodes" for formatting purposes
+shortcodes = {
+    '[b]': '\x02',
+    '[/b]': '\x02',
+    '[u]': '\x1F',
+    '[/u]': '\x1F',
+    '[i]': '\x16',
+    '[/i]': '\x16'
+}
+
+table = Table(
+    "mem",
+    botvars.metadata,
+    Column("word", String, primary_key=True),
+    Column("data", String),
+    Column("nick", String)
+)
+
+
+@hook.onload()
+def load_cache(db):
+    """
+    :type db: sqlalchemy.orm.Session
+    """
+    global factoid_cache
+    factoid_cache = {}
+    for row in db.execute(table.select()):
+        word = row["word"]
+        data = row["data"]
+        # nick = row["nick"]
+        factoid_cache[word] = data  # we might want (data, nick) sometime later
+
+
+def add_factoid(db, word, data, nick):
+    """
+    :type db: sqlalchemy.orm.Session
+    :type word: str
+    :type data: str
+    :type nick: str
+    """
+    if word in factoid_cache:
+        # if we have a set value, update
+        db.execute(table.update().values(data=data, nick=nick).where(table.c.word == word))
+    else:
+        # otherwise, insert
+        db.execute(table.insert().values(word=word, data=data, nick=nick))
+    db.commit()
+    load_cache(db)
+
+
+def del_factoid(db, word):
+    """
+    :type db: sqlalchemy.orm.Session
+    :type word: str
+    """
+    db.execute(table.delete().where(table.c.word == word))
+    db.commit()
+    load_cache(db)
+
+
+@hook.command(["r", "remember"], threaded=False, permissions=["addfactoid"])
+def remember(text, nick, db, notice):
+    """remember <word> [+]<data> -- Remembers <data> with <word>. Add + to <data> to append."""
+
+    append = False
+
+    try:
+        word, data = text.split(None, 1)
+    except ValueError:
+        return remember.__doc__
+
+    old_data = factoid_cache.get(word)
+
+    if data.startswith('+') and old_data:
+        append = True
+        # remove + symbol
+        new_data = data[1:]
+        # append new_data to the old_data
+        if len(new_data) > 1 and new_data[1] in (string.punctuation + ' '):
+            data = old_data + new_data
+        else:
+            data = old_data + ' ' + new_data
+
+    add_factoid(db, word, data, nick)
+
+    if old_data:
+        if append:
+            notice("Appending \x02{}\x02 to \x02{}\x02".format(new_data, old_data))
+        else:
+            notice('Remembering \x02{}\x02 for \x02{}\x02. Type ?{} to see it.'.format(data, word, word))
+            notice('Previous data was \x02{}\x02'.format(old_data))
+    else:
+        notice('Remembering \x02{}\x02 for \x02{}\x02. Type ?{} to see it.'.format(data, word, word))
+
+
+@hook.command(["f", "forget"], threaded=True, permissions=["delfactoid"])
+def forget(text, db, notice):
+    """forget <word> -- Forgets a remembered <word>."""
+
+    data = factoid_cache.get(text)
+
+    if data:
+        del_factoid(db, text)
+        notice('"%s" has been forgotten.' % data.replace('`', "'"))
+        return
+    else:
+        notice("I don't know about that.")
+        return
+
+
+@hook.command(threaded=False)
+def info(text, notice):
+    """info <factoid> -- Shows the source of a factoid."""
+
+    text = text.strip()
+
+    if text in factoid_cache:
+        notice(factoid_cache[text])
+    else:
+        notice("Unknown Factoid.")
+
+
+@hook.regex(r'^\^ ?(.+)', threaded=False)
+def factoid(inp, input, db, message, action):
+    """?<word> -- Shows what data is associated with <word>."""
+
+    # split up the input
+    split = inp.group(1).strip().split(" ")
+    factoid_id = split[0]
+
+    if len(split) >= 1:
+        arguments = " ".join(split[1:])
+    else:
+        arguments = ""
+
+    if factoid_id in factoid_cache:
+        data = factoid_cache[factoid_id]
+        # factoid preprocessors
+        if data.startswith("<py>"):
+            code = data[4:].strip()
+            variables = 'input="""{}"""; nick="{}"; chan="{}"; bot_nick="{}";'.format(arguments.replace('"', '\\"'),
+                                                                                      input.nick, input.chan,
+                                                                                      input.conn.nick)
+            result = pyexec.eval_py(variables + code)
+        else:
+            result = data
+
+        # factoid postprocessors
+        result = formatting.multiword_replace(result, shortcodes)
+
+        if result.startswith("<act>"):
+            result = result[5:].strip()
+            action(result)
+        elif result.startswith("<url>"):
+            url = result[5:].strip()
+            try:
+                message(http.get(url))
+            except http.HTTPError:
+                message("Could not fetch URL.")
+        else:
+            message(result)
+
+
+@hook.command(autohelp=False, threaded=False, permissions=["listfactoids"])
+def listfactoids(reply):
+    reply_text = []
+    reply_text_length = 0
+    for word in factoid_cache.keys():
+        added_length = len(word) + 2
+        if reply_text_length + added_length > 400:
+            reply(", ".join(reply_text))
+            reply_text = []
+            reply_text_length = 0
+        else:
+            reply_text.append(word)
+            reply_text_length += added_length
+    return ", ".join(reply_text)
diff --git a/disabled/fishbans.py b/disabled/fishbans.py
new file mode 100644
index 0000000..0b42c5e
--- /dev/null
+++ b/disabled/fishbans.py
@@ -0,0 +1,58 @@
+from urllib.parse import quote_plus
+
+from util import hook, http, formatting
+
+api_url = "http://api.fishbans.com/stats/{}/"
+
+
+@hook.command(["bans", "fishbans"], threaded=True)
+def fishbans(text):
+    """fishbans <user> -- Gets information on <user>s minecraft bans from fishbans"""
+    user = text.strip()
+
+    try:
+        request = http.get_json(api_url.format(quote_plus(user)))
+    except (http.HTTPError, http.URLError) as e:
+        return "Could not fetch ban data from the Fishbans API: {}".format(e)
+
+    if not request["success"]:
+        return "Could not fetch ban data for {}.".format(user)
+
+    user_url = "http://fishbans.com/u/{}/".format(user)
+    ban_count = request["stats"]["totalbans"]
+
+    if ban_count == 1:
+        return "The user \x02{}\x02 has \x021\x02 ban - {}".format(user, user_url)
+    elif ban_count > 1:
+        return "The user \x02{}\x02 has \x02{}\x02 bans - {}".format(user, ban_count, user_url)
+    else:
+        return "The user \x02{}\x02 has no bans - {}".format(user, user_url)
+
+
+@hook.command(threaded=True)
+def bancount(text):
+    """bancount <user> -- Gets a count of <user>s minecraft bans from fishbans"""
+    user = text.strip()
+
+    try:
+        request = http.get_json(api_url.format(quote_plus(user)))
+    except (http.HTTPError, http.URLError) as e:
+        return "Could not fetch ban data from the Fishbans API: {}".format(e)
+
+    if not request["success"]:
+        return "Could not fetch ban data for {}.".format(user)
+
+    user_url = "http://fishbans.com/u/{}/".format(user)
+    services = request["stats"]["service"]
+
+    out = []
+    for service, ban_count in list(services.items()):
+        if ban_count != 0:
+            out.append("{}: \x02{}\x02".format(service, ban_count))
+        else:
+            pass
+
+    if not out:
+        return "The user \x02{}\x02 has no bans - {}".format(user, user_url)
+    else:
+        return "Bans for \x02{}\x02: {} - {}".format(user, formatting.get_text_list(out, "and"), user_url)
diff --git a/disabled/fmylife.py b/disabled/fmylife.py
new file mode 100644
index 0000000..d6628c3
--- /dev/null
+++ b/disabled/fmylife.py
@@ -0,0 +1,32 @@
+from util import hook, http
+
+fml_cache = []
+
+
+def refresh_cache():
+    """ gets a page of random FMLs and puts them into a dictionary """
+    soup = http.get_soup('http://www.fmylife.com/random/')
+
+    for e in soup.find_all('div', {'class': 'post article'}):
+        fml_id = int(e['id'])
+        text = ''.join(e.find('p').find_all(text=True))
+        fml_cache.append((fml_id, text))
+
+
+@hook.onload()
+def initial_refresh():
+    # do an initial refresh of the cache
+    refresh_cache()
+
+
+@hook.command(autohelp=False, threaded=True)
+def fml(reply):
+    """fml -- Gets a random quote from fmyfife.com."""
+
+    # grab the last item in the fml cache and remove it
+    fml_id, text = fml_cache.pop()
+    # reply with the fml we grabbed
+    reply('(#{}) {}'.format(fml_id, text))
+    # refresh fml cache if its getting empty
+    if len(fml_cache) < 3:
+        refresh_cache()
diff --git a/disabled/fortune.py b/disabled/fortune.py
new file mode 100644
index 0000000..a181f01
--- /dev/null
+++ b/disabled/fortune.py
@@ -0,0 +1,19 @@
+import os
+import random
+
+from util import hook
+
+
+@hook.onload()
+def load_fortunes(bot):
+    path = os.path.join(bot.data_dir, "fortunes.txt")
+    global fortunes
+    with open(path) as f:
+        fortunes = [line.strip() for line in f.readlines()
+                    if not line.startswith("//")]
+
+
+@hook.command(autohelp=False,threaded=False)
+def fortune():
+    """fortune -- Fortune cookies on demand."""
+    return random.choice(fortunes)
diff --git a/disabled/geoip.py b/disabled/geoip.py
new file mode 100644
index 0000000..103d285
--- /dev/null
+++ b/disabled/geoip.py
@@ -0,0 +1,59 @@
+import os.path
+import json
+import gzip
+from io import BytesIO
+
+import pygeoip
+
+from util import hook, http
+
+
+@hook.onload()
+def load_regions(bot):
+    global regions, geo
+    # load region database
+    with open(os.path.join(bot.data_dir, "geoip_regions.json"), "rb") as f:
+        regions = json.loads(f.read().decode())
+
+    if os.path.isfile(os.path.join(bot.data_dir, "GeoLiteCity.dat")):
+        # initialise geolocation database
+        geo = pygeoip.GeoIP(os.path.join(bot.data_dir, "GeoLiteCity.dat"))
+    else:
+        print("Downloading GeoIP database")
+        download = http.get("http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz", decode=False)
+        print("Download complete")
+        bytes_io = BytesIO(download)
+        geoip_file = gzip.GzipFile(fileobj=bytes_io, mode='rb')
+
+        output = open(os.path.join(bot.data_dir, "GeoLiteCity.dat"), 'wb')
+        output.write(geoip_file.read())
+        output.close()
+
+        geo = pygeoip.GeoIP(os.path.join(bot.data_dir, "GeoLiteCity.dat"))
+
+
+@hook.command(threaded=True)
+def geoip(text):
+    """geoip <host/ip> -- Gets the location of <host/ip>"""
+
+    try:
+        record = geo.record_by_name(text)
+    except Exception:
+        return "Sorry, I can't locate that in my database."
+
+    data = {}
+
+    if "region_name" in record:
+        # we try catching an exception here because the region DB is missing a few areas
+        # it's a lazy patch, but it should do the job
+        try:
+            data["region"] = ", " + regions[record["country_code"]][record["region_name"]]
+        except:
+            data["region"] = ""
+    else:
+        data["region"] = ""
+
+    data["cc"] = record["country_code"] or "N/A"
+    data["country"] = record["country_name"] or "Unknown"
+    data["city"] = record["city"] or "Unknown"
+    return "\x02Country:\x02 {country} ({cc}), \x02City:\x02 {city}{region}".format(**data)
diff --git a/disabled/github.py b/disabled/github.py
new file mode 100644
index 0000000..d692ae0
--- /dev/null
+++ b/disabled/github.py
@@ -0,0 +1,128 @@
+import json
+import traceback
+import urllib
+
+from util import hook, http
+
+
+shortcuts = {"cloudbot": "ClouDev/CloudBot"}
+
+# (number, state, user.login, title, truncate(body), gitio.gitio(data.url))
+format_with_summary = "Issue: #{} ({}) by {}: {} | {} {}"
+
+# (number, state, user.login, title, gitio.gitio(data.url))
+format_without_summary = "Issue: #{} ({}) by {}: {} {}"
+
+
+def truncate(msg):
+    nmsg = msg.split()
+    out = None
+    x = 0
+    for i in nmsg:
+        if x <= 7:
+            if out:
+                out = out + " " + nmsg[x]
+            else:
+                out = nmsg[x]
+        x += 1
+    if x <= 7:
+        return out
+    else:
+        return out + "..."
+
+
+def shorten_gitio(url, code=None):
+    # Make sure the url starts with https://
+    if not url.startswith("https://"):
+        if url.startswith("http://"):
+            url = "https://" + url
+        else:
+            url = "https://" + url
+
+    data = 'url=' + url
+    if code:
+        data += '&code=' + code
+        print(code)
+    req = urllib.request.Request(url='http://git.io', data=data.encode())
+
+    # try getting url, let http error raise to next level
+    response = urllib.request.urlopen(req)
+
+    # return location
+    return response.headers["Location"]
+
+
+def try_shorten_gitio(url, code=None):
+    try:
+        return shorten_gitio(url, code)
+    except urllib.error.HTTPError:
+        return url
+
+
+@hook.command(threaded=True)
+def ghissues(text):
+    """ghissues username/repo [number] - Get specified issue summary, or open issue count """
+    args = text.split()
+    if args[0] in shortcuts:
+        repo = shortcuts[args[0]]
+    else:
+        repo = args[0]
+    url = "https://api.github.com/repos/{}/issues".format(repo)
+
+    specific_issue = len(args) > 1
+    if specific_issue:
+        url += "/{}".format(args[1])
+    print("Fetching {}".format(url))
+    try:
+        raw_data = http.get(url)
+    except urllib.error.HTTPError:
+        if specific_issue:
+            return "Error getting issues for '{}/{}', is it a valid issue?".format(args[0], args[1])
+        else:
+            return "Error getting issues for '{}', is it a valid repository?".format(args[0])
+
+    issue_list = json.loads(raw_data)
+
+    if not specific_issue:
+        if len(issue_list) < 1:
+            return "Repository has no open issues"
+        issue = issue_list[0]
+    else:
+        issue = issue_list  # only had one issue
+
+    issue_number = issue["number"]
+    if issue["state"] == "open":
+        state = "\x033\x02OPEN\x02\x0f"
+    else:
+        state = "\x034\x02CLOSED\x02\x0f by {}".format(issue["closed_by"]["login"])
+    user = issue["user"]["login"]
+    title = issue["title"]
+    summary = truncate(issue["body"])
+
+    try:
+        shorturl = try_shorten_gitio(issue["html_url"])
+    except urllib.error.HTTPError:
+        shorturl = try_shorten_gitio(issue["html_url"] + " " + repo.split("/")[1] + issue_number)
+
+    if summary:
+        return format_with_summary.format(issue_number, state, user, title, summary, shorturl)
+    else:
+        return format_without_summary.format(issue_number, state, user, title, shorturl)
+
+
+@hook.command(threaded=True)
+def gitio(text):
+    """gitio <url> [code] -- Shorten Github URLs with git.io. [code] is an optional custom short code."""
+    split = text.split()
+    url = split[0]
+
+    if len(split) > 1:
+        code = split[1]
+    else:
+        code = None
+
+    try:
+        return shorten_gitio(url, code=code)
+    except urllib.error.HTTPError:
+        traceback.print_exc()
+        return "Failed to shorten!"
diff --git a/disabled/google.py b/disabled/google.py
new file mode 100644
index 0000000..9b393bf
--- /dev/null
+++ b/disabled/google.py
@@ -0,0 +1,47 @@
+import random
+
+from util import hook, http, formatting
+
+
+def api_get(kind, query):
+    """Use the RESTful Google Search API"""
+    url = 'http://ajax.googleapis.com/ajax/services/search/%s?' \
+          'v=1.0&safe=moderate'
+    return http.get_json(url % kind, q=query)
+
+
+@hook.command(["googleimage", "gis", "image"], threaded=True)
+def googleimage(text):
+    """gis <query> -- Returns first Google Image result for <query>."""
+
+    parsed = api_get('images', text)
+    if not 200 <= parsed['responseStatus'] < 300:
+        raise IOError('error searching for images: {}: {}'.format(parsed['responseStatus'], ''))
+    if not parsed['responseData']['results']:
+        return 'no images found'
+    return random.choice(parsed['responseData']['results'][:10])['unescapedUrl']
+
+
+@hook.command(["google", "g", "search"], threaded=True)
+def google(text):
+    """google <query> -- Returns first google search result for <query>."""
+
+    parsed = api_get('web', text)
+    if not 200 <= parsed['responseStatus'] < 300:
+        raise IOError('error searching for pages: {}: {}'.format(parsed['responseStatus'], ''))
+    if not parsed['responseData']['results']:
+        return 'No results found.'
+
+    result = parsed['responseData']['results'][0]
+
+    title = http.unescape(result['titleNoFormatting'])
+    title = formatting.truncate_str(title, 60)
+    content = http.unescape(result['content'])
+
+    if not content:
+        content = "No description available."
+    else:
+        content = http.html.fromstring(content).text_content()
+        content = formatting.truncate_str(content, 150)
+
+    return '{} -- \x02{}\x02: "{}"'.format(result['unescapedUrl'], title, content)
diff --git a/disabled/google_translate.py b/disabled/google_translate.py
new file mode 100644
index 0000000..cb42a35
--- /dev/null
+++ b/disabled/google_translate.py
@@ -0,0 +1,169 @@
+"""
+A Google API key is required and retrieved from the bot config file.
+Since December 1, 2011, the Google Translate API is a paid service only.
+"""
+
+import re
+
+import html.entities
+from util import hook, http
+
+
+max_length = 100
+
+
+########### from http://effbot.org/zone/re-sub.htm#unescape-html #############
+
+
+def unescape(text):
+    def fixup(m):
+        text = m.group(0)
+        if text[:2] == "&#":
+            # character reference
+            try:
+                if text[:3] == "&#x":
+                    return chr(int(text[3:-1], 16))
+                else:
+                    return chr(int(text[2:-1]))
+            except ValueError:
+                pass
+        else:
+            # named entity
+            try:
+                text = chr(html.entities.name2codepoint[text[1:-1]])
+            except KeyError:
+                pass
+        return text  # leave as is
+
+    return re.sub("&#?\w+;", fixup, text)
+
+
+##############################################################################
+
+
+def goog_trans(api_key, text, slang, tlang):
+    url = 'https://www.googleapis.com/language/translate/v2'
+
+    if len(text) > max_length:
+        return "This command only supports input of less then 100 characters."
+
+    if slang:
+        parsed = http.get_json(url, key=api_key, q=text, source=slang, target=tlang, format="text")
+    else:
+        parsed = http.get_json(url, key=api_key, q=text, target=tlang, format="text")
+
+        #if not 200 <= parsed['responseStatus'] < 300:
+        #   raise IOError('error with the translation server: %d: %s' % (
+        #           parsed['responseStatus'], parsed['responseDetails']))
+    if not slang:
+        return unescape('(%(detectedSourceLanguage)s) %(translatedText)s' %
+                        (parsed['data']['translations'][0]))
+    return unescape('%(translatedText)s' % parsed['data']['translations'][0])
+
+
+def match_language(fragment):
+    fragment = fragment.lower()
+    for short, _ in lang_pairs:
+        if fragment in short.lower().split():
+            return short.split()[0]
+
+    for short, full in lang_pairs:
+        if fragment in full.lower():
+            return short.split()[0]
+
+    return None
+
+
+@hook.command(threaded=True)
+def translate(text, bot):
+    """translate [source language [target language]] <sentence> -- translates
+    <sentence> from source language (default autodetect) to target
+    language (default English) using Google Translate"""
+
+    api_key = bot.config.get("api_keys", {}).get("googletranslate", None)
+    if not api_key:
+        return "This command requires a paid API key."
+
+    args = text.split(' ', 2)
+
+    try:
+        if len(args) >= 2:
+            sl = match_language(args[0])
+            if not sl:
+                return goog_trans(api_key, text, '', 'en')
+            if len(args) == 2:
+                return goog_trans(api_key, args[1], sl, 'en')
+            if len(args) >= 3:
+                tl = match_language(args[1])
+                if not tl:
+                    if sl == 'en':
+                        return 'unable to determine desired target language'
+                    return goog_trans(api_key, args[1] + ' ' + args[2], sl, 'en')
+                return goog_trans(api_key, args[2], sl, tl)
+        return goog_trans(api_key, text, '', 'en')
+    except IOError as e:
+        return e
+
+
+lang_pairs = [
+    ("no", "Norwegian"),
+    ("it", "Italian"),
+    ("ht", "Haitian Creole"),
+    ("af", "Afrikaans"),
+    ("sq", "Albanian"),
+    ("ar", "Arabic"),
+    ("hy", "Armenian"),
+    ("az", "Azerbaijani"),
+    ("eu", "Basque"),
+    ("be", "Belarusian"),
+    ("bg", "Bulgarian"),
+    ("ca", "Catalan"),
+    ("zh-CN zh", "Chinese"),
+    ("hr", "Croatian"),
+    ("cs", "Czech"),
+    ("da", "Danish"),
+    ("nl", "Dutch"),
+    ("en", "English"),
+    ("et", "Estonian"),
+    ("tl", "Filipino"),
+    ("fi", "Finnish"),
+    ("fr", "French"),
+    ("gl", "Galician"),
+    ("ka", "Georgian"),
+    ("de", "German"),
+    ("el", "Greek"),
+    ("ht", "Haitian Creole"),
+    ("iw", "Hebrew"),
+    ("hi", "Hindi"),
+    ("hu", "Hungarian"),
+    ("is", "Icelandic"),
+    ("id", "Indonesian"),
+    ("ga", "Irish"),
+    ("it", "Italian"),
+    ("ja jp jpn", "Japanese"),
+    ("ko", "Korean"),
+    ("lv", "Latvian"),
+    ("lt", "Lithuanian"),
+    ("mk", "Macedonian"),
+    ("ms", "Malay"),
+    ("mt", "Maltese"),
+    ("no", "Norwegian"),
+    ("fa", "Persian"),
+    ("pl", "Polish"),
+    ("pt", "Portuguese"),
+    ("ro", "Romanian"),
+    ("ru", "Russian"),
+    ("sr", "Serbian"),
+    ("sk", "Slovak"),
+    ("sl", "Slovenian"),
+    ("es", "Spanish"),
+    ("sw", "Swahili"),
+    ("sv", "Swedish"),
+    ("th", "Thai"),
+    ("tr", "Turkish"),
+    ("uk", "Ukrainian"),
+    ("ur", "Urdu"),
+    ("vi", "Vietnamese"),
+    ("cy", "Welsh"),
+    ("yi", "Yiddish")
+]
diff --git a/disabled/googleurlparse.py b/disabled/googleurlparse.py
new file mode 100644
index 0000000..7f9dfb4
--- /dev/null
+++ b/disabled/googleurlparse.py
@@ -0,0 +1,23 @@
+from util import hook
+from urllib.parse import unquote
+
+
+@hook.command(autohelp=False, threaded=True)
+def googleurl(text, db, nick):
+    """googleurl [nickname] - Converts Google urls (google.com/url) to normal urls
+       where possible, in the specified nickname's last message. If nickname isn't provided,
+       action will be performed on user's last message"""
+    if not text:
+        text = nick
+    last_message = db.execute("select name, quote from seen_user where name"
+                              " like ? and chan = ?", (text.lower(), input.chan.lower())).fetchone()
+    if last_message:
+        msg = last_message[1]
+        out = ", ".join([(unquote(a[4:]) if a[:4] == "url=" else "") for a in msg.split("&")]) \
+            .replace(", ,", "").strip()
+        return out if out else "No matches in your last message."
+    else:
+        if text == nick:
+            return "You haven't said anything in this channel yet!"
+        else:
+            return "That user hasn't said anything in this channel yet!"
diff --git a/disabled/history.py b/disabled/history.py
new file mode 100644
index 0000000..81ca449
--- /dev/null
+++ b/disabled/history.py
@@ -0,0 +1,92 @@
+from collections import deque
+import time
+import re
+
+from util import hook, timesince
+
+
+db_ready = []
+
+
+def db_init(db, conn_name):
+    """check to see that our db has the the seen table (connection name is for caching the result per connection)"""
+    global db_ready
+    if db_ready.count(conn_name) < 1:
+        db.execute("create table if not exists seen_user(name, time, quote, chan, host, "
+                   "primary key(name, chan))")
+        db.commit()
+        db_ready.append(conn_name)
+
+
+def track_seen(input, message_time, db, conn):
+    """ Tracks messages for the .seen command """
+    db_init(db, conn)
+    # keep private messages private
+    if input.chan[:1] == "#" and not re.findall('^s/.*/.*/$', input.msg.lower()):
+        db.execute("insert or replace into seen_user(name, time, quote, chan, host)"
+                   "values(:name,:time,:quote,:chan,:host)", {'name': input.nick.lower(),
+                                                              'time': time.time(),
+                                                              'quote': input.msg,
+                                                              'chan': input.chan,
+                                                              'host': input.mask})
+        db.commit()
+
+
+def track_history(input, message_time, conn):
+    try:
+        history = conn.history[input.chan]
+    except KeyError:
+        conn.history[input.chan] = deque(maxlen=100)
+        history = conn.history[input.chan]
+
+    data = (input.nick, message_time, input.msg)
+    history.append(data)
+
+
+@hook.event('PRIVMSG', threaded=True, singlethread=True)
+def chat_tracker(input, db, conn):
+    message_time = time.time()
+    track_seen(input, message_time, db, conn)
+    track_history(input, message_time, conn)
+
+
+@hook.command(autohelp=False, threaded=False)
+def resethistory(input, conn):
+    """resethistory - Resets chat history for the current channel"""
+    try:
+        conn.history[input.chan].clear()
+        return "Reset chat history for current channel."
+    except KeyError:
+        # wat
+        return "There is no history for this channel."
+
+
+@hook.command(threaded=True)
+def seen(text, nick, chan, db, input, conn):
+    """seen <nick> <channel> -- Tell when a nickname was last in active in one of this bot's channels."""
+
+    if input.conn.nick.lower() == text.lower():
+        return "You need to get your eyes checked."
+
+    if text.lower() == nick.lower():
+        return "Have you looked in a mirror lately?"
+
+    if not re.match("^[A-Za-z0-9_|.\-\]\[]*$", text.lower()):
+        return "I can't look up that name, its impossible to use!"
+
+    db_init(db, conn.name)
+
+    last_seen = db.execute("select name, time, quote from seen_user where name"
+                           " like :name and chan = :chan", {'name': text, 'chan': chan}).fetchone()
+
+    if last_seen:
+        reltime = timesince.timesince(last_seen[1])
+        if last_seen[0] != text.lower():  # for glob matching
+            text = last_seen[0]
+        if last_seen[2][0:1] == "\x01":
+            return '{} was last seen {} ago: * {} {}'.format(text, reltime, text,
+                                                             last_seen[2][8:-1])
+        else:
+            return '{} was last seen {} ago saying: {}'.format(text, reltime, last_seen[2])
+    else:
+        return "I've never seen {} talking in this channel.".format(text)
diff --git a/disabled/horoscope.py b/disabled/horoscope.py
new file mode 100644
index 0000000..6eebd19
--- /dev/null
+++ b/disabled/horoscope.py
@@ -0,0 +1,50 @@
+# Plugin by Infinity - <https://github.com/infinitylabs/UguuBot>
+
+from util import hook, http, formatting
+
+
+@hook.onload()
+def init(db):
+    db.execute("create table if not exists horoscope(nick primary key, sign)")
+    db.commit()
+
+
+@hook.command(autohelp=False, threaded=True)
+def horoscope(text, db, notice, nick):
+    """horoscope <sign> -- Get your horoscope."""
+
+    # check if the user asked us not to save his details
+    dontsave = text.endswith(" dontsave")
+    if dontsave:
+        sign = text[:-9].strip().lower()
+    else:
+        sign = text
+
+    db.execute("create table if not exists horoscope(nick primary key, sign)")
+
+    if not sign:
+        sign = db.execute("select sign from horoscope where "
+                          "nick=lower(:nick)", {'nick': nick}).fetchone()
+        if not sign:
+            notice("horoscope <sign> -- Get your horoscope")
+            return
+        sign = sign[0]
+
+    url = "http://my.horoscope.com/astrology/free-daily-horoscope-{}.html".format(sign)
+    soup = http.get_soup(url)
+
+    title = soup.find_all('h1', {'class': 'h1b'})[1]
+    horoscope_text = soup.find('div', {'class': 'fontdef1'})
+    result = "\x02{}\x02 {}".format(title, horoscope_text)
+    result = formatting.strip_html(result)
+    #result = unicode(result, "utf8").replace('flight ','')
+
+    if not title:
+        return "Could not get the horoscope for {}.".format(text)
+
+    if text and not dontsave:
+        db.execute("insert or replace into horoscope(nick, sign) values (:nick, :sign)",
+                   {'nick': nick.lower(), 'sign': sign})
+        db.commit()
+
+    return result
diff --git a/disabled/hulu.py b/disabled/hulu.py
new file mode 100644
index 0000000..ee7197d
--- /dev/null
+++ b/disabled/hulu.py
@@ -0,0 +1,30 @@
+import re
+
+from urllib.parse import urlencode
+from util import hook, http, timeformat
+
+
+hulu_re = (r'(.*://)(www.hulu.com|hulu.com)(.*)', re.I)
+
+
+@hook.regex(*hulu_re, threaded=True)
+def hulu_url(match):
+    data = http.get_json("http://www.hulu.com/api/oembed.json?url=http://www.hulu.com" + match.group(3))
+    showname = data['title'].split("(")[-1].split(")")[0]
+    title = data['title'].split(" (")[0]
+    return "{}: {} - {}".format(showname, title, timeformat.format_time(int(data['duration'])))
+
+
+@hook.command('hulu', threaded=True)
+def hulu_search(text):
+    """hulu <search> - Search Hulu"""
+    result = http.get_soup(
+        "http://m.hulu.com/search?dp_identifier=hulu&{}&items_per_page=1&page=1".format(urlencode({'query': text})))
+    data = result.find('results').find('videos').find('video')
+    showname = data.find('show').find('name').text
+    title = data.find('title').text
+    duration = timeformat.format_time(int(float(data.find('duration').text)))
+    description = data.find('description').text
+    rating = data.find('content-rating').text
+    return "{}: {} - {} - {} ({}) {}".format(showname, title, description, duration, rating,
+                                             "http://www.hulu.com/watch/" + str(data.find('id').text))
diff --git a/disabled/ignore.py b/disabled/ignore.py
new file mode 100644
index 0000000..ded2bf5
--- /dev/null
+++ b/disabled/ignore.py
@@ -0,0 +1,71 @@
+from fnmatch import fnmatch
+
+from util import hook
+
+
+#@hook.sieve
+def ignore_sieve(bot, input, plugin):
+    """ blocks input from ignored channels/hosts """
+    ignorelist = bot.config["modules"]["ignore"]["ignored"]
+    mask = input.mask.lower()
+
+    # don't block input to event hooks
+    if type == "event":
+        return input
+
+    if ignorelist:
+        for pattern in ignorelist:
+            if pattern.startswith("#") and pattern in ignorelist:
+                if input.command == "PRIVMSG" and input.lastparam[1:] == "unignore":
+                    return input
+                else:
+                    return None
+            elif fnmatch(mask, pattern):
+                if input.command == "PRIVMSG" and input.lastparam[1:] == "unignore":
+                    return input
+                else:
+                    return None
+
+    return input
+
+
+@hook.command(threaded=False, autohelp=False)
+def ignored(notice, bot):
+    """ignored -- Lists ignored channels/users."""
+    ignorelist = bot.config["modules"]["ignore"]["ignored"]
+    if ignorelist:
+        notice("Ignored channels/users are: {}".format(", ".join(ignorelist)))
+    else:
+        notice("No masks are currently ignored.")
+    return
+
+
+@hook.command(threaded=True, permissions=["ignore"])
+def ignore(text, notice, bot):
+    """ignore <channel|nick|host> -- Makes the bot ignore <channel|user>."""
+    target = text.lower()
+    ignorelist = bot.config["modules"]["ignore"]["ignored"]
+    if target in ignorelist:
+        notice("{} is already ignored.".format(target))
+    else:
+        notice("{} has been ignored.".format(target))
+        ignorelist.append(target)
+        ignorelist.sort()
+        bot.config.save_config()
+    return
+
+
+@hook.command(threaded=True, permissions=["ignore"])
+def unignore(text, notice, bot):
+    """unignore <channel|user> -- Makes the bot listen to
+    <channel|user>."""
+    target = text.lower()
+    ignorelist = bot.config["modules"]["ignore"]["ignored"]
+    if target in ignorelist:
+        notice("{} has been unignored.".format(target))
+        ignorelist.remove(target)
+        ignorelist.sort()
+        bot.config.save_config()
+    else:
+        notice("{} is not ignored.".format(target))
+    return
diff --git a/disabled/imdb.py b/disabled/imdb.py
new file mode 100644
index 0000000..c8810d6
--- /dev/null
+++ b/disabled/imdb.py
@@ -0,0 +1,59 @@
+# IMDb lookup plugin by Ghetto Wizard (2011) and blha303 (2013)
+
+import re
+
+from util import hook, http, formatting
+
+
+id_re = re.compile("tt\d+")
+imdb_re = (r'(.*:)//(imdb.com|www.imdb.com)(:[0-9]+)?(.*)', re.I)
+
+
+@hook.command(threaded=True)
+def imdb(text):
+    """imdb <movie> -- Gets information about <movie> from IMDb."""
+
+    strip = text.strip()
+
+    if id_re.match(strip):
+        content = http.get_json("http://www.omdbapi.com/", i=strip)
+    else:
+        content = http.get_json("http://www.omdbapi.com/", t=strip)
+
+    if content.get('Error', None) == 'Movie not found!':
+        return 'Movie not found!'
+    elif content['Response'] == 'True':
+        content['URL'] = 'http://www.imdb.com/title/{}'.format(content['imdbID'])
+
+        out = '\x02%(Title)s\x02 (%(Year)s) (%(Genre)s): %(Plot)s'
+        if content['Runtime'] != 'N/A':
+            out += ' \x02%(Runtime)s\x02.'
+        if content['imdbRating'] != 'N/A' and content['imdbVotes'] != 'N/A':
+            out += ' \x02%(imdbRating)s/10\x02 with \x02%(imdbVotes)s\x02' \
+                   ' votes.'
+        out += ' %(URL)s'
+        return out % content
+    else:
+        return 'Unknown error.'
+
+
+@hook.regex(*imdb_re, threaded=True)
+def imdb_url(match):
+    imdb_id = match.group(4).split('/')[-1]
+    if imdb_id == "":
+        imdb_id = match.group(4).split('/')[-2]
+    content = http.get_json("http://www.omdbapi.com/", i=imdb_id)
+    if content.get('Error', None) == 'Movie not found!':
+        return 'Movie not found!'
+    elif content['Response'] == 'True':
+        content['URL'] = 'http://www.imdb.com/title/%(imdbID)s' % content
+        content['Plot'] = formatting.truncate_str(content['Plot'], 50)
+        out = '\x02%(Title)s\x02 (%(Year)s) (%(Genre)s): %(Plot)s'
+        if content['Runtime'] != 'N/A':
+            out += ' \x02%(Runtime)s\x02.'
+        if content['imdbRating'] != 'N/A' and content['imdbVotes'] != 'N/A':
+            out += ' \x02%(imdbRating)s/10\x02 with \x02%(imdbVotes)s\x02' \
+                   ' votes.'
+        return out % content
+    else:
+        return 'Unknown error.'
diff --git a/disabled/imgur.py b/disabled/imgur.py
new file mode 100644
index 0000000..7b95cfb
--- /dev/null
+++ b/disabled/imgur.py
@@ -0,0 +1,82 @@
+import re
+import random
+
+from util import hook, http, web
+
+
+base_url = "http://reddit.com/r/{}/.json"
+imgur_re = re.compile(r'http://(?:i\.)?imgur\.com/(a/)?(\w+\b(?!/))\.?\w?')
+
+album_api = "https://api.imgur.com/3/album/{}/images.json"
+
+
+def is_valid(data):
+    if data["domain"] in ["i.imgur.com", "imgur.com"]:
+        return True
+    else:
+        return False
+
+
+@hook.command(autohelp=False, threaded=True)
+def imgur(inp):
+    """imgur [subreddit] -- Gets the first page of imgur images from [subreddit] and returns a link to them.
+     If [subreddit] is undefined, return any imgur images"""
+    if inp:
+        # see if the input ends with "nsfw"
+        show_nsfw = inp.endswith(" nsfw")
+
+        # remove "nsfw" from the input string after checking for it
+        if show_nsfw:
+            inp = inp[:-5].strip().lower()
+
+        url = base_url.format(inp.strip())
+    else:
+        url = "http://www.reddit.com/domain/imgur.com/.json"
+        show_nsfw = False
+
+    try:
+        data = http.get_json(url, user_agent=http.ua_chrome)
+    except Exception as e:
+        return "Error: " + str(e)
+
+    data = data["data"]["children"]
+    random.shuffle(data)
+
+    # filter list to only have imgur links
+    filtered_posts = [i["data"] for i in data if is_valid(i["data"])]
+
+    if not filtered_posts:
+        return "No images found."
+
+    items = []
+
+    headers = {
+        "Authorization": "Client-ID b5d127e6941b07a"
+    }
+
+    # loop over the list of posts
+    for post in filtered_posts:
+        if post["over_18"] and not show_nsfw:
+            continue
+
+        match = imgur_re.search(post["url"])
+        if match.group(1) == 'a/':
+            # post is an album
+            url = album_api.format(match.group(2))
+            images = http.get_json(url, headers=headers)["data"]
+
+            # loop over the images in the album and add to the list
+            for image in images:
+                items.append(image["id"])
+
+        elif match.group(2) is not None:
+            # post is an image
+            items.append(match.group(2))
+
+    if not items:
+        return "No images found (use .imgur <subreddit> nsfw to show explicit content)"
+
+    if show_nsfw:
+        return "{} \x02NSFW\x02".format(web.isgd("http://imgur.com/" + ','.join(items)))
+    else:
+        return web.isgd("http://imgur.com/" + ','.join(items))
diff --git a/disabled/kernel.py b/disabled/kernel.py
new file mode 100644
index 0000000..5944372
--- /dev/null
+++ b/disabled/kernel.py
@@ -0,0 +1,14 @@
+import re
+
+from util import hook, http
+
+
+@hook.command(autohelp=False, threaded=True)
+def kernel(reply):
+    contents = http.get("https://www.kernel.org/finger_banner")
+    contents = re.sub(r'The latest(\s*)', '', contents)
+    contents = re.sub(r'version of the Linux kernel is:(\s*)', '- ', contents)
+    lines = contents.split("\n")
+
+    message = "Linux kernel versions: {}".format(", ".join(line for line in lines[:-1]))
+    reply(message)
diff --git a/disabled/kill.py b/disabled/kill.py
new file mode 100644
index 0000000..d687436
--- /dev/null
+++ b/disabled/kill.py
@@ -0,0 +1,33 @@
+import json
+
+from util import hook, textgen
+
+
+def get_generator(_json, variables):
+    data = json.loads(_json)
+    return textgen.TextGenerator(data["templates"],
+                                 data["parts"], variables=variables)
+
+
+@hook.command(threaded=False)
+def kill(inp, action=None, nick=None, conn=None, notice=None):
+    """kill <user> -- Makes the bot kill <user>."""
+    target = inp.strip()
+
+    if " " in target:
+        notice("Invalid username!")
+        return
+
+    # if the user is trying to make the bot kill itself, kill them
+    if target.lower() == conn.nick.lower() or target.lower() == "itself":
+        target = nick
+
+    variables = {
+        "user": target
+    }
+
+    with open("./data/kills.json") as f:
+        generator = get_generator(f.read(), variables)
+
+    # act out the message
+    action(generator.generate_string())
diff --git a/disabled/lastfm.py b/disabled/lastfm.py
new file mode 100644
index 0000000..51d6dc2
--- /dev/null
+++ b/disabled/lastfm.py
@@ -0,0 +1,81 @@
+from datetime import datetime
+
+from util import hook, http, timesince
+
+
+api_url = "http://ws.audioscrobbler.com/2.0/?format=json"
+
+
+@hook.command(["lastfm", "l"], threaded=True, autohelp=False)
+def lastfm(inp, nick, db, bot, notice):
+    """lastfm [user] [dontsave] -- Displays the now playing (or last played) track of LastFM user [user]."""
+    api_key = bot.config.get("api_keys", {}).get("lastfm")
+    if not api_key:
+        return "error: no api key set"
+
+    # check if the user asked us not to save his details
+    dontsave = inp.endswith(" dontsave")
+    if dontsave:
+        user = inp[:-9].strip().lower()
+    else:
+        user = inp
+
+    db.execute("create table if not exists lastfm(nick primary key, acc)")
+
+    if not user:
+        user = db.execute("select acc from lastfm where nick=lower(:nick)",
+                          {'nick': nick}).fetchone()
+        if not user:
+            notice(lastfm.__doc__)
+            return
+        user = user[0]
+
+    response = http.get_json(api_url, method="user.getrecenttracks",
+                             api_key=api_key, user=user, limit=1)
+
+    if 'error' in response:
+        return "Error: {}.".format(response["message"])
+
+    if not "track" in response["recenttracks"] or len(response["recenttracks"]["track"]) == 0:
+        return 'No recent tracks for user "{}" found.'.format(user)
+
+    tracks = response["recenttracks"]["track"]
+
+    if type(tracks) == list:
+        # if the user is listening to something, the tracks entry is a list
+        # the first item is the current track
+        track = tracks[0]
+        status = 'is listening to'
+        ending = '.'
+    elif type(tracks) == dict:
+        # otherwise, they aren't listening to anything right now, and
+        # the tracks entry is a dict representing the most recent track
+        track = tracks
+        status = 'last listened to'
+        # lets see how long ago they listened to it
+        time_listened = datetime.fromtimestamp(int(track["date"]["uts"]))
+        time_since = timesince.timesince(time_listened)
+        ending = ' ({} ago)'.format(time_since)
+
+    else:
+        return "error: could not parse track listing"
+
+    title = track["name"]
+    album = track["album"]["#text"]
+    artist = track["artist"]["#text"]
+
+    out = '{} {} "{}"'.format(user, status, title)
+    if artist:
+        out += " by \x02{}\x0f".format(artist)
+    if album:
+        out += " from the album \x02{}\x0f".format(album)
+
+    # append ending based on what type it was
+    out += ending
+
+    if inp and not dontsave:
+        db.execute("insert or replace into lastfm(nick, acc) values "
+                   "(:nick, :account)", {'nick': nick.lower(), 'account': user})
+        db.commit()
+
+    return out
diff --git a/disabled/lmgtfy.py b/disabled/lmgtfy.py
new file mode 100644
index 0000000..e09358a
--- /dev/null
+++ b/disabled/lmgtfy.py
@@ -0,0 +1,13 @@
+from util import hook, web, http
+
+
+@hook.command(["lmgtfy", "gfy"], threaded=True)
+def lmgtfy(inp):
+    """lmgtfy [phrase] - Posts a google link for the specified phrase"""
+
+    link = "http://lmgtfy.com/?q={}".format(http.quote_plus(inp))
+
+    try:
+        return web.isgd(link)
+    except (web.ShortenError, http.HTTPError):
+        return link
diff --git a/disabled/lyrics.py b/disabled/lyrics.py
new file mode 100644
index 0000000..0a1aeb5
--- /dev/null
+++ b/disabled/lyrics.py
@@ -0,0 +1,43 @@
+from util import hook, http, web
+
+url = "http://search.azlyrics.com/search.php?q="
+
+
+@hook.command(threaded=True)
+def lyrics(inp):
+    """lyrics <search> - Search AZLyrics.com for song lyrics"""
+    if "pastelyrics" in inp:
+        dopaste = True
+        inp = inp.replace("pastelyrics", "").strip()
+    else:
+        dopaste = False
+    soup = http.get_soup(url + inp.replace(" ", "+"))
+    if "Try to compose less restrictive search query" in soup.find('div', {'id': 'inn'}).text:
+        return "No results. Check spelling."
+    div = None
+    for i in soup.findAll('div', {'class': 'sen'}):
+        if "/lyrics/" in i.find('a')['href']:
+            div = i
+            break
+    if div:
+        title = div.find('a').text
+        link = div.find('a')['href']
+        if dopaste:
+            newsoup = http.get_soup(link)
+            try:
+                lyrics = newsoup.find('div', {'style': 'margin-left:10px;margin-right:10px;'}).text.strip()
+                pasteurl = " " + web.haste(lyrics)
+            except Exception as e:
+                pasteurl = " (\x02Unable to paste lyrics\x02 [{}])".format(str(e))
+        else:
+            pasteurl = ""
+        artist = div.find('b').text.title()
+        lyricsum = div.find('div').text
+        if "\r\n" in lyricsum.strip():
+            lyricsum = " / ".join(lyricsum.strip().split("\r\n")[0:4])  # truncate, format
+        else:
+            lyricsum = " / ".join(lyricsum.strip().split("\n")[0:4])  # truncate, format
+        return "\x02{}\x02 by \x02{}\x02 {}{} - {}".format(title, artist, web.try_isgd(link), pasteurl,
+                                                           lyricsum[:-3])
+    else:
+        return "No song results. " + url + inp.replace(" ", "+")
diff --git a/disabled/metacritic.py b/disabled/metacritic.py
new file mode 100644
index 0000000..261c141
--- /dev/null
+++ b/disabled/metacritic.py
@@ -0,0 +1,103 @@
+# metacritic.com scraper
+
+import re
+
+from urllib.error import HTTPError
+from util import hook, http
+
+
+@hook.command(["metacritic", "mc"], threaded=True)
+def metacritic(inp):
+    """mc [all|movie|tv|album|x360|ps3|pc|gba|ds|3ds|wii|vita|wiiu|xone|ps4] <title>
+    Gets rating for <title> from metacritic on the specified medium."""
+
+    args = inp.strip()
+
+    game_platforms = ('x360', 'ps3', 'pc', 'gba', 'ds', '3ds', 'wii',
+                      'vita', 'wiiu', 'xone', 'ps4')
+
+    all_platforms = game_platforms + ('all', 'movie', 'tv', 'album')
+
+    try:
+        plat, title = args.split(' ', 1)
+        if plat not in all_platforms:
+            # raise the ValueError so that the except block catches it
+            # in this case, or in the case of the .split above raising the
+            # ValueError, we want the same thing to happen
+            raise ValueError
+    except ValueError:
+        plat = 'all'
+        title = args
+
+    cat = 'game' if plat in game_platforms else plat
+
+    title_safe = http.quote_plus(title)
+
+    url = 'http://www.metacritic.com/search/{}/{}/results'.format(cat, title_safe)
+
+    try:
+        doc = http.get_html(url)
+    except HTTPError:
+        return 'error fetching results'
+
+    # get the proper result element we want to pull data from
+    result = None
+
+    if not doc.find_class('query_results'):
+        return 'No results found.'
+
+    # if they specified an invalid search term, the input box will be empty
+    if doc.get_element_by_id('search_term').value == '':
+        return 'Invalid search term.'
+
+    if plat not in game_platforms:
+        # for [all] results, or non-game platforms, get the first result
+        result = doc.find_class('result first_result')[0]
+
+        # find the platform, if it exists
+        result_type = result.find_class('result_type')
+        if result_type:
+
+            # if the result_type div has a platform div, get that one
+            platform_div = result_type[0].find_class('platform')
+            if platform_div:
+                plat = platform_div[0].text_content().strip()
+            else:
+                # otherwise, use the result_type text_content
+                plat = result_type[0].text_content().strip()
+
+    else:
+        # for games, we want to pull the first result with the correct
+        # platform
+        results = doc.find_class('result')
+        for res in results:
+            result_plat = res.find_class('platform')[0].text_content().strip()
+            if result_plat == plat.upper():
+                result = res
+                break
+
+    if not result:
+        return 'No results found.'
+
+    # get the name, release date, and score from the result
+    product_title = result.find_class('product_title')[0]
+    name = product_title.text_content()
+    link = 'http://metacritic.com' + product_title.find('a').attrib['href']
+
+    try:
+        release = result.find_class('release_date')[0]. \
+            find_class('data')[0].text_content()
+
+        # strip extra spaces out of the release date
+        release = re.sub(r'\s{2,}', ' ', release)
+    except IndexError:
+        release = None
+
+    try:
+        score = result.find_class('metascore_w')[0].text_content()
+    except IndexError:
+        score = None
+
+    return '[{}] {} - \x02{}/100\x02, {} - {}'.format(plat.upper(), name, score or 'no score',
+                                                      'release: \x02%s\x02' % release if release else 'unreleased',
+                                                      link)
diff --git a/disabled/minecraft_bukget.py b/disabled/minecraft_bukget.py
new file mode 100644
index 0000000..f336fb4
--- /dev/null
+++ b/disabled/minecraft_bukget.py
@@ -0,0 +1,157 @@
+import time
+import random
+
+from util import hook, http, web, formatting
+
+
+## CONSTANTS
+
+base_url = "http://api.bukget.org/3/"
+
+search_url = base_url + "search/plugin_name/like/{}"
+random_url = base_url + "plugins/bukkit/?start={}&size=1"
+details_url = base_url + "plugins/bukkit/{}"
+
+
+@hook.onload()
+def load_categories():
+    global categories, count_total, count_categories
+    categories = http.get_json("http://api.bukget.org/3/categories")
+
+    count_total = sum([cat["count"] for cat in categories])
+    count_categories = {cat["name"].lower(): int(cat["count"]) for cat in categories}  # dict comps!
+
+
+class BukgetError(Exception):
+    def __init__(self, code, text):
+        self.code = code
+        self.text = text
+
+    def __str__(self):
+        return self.text
+
+
+## DATA FUNCTIONS
+
+def plugin_search(term):
+    """ searches for a plugin with the bukget API and returns the slug """
+    term = term.lower().strip()
+
+    search_term = http.quote_plus(term)
+
+    try:
+        results = http.get_json(search_url.format(search_term))
+    except (http.HTTPError, http.URLError) as e:
+        raise BukgetError(500, "Error Fetching Search Page: {}".format(e))
+
+    if not results:
+        raise BukgetError(404, "No Results Found")
+
+    for result in results:
+        if result["slug"] == term:
+            return result["slug"]
+
+    return results[0]["slug"]
+
+
+def plugin_random():
+    """ gets a random plugin from the bukget API and returns the slug """
+    results = None
+
+    while not results:
+        plugin_number = random.randint(1, count_total)
+        print("trying {}".format(plugin_number))
+        try:
+            results = http.get_json(random_url.format(plugin_number))
+        except (http.HTTPError, http.URLError) as e:
+            raise BukgetError(500, "Error Fetching Search Page: {}".format(e))
+
+    return results[0]["slug"]
+
+
+def plugin_details(slug):
+    """ takes a plugin slug and returns details from the bukget API """
+    slug = slug.lower().strip()
+
+    try:
+        details = http.get_json(details_url.format(slug))
+    except (http.HTTPError, http.URLError) as e:
+        raise BukgetError(500, "Error Fetching Details: {}".format(e))
+    return details
+
+
+## OTHER FUNCTIONS
+
+def format_output(data):
+    """ takes plugin data and returns two strings representing information about that plugin """
+    name = data["plugin_name"]
+    description = formatting.truncate_str(data['description'], 30)
+    url = data['website']
+    authors = data['authors'][0]
+    authors = authors[0] + "\u200b" + authors[1:]
+    stage = data['stage']
+
+    current_version = data['versions'][0]
+
+    last_update = time.strftime('%d %B %Y %H:%M',
+                                time.gmtime(current_version['date']))
+    version_number = data['versions'][0]['version']
+
+    bukkit_versions = ", ".join(current_version['game_versions'])
+    link = web.try_isgd(current_version['link'])
+
+    if description:
+        line_a = "\x02{}\x02, by \x02{}\x02 - {} - ({}) \x02{}".format(name, authors, description, stage, url)
+    else:
+        line_a = "\x02{}\x02, by \x02{}\x02 ({}) \x02{}".format(name, authors, stage, url)
+
+    line_b = "Last release: \x02v{}\x02 for \x02{}\x02 at {} \x02{}\x02".format(version_number, bukkit_versions,
+                                                                                last_update, link)
+
+    return line_a, line_b
+
+
+## HOOK FUNCTIONS
+
+@hook.command(["bukget", "plugin"], threaded=True)
+def bukget(text, reply, message):
+    """bukget <slug/name> - Look up a plugin on dev.bukkit.org"""
+    # get the plugin slug using search
+    try:
+        slug = plugin_search(text)
+    except BukgetError as e:
+        return e
+
+    # get the plugin info using the slug
+    try:
+        data = plugin_details(slug)
+    except BukgetError as e:
+        return e
+
+    # format the final message and send it to IRC
+    line_a, line_b = format_output(data)
+
+    reply(line_a)
+    message(line_b)
+
+
+@hook.command(threaded=True, autohelp=None)
+def randomplugin(reply, message):
+    """randomplugin - Gets a random plugin from dev.bukkit.org"""
+    # get a random plugin slug
+    try:
+        slug = plugin_random()
+    except BukgetError as e:
+        return e
+
+    # get the plugin info using the slug
+    try:
+        data = plugin_details(slug)
+    except BukgetError as e:
+        return e
+
+    # format the final message and send it to IRC
+    line_a, line_b = format_output(data)
+
+    reply(line_a)
+    message(line_b)
\ No newline at end of file
diff --git a/disabled/minecraft_items.py b/disabled/minecraft_items.py
new file mode 100644
index 0000000..bcb596b
--- /dev/null
+++ b/disabled/minecraft_items.py
@@ -0,0 +1,98 @@
+""" plugin by _303 (?)
+"""
+
+import re
+
+from util import hook
+
+
+pattern = re.compile(r'^(?P<count>\d+)x (?P<name>.+?): (?P<ingredients>.*)$')
+
+recipelist = []
+
+
+class Recipe(object):
+    __slots__ = 'output', 'count', 'ingredients', 'line'
+
+    def __init__(self, output, count, ingredients, line):
+        self.output = output
+        self.count = count
+        self.ingredients = ingredients
+        self.line = line
+
+    def __str__(self):
+        return self.line
+
+
+with open("./data/recipes.txt") as f:
+    for line in f.readlines():
+        if line.startswith("//"):
+            continue
+        line = line.strip()
+        match = pattern.match(line)
+        if not match:
+            continue
+        recipelist.append(Recipe(line=line,
+                                 output=match.group("name").lower(),
+                                 ingredients=match.group("ingredients"),
+                                 count=match.group("count")))
+
+ids = []
+
+with open("./data/itemids.txt") as f:
+    for line in f.readlines():
+        if line.startswith("//"):
+            continue
+        parts = line.strip().split()
+        itemid = parts[0]
+        name = " ".join(parts[1:])
+        ids.append((itemid, name))
+
+
+@hook.command(["mcitem", "mcid"], threaded=False)
+def mcitem(inp, reply=None):
+    """mcitem <item/id> -- gets the id from an item or vice versa"""
+    inp = inp.lower().strip()
+
+    if inp == "":
+        reply("error: no input.")
+        return
+
+    results = []
+
+    for item_id, item_name in ids:
+        if inp == item_id:
+            results = ["\x02[{}]\x02 {}".format(item_id, item_name)]
+            break
+        elif inp in item_name.lower():
+            results.append("\x02[{}]\x02 {}".format(item_id, item_name))
+
+    if not results:
+        return "No matches found."
+
+    if len(results) > 12:
+        reply("There are too many options, please narrow your search. ({})".format(str(len(results))))
+        return
+
+    out = ", ".join(results)
+
+    return out
+
+
+@hook.command(["mcrecipe", "mccraft"], threaded=False)
+def mcrecipe(inp, reply=None):
+    """mcrecipe <item> -- gets the crafting recipe for an item"""
+    inp = inp.lower().strip()
+
+    results = [recipe.line for recipe in recipelist
+               if inp in recipe.output]
+
+    if not results:
+        return "No matches found."
+
+    if len(results) > 3:
+        reply("There are too many options, please narrow your search. ({})".format(len(results)))
+        return
+
+    for result in results:
+        reply(result)
diff --git a/disabled/minecraft_ping.py b/disabled/minecraft_ping.py
new file mode 100644
index 0000000..3c59f81
--- /dev/null
+++ b/disabled/minecraft_ping.py
@@ -0,0 +1,232 @@
+import socket
+import struct
+import json
+import traceback
+
+from util import hook
+
+
+try:
+    import DNS
+
+    has_dns = True
+except ImportError:
+    has_dns = False
+
+mc_colors = [('\xa7f', '\x0300'), ('\xa70', '\x0301'), ('\xa71', '\x0302'), ('\xa72', '\x0303'),
+             ('\xa7c', '\x0304'), ('\xa74', '\x0305'), ('\xa75', '\x0306'), ('\xa76', '\x0307'),
+             ('\xa7e', '\x0308'), ('\xa7a', '\x0309'), ('\xa73', '\x0310'), ('\xa7b', '\x0311'),
+             ('\xa71', '\x0312'), ('\xa7d', '\x0313'), ('\xa78', '\x0314'), ('\xa77', '\x0315'),
+             ('\xa7l', '\x02'), ('\xa79', '\x0310'), ('\xa7o', '\t'), ('\xa7m', '\x13'),
+             ('\xa7r', '\x0f'), ('\xa7n', '\x15')]
+
+
+## EXCEPTIONS
+
+
+class PingError(Exception):
+    def __init__(self, text):
+        self.text = text
+
+    def __str__(self):
+        return self.text
+
+
+class ParseError(Exception):
+    def __init__(self, text):
+        self.text = text
+
+    def __str__(self):
+        return self.text
+
+
+## MISC
+
+
+def unpack_varint(s):
+    d = 0
+    i = 0
+    while True:
+        b = ord(s.recv(1))
+        d |= (b & 0x7F) << 7 * i
+        i += 1
+        if not b & 0x80:
+            return d
+
+
+pack_data = lambda d: struct.pack('>b', len(d)) + d
+pack_port = lambda i: struct.pack('>H', i)
+
+## DATA FUNCTIONS
+
+
+def mcping_modern(host, port):
+    """ pings a server using the modern (1.7+) protocol and returns data """
+    try:
+        # connect to the server
+        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
+
+        try:
+            s.connect((host, port))
+        except socket.gaierror:
+            raise PingError("Invalid hostname")
+        except socket.timeout:
+            raise PingError("Request timed out")
+
+        # send handshake + status request
+        s.send(pack_data(b"\x00\x00" + pack_data(host.encode('utf8')) + pack_port(port) + b"\x01"))
+        s.send(pack_data(b"\x00"))
+
+        # read response
+        unpack_varint(s)  # Packet length
+        unpack_varint(s)  # Packet ID
+        l = unpack_varint(s)  # String length
+
+        if not l > 1:
+            raise PingError("Invalid response")
+
+        d = b""
+        while len(d) < l:
+            d += s.recv(1024)
+
+        # Close our socket
+        s.close()
+    except socket.error:
+        raise PingError("Socket Error")
+
+    # Load json and return
+    data = json.loads(d.decode('utf8'))
+    try:
+        version = data["version"]["name"]
+        try:
+            desc = " ".join(data["description"]["text"].split())
+        except TypeError:
+            desc = " ".join(data["description"].split())
+        max_players = data["players"]["max"]
+        online = data["players"]["online"]
+    except Exception as e:
+        # TODO: except Exception is bad
+        traceback.print_exc(e)
+        raise PingError("Unknown Error: {}".format(e))
+
+    output = {
+        "motd": format_colors(desc),
+        "motd_raw": desc,
+        "version": version,
+        "players": online,
+        "players_max": max_players
+    }
+    return output
+
+
+def mcping_legacy(host, port):
+    """ pings a server using the legacy (1.6 and older) protocol and returns data """
+    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
+
+    try:
+        sock.connect((host, port))
+        sock.send('\xfe\x01')
+        response = sock.recv(1)
+    except socket.gaierror:
+        raise PingError("Invalid hostname")
+    except socket.timeout:
+        raise PingError("Request timed out")
+
+    if response[0] != '\xff':
+        raise PingError("Invalid response")
+
+    length = struct.unpack('!h', sock.recv(2))[0]
+    values = sock.recv(length * 2).decode('utf-16be')
+    data = values.split('\x00')  # try to decode data using new format
+    if len(data) == 1:
+        # failed to decode data, server is using old format
+        data = values.split('\xa7')
+        output = {
+            "motd": format_colors(" ".join(data[0].split())),
+            "motd_raw": data[0],
+            "version": None,
+            "players": data[1],
+            "players_max": data[2]
+        }
+    else:
+        # decoded data, server is using new format
+        output = {
+            "motd": format_colors(" ".join(data[3].split())),
+            "motd_raw": data[3],
+            "version": data[2],
+            "players": data[4],
+            "players_max": data[5]
+        }
+    sock.close()
+    return output
+
+
+## FORMATTING/PARSING FUNCTIONS
+
+def check_srv(domain):
+    """ takes a domain and finds minecraft SRV records """
+    DNS.DiscoverNameServers()
+    srv_req = DNS.Request(qtype='srv')
+    srv_result = srv_req.req('_minecraft._tcp.{}'.format(domain))
+
+    for getsrv in srv_result.answers:
+        if getsrv['typename'] == 'SRV':
+            data = [getsrv['data'][2], getsrv['data'][3]]
+            return data
+
+
+def parse_input(inp):
+    """ takes the input from the mcping command and returns the host and port """
+    inp = inp.strip().split(" ")[0]
+    if ":" in inp:
+        # the port is defined in the input string
+        host, port = inp.split(":", 1)
+        try:
+            port = int(port)
+            if port > 65535 or port < 0:
+                raise ParseError("The port '{}' is invalid.".format(port))
+        except ValueError:
+            raise ParseError("The port '{}' is invalid.".format(port))
+        return host, port
+    if has_dns:
+        # the port is not in the input string, but we have PyDNS so look for a SRV record
+        srv_data = check_srv(inp)
+        if srv_data:
+            return str(srv_data[1]), int(srv_data[0])
+    # return default port
+    return inp, 25565
+
+
+def format_colors(motd):
+    for original, replacement in mc_colors:
+        motd = motd.replace(original, replacement)
+    motd = motd.replace("\xa7k", "")
+    return motd
+
+
+def format_output(data):
+    if data["version"]:
+        return "{motd}\x0f - {version}\x0f - {players}/{players_max}" \
+               " players.".format(**data).replace("\n", "\x0f - ")
+    else:
+        return "{motd}\x0f - {players}/{players_max}" \
+               " players.".format(**data).replace("\n", "\x0f - ")
+
+
+@hook.command(["mcping", "mcp"], threaded=True)
+def mcping(inp):
+    """mcping <server>[:port] - Ping a Minecraft server to check status."""
+    try:
+        host, port = parse_input(inp)
+    except ParseError as e:
+        return "Could not parse input ({})".format(e)
+
+    try:
+        data = mcping_modern(host, port)
+    except PingError:
+        try:
+            data = mcping_legacy(host, port)
+        except PingError as e:
+            return "Could not ping server, is it offline? ({})".format(e)
+
+    return format_output(data)
diff --git a/disabled/minecraft_status.py b/disabled/minecraft_status.py
new file mode 100644
index 0000000..cb90dbd
--- /dev/null
+++ b/disabled/minecraft_status.py
@@ -0,0 +1,42 @@
+import json
+
+from util import hook, http
+
+
+green_prefix = "\x02\x0f"
+green_suffix = ": \x033\x02\u2714"
+yellow_prefix = "\x02\x0f"
+yellow_suffix = ": \x037\x02\u26A0"
+red_prefix = "\x02\x0f"
+red_suffix = ": \x034\x02\u2716"
+
+
+@hook.command(["mcs", "mcstatus", "mojang"], threaded=True, autohelp=False)
+def mcstatus():
+    """mcstatus -- Checks the status of various Mojang (the creators of Minecraft) servers."""
+
+    try:
+        result = http.get("http://status.mojang.com/check")
+    except (http.URLError, http.HTTPError) as e:
+        return "Unable to get Minecraft server status: {}".format(e)
+
+    data = json.loads(result)
+
+    # use a loop so we don't have to update it if they add more servers
+    servers = []
+    for server_dict in data:
+        for server, status in server_dict.items():
+            if server == "minecraft.net":
+                server = "MC|Website"
+            elif server.endswith(".mojang.com"):
+                server = "MJ|{}".format(server[:-11].capitalize())
+            elif server.endswith(".minecraft.net"):
+                server = "MC|{}".format(server[:-14].capitalize())
+
+            if status == "green":
+                servers.append("{}{}{}".format(green_prefix, server, green_suffix))
+            elif status == "yellow":
+                servers.append("{}{}{}".format(yellow_prefix, server, yellow_suffix))
+            else:
+                servers.append("{}{}{}".format(red_prefix, server, red_suffix))
+    return "  ".join(servers)
diff --git a/disabled/minecraft_user.py b/disabled/minecraft_user.py
new file mode 100644
index 0000000..0c8d495
--- /dev/null
+++ b/disabled/minecraft_user.py
@@ -0,0 +1,101 @@
+import json
+
+from util import hook, http
+
+
+NAME_URL = "https://account.minecraft.net/buy/frame/checkName/{}"
+PAID_URL = "http://www.minecraft.net/haspaid.jsp"
+
+
+class McuError(Exception):
+    pass
+
+
+def get_status(name):
+    """ takes a name and returns status """
+    try:
+        name_encoded = http.quote_plus(name)
+        response = http.get(NAME_URL.format(name_encoded))
+    except (http.URLError, http.HTTPError) as e:
+        raise McuError("Could not get name status: {}".format(e))
+
+    if "OK" in response:
+        return "free"
+    elif "TAKEN" in response:
+        return "taken"
+    elif "invalid characters" in response:
+        return "invalid"
+
+
+def get_profile(name):
+    profile = {}
+
+    # form the profile request
+    request = {
+        "name": name,
+        "agent": "minecraft"
+    }
+
+    # submit the profile request
+    try:
+        headers = {"Content-Type": "application/json"}
+        r = http.get_json(
+            'https://api.mojang.com/profiles/page/1',
+            post_data=json.dumps(request).encode('utf-8'),
+            headers=headers
+        )
+    except (http.URLError, http.HTTPError) as e:
+        raise McuError("Could not get profile status: {}".format(e))
+
+    user = r["profiles"][0]
+    profile["name"] = user["name"]
+    profile["id"] = user["id"]
+
+    profile["legacy"] = user.get("legacy", False)
+
+    try:
+        response = http.get(PAID_URL, user=name)
+    except (http.URLError, http.HTTPError) as e:
+        raise McuError("Could not get payment status: {}".format(e))
+
+    if "true" in response:
+        profile["paid"] = True
+    else:
+        profile["paid"] = False
+
+    return profile
+
+
+@hook.command(["mcuser", "mcpaid", "haspaid"], threaded=True)
+def mcuser(inp):
+    """mcpaid <username> -- Gets information about the Minecraft user <account>."""
+    user = inp.strip()
+
+    try:
+        # get status of name (does it exist?)
+        name_status = get_status(user)
+    except McuError as e:
+        return e
+
+    if name_status == "taken":
+        try:
+            # get information about user
+            profile = get_profile(user)
+        except McuError as e:
+            return "Error: {}".format(e)
+
+        profile["lt"] = ", legacy" if profile["legacy"] else ""
+
+        if profile["paid"]:
+            return "The account \x02{name}\x02 ({id}{lt}) exists. It is a \x02paid\x02" \
+                   " account.".format(**profile)
+        else:
+            return "The account \x02{name}\x02 ({id}{lt}) exists. It \x034\x02is NOT\x02\x0f a paid" \
+                   " account.".format(**profile)
+    elif name_status == "free":
+        return "The account \x02{}\x02 does not exist.".format(user)
+    elif name_status == "invalid":
+        return "The name \x02{}\x02 contains invalid characters.".format(user)
+    else:
+        # if you see this, panic
+        return "Unknown Error."
\ No newline at end of file
diff --git a/disabled/minecraft_wiki.py b/disabled/minecraft_wiki.py
new file mode 100644
index 0000000..e5419a7
--- /dev/null
+++ b/disabled/minecraft_wiki.py
@@ -0,0 +1,51 @@
+import re
+
+from util import hook, http, formatting
+
+
+api_url = "http://minecraft.gamepedia.com/api.php?action=opensearch"
+mc_url = "http://minecraft.gamepedia.com/"
+
+
+@hook.command(threaded=True)
+def mcwiki(text):
+    """mcwiki <phrase> -- Gets the first paragraph of
+    the Minecraft Wiki article on <phrase>."""
+
+    try:
+        j = http.get_json(api_url, search=text)
+    except (http.HTTPError, http.URLError) as e:
+        return "Error fetching search results: {}".format(e)
+    except ValueError as e:
+        return "Error reading search results: {}".format(e)
+
+    if not j[1]:
+        return "No results found."
+
+    # we remove items with a '/' in the name, because
+    # gamepedia uses sub-pages for different languages
+    # for some stupid reason
+    items = [item for item in j[1] if not "/" in item]
+
+    if items:
+        article_name = items[0].replace(' ', '_').encode('utf8')
+    else:
+        # there are no items without /, just return a / one
+        article_name = j[1][0].replace(' ', '_').encode('utf8')
+
+    url = mc_url + http.quote(article_name, '')
+
+    try:
+        page = http.get_html(url)
+    except (http.HTTPError, http.URLError) as e:
+        return "Error fetching wiki page: {}".format(e)
+
+    for p in page.xpath('//div[@class="mw-content-ltr"]/p'):
+        if p.text_content():
+            summary = " ".join(p.text_content().splitlines())
+            summary = re.sub("\[\d+\]", "", summary)
+            summary = formatting.truncate_str(summary, 200)
+            return "{} :: {}".format(summary, url)
+
+    # this shouldn't happen
+    return "Unknown Error."
diff --git a/disabled/mlia.py b/disabled/mlia.py
new file mode 100644
index 0000000..9f3226f
--- /dev/null
+++ b/disabled/mlia.py
@@ -0,0 +1,34 @@
+# Plugin by Infinity - <https://github.com/infinitylabs/UguuBot>
+
+import random
+
+from util import hook, http
+
+
+mlia_cache = []
+
+
+def refresh_cache():
+    """gets a page of random MLIAs and puts them into a dictionary """
+    url = 'http://mylifeisaverage.com/{}'.format(random.randint(1, 11000))
+    soup = http.get_soup(url)
+
+    for story in soup.find_all('div', {'class': 'story '}):
+        mlia_id = story.find('span', {'class': 'left'}).a.text
+        mlia_text = story.find('div', {'class': 'sc'}).text.strip()
+        mlia_cache.append((mlia_id, mlia_text))
+
+# do an initial refresh of the cache
+refresh_cache()
+
+
+@hook.command(threaded=True, autohelp=False)
+def mlia(reply):
+    """mlia -- Gets a random quote from MyLifeIsAverage.com."""
+    # grab the last item in the mlia cache and remove it
+    mlia_id, text = mlia_cache.pop()
+    # reply with the mlia we grabbed
+    reply('({}) {}'.format(mlia_id, text))
+    # refresh mlia cache if its getting empty
+    if len(mlia_cache) < 3:
+        refresh_cache()
diff --git a/disabled/namegen.py b/disabled/namegen.py
new file mode 100644
index 0000000..e182c7f
--- /dev/null
+++ b/disabled/namegen.py
@@ -0,0 +1,58 @@
+import json
+import os
+
+from util import hook, formatting, textgen
+
+
+def get_generator(_json):
+    data = json.loads(_json)
+    return textgen.TextGenerator(data["templates"],
+                                 data["parts"], default_templates=data["default_templates"])
+
+
+@hook.command(threaded=True, autohelp=False)
+def namegen(input, bot):
+    """namegen [generator] -- Generates some names using the chosen generator.
+    :type bot: core.bot.CloudBot
+    'namegen list' will display a list of all generators."""
+
+    # clean up the input
+    inp = input.text.strip().lower()
+
+    # get a list of available name generators
+    files = os.listdir(os.path.join(bot.data_dir, "name_files"))
+    all_modules = []
+    for i in files:
+        if os.path.splitext(i)[1] == ".json":
+            all_modules.append(os.path.splitext(i)[0])
+    all_modules.sort()
+
+    # command to return a list of all available generators
+    if inp == "list":
+        message = "Available generators: "
+        message += formatting.get_text_list(all_modules, 'and')
+        input.notice(message)
+        return
+
+    if inp:
+        selected_module = inp.split()[0]
+    else:
+        # make some generic fantasy names
+        selected_module = "fantasy"
+
+    # check if the selected module is valid
+    if not selected_module in all_modules:
+        return "Invalid name generator :("
+
+    # load the name generator
+    with open(os.path.join(bot.data_dir, "name_files", "{}.json".format(selected_module))) as f:
+        try:
+            generator = get_generator(f.read())
+        except ValueError as error:
+            return "Unable to read name file: {}".format(error)
+
+    # time to generate some names
+    name_list = generator.generate_strings(10)
+
+    # and finally return the final message :D
+    return "Some names to ponder: {}.".format(formatting.get_text_list(name_list, 'and'))
diff --git a/disabled/newegg.py b/disabled/newegg.py
new file mode 100644
index 0000000..33d72af
--- /dev/null
+++ b/disabled/newegg.py
@@ -0,0 +1,95 @@
+import json
+import re
+
+from util import hook, http, formatting, web
+
+
+## CONSTANTS
+
+ITEM_URL = "http://www.newegg.com/Product/Product.aspx?Item={}"
+
+API_PRODUCT = "http://www.ows.newegg.com/Products.egg/{}/ProductDetails"
+API_SEARCH = "http://www.ows.newegg.com/Search.egg/Advanced"
+
+NEWEGG_RE = (r"(?:(?:www.newegg.com|newegg.com)/Product/Product\.aspx\?Item=)([-_a-zA-Z0-9]+)", re.I)
+
+
+## OTHER FUNCTIONS
+
+def format_item(item, show_url=True):
+    """ takes a newegg API item object and returns a description """
+    title = formatting.truncate_str(item["Title"], 50)
+
+    # format the rating nicely if it exists
+    if not item["ReviewSummary"]["TotalReviews"] == "[]":
+        rating = "Rated {}/5 ({} ratings)".format(item["ReviewSummary"]["Rating"],
+                                                  item["ReviewSummary"]["TotalReviews"][1:-1])
+    else:
+        rating = "No Ratings"
+
+    if not item["FinalPrice"] == item["OriginalPrice"]:
+        price = "{FinalPrice}, was {OriginalPrice}".format(**item)
+    else:
+        price = item["FinalPrice"]
+
+    tags = []
+
+    if item["Instock"]:
+        tags.append("\x02Stock Available\x02")
+    else:
+        tags.append("\x02Out Of Stock\x02")
+
+    if item["FreeShippingFlag"]:
+        tags.append("\x02Free Shipping\x02")
+
+    if item["IsFeaturedItem"]:
+        tags.append("\x02Featured\x02")
+
+    if item["IsShellShockerItem"]:
+        tags.append("\x02SHELL SHOCKER\u00AE\x02")
+
+    # join all the tags together in a comma separated string ("tag1, tag2, tag3")
+    tag_text = ", ".join(tags)
+
+    if show_url:
+        # create the item URL and shorten it
+        url = web.try_isgd(ITEM_URL.format(item["NeweggItemNumber"]))
+        return "\x02{}\x02 ({}) - {} - {} - {}".format(title, price, rating,
+                                                       tag_text, url)
+    else:
+        return "\x02{}\x02 ({}) - {} - {}".format(title, price, rating,
+                                                  tag_text)
+
+
+## HOOK FUNCTIONS
+
+@hook.regex(*NEWEGG_RE, threaded=True)
+def newegg_url(match):
+    item_id = match.group(1)
+    item = http.get_json(API_PRODUCT.format(item_id))
+    return format_item(item, show_url=False)
+
+
+@hook.command(threaded=True)
+def newegg(inp):
+    """newegg <item name> -- Searches newegg.com for <item name>"""
+
+    # form the search request
+    request = {
+        "Keyword": inp,
+        "Sort": "FEATURED"
+    }
+
+    # submit the search request
+    r = http.get_json(
+        'http://www.ows.newegg.com/Search.egg/Advanced',
+        post_data=json.dumps(request).encode('utf-8')
+    )
+
+    # get the first result
+    if r["ProductListItems"]:
+        return format_item(r["ProductListItems"][0])
+    else:
+        return "No results found."
+
+
diff --git a/disabled/newgrounds.py b/disabled/newgrounds.py
new file mode 100644
index 0000000..e0d96c1
--- /dev/null
+++ b/disabled/newgrounds.py
@@ -0,0 +1,60 @@
+import re
+
+from util import hook, http
+
+
+newgrounds_re = (r'(.*:)//(www.newgrounds.com|newgrounds.com)(:[0-9]+)?(.*)', re.I)
+valid = set('0123456789')
+
+
+def test(s):
+    return set(s) <= valid
+
+
+@hook.regex(*newgrounds_re, threaded=True)
+def newgrounds_url(match):
+    location = match.group(4).split("/")[-1]
+    if not test(location):
+        print("Not a valid Newgrounds portal ID. Example: http://www.newgrounds.com/portal/view/593993")
+        return None
+    soup = http.get_soup("http://www.newgrounds.com/portal/view/" + location)
+
+    title = "\x02{}\x02".format(soup.find('title').text)
+
+    # get author
+    try:
+        author_info = soup.find('ul', {'class': 'authorlinks'}).find('img')['alt']
+        author = " - \x02{}\x02".format(author_info)
+    except:
+        author = ""
+
+    # get rating
+    try:
+        rating_info = soup.find('dd', {'class': 'star-variable'})['title'].split("Stars &ndash;")[0].strip()
+        rating = " - rated \x02{}\x02/\x025.0\x02".format(rating_info)
+    except:
+        rating = ""
+
+    # get amount of ratings
+    try:
+        ratings_info = soup.find('dd', {'class': 'star-variable'})['title'].split("Stars"
+                                                                                  " &ndsh;")[1].replace("Votes",
+                                                                                                        "").strip()
+        numofratings = " ({})".format(ratings_info)
+    except:
+        numofratings = ""
+
+    # get amount of views
+    try:
+        views_info = soup.find('dl', {'class': 'contentdata'}).findAll('dd')[1].find('strong').text
+        views = " - \x02{}\x02 views".format(views_info)
+    except:
+        views = ""
+
+    # get upload data
+    try:
+        date = "on \x02{}\x02".format(soup.find('dl', {'class': 'sidestats'}).find('dd').text)
+    except:
+        date = ""
+
+    return title + rating + numofratings + views + author + date
diff --git a/disabled/notes.py b/disabled/notes.py
new file mode 100644
index 0000000..9364b89
--- /dev/null
+++ b/disabled/notes.py
@@ -0,0 +1,189 @@
+import re
+
+from util import hook
+
+db_ready = False
+
+
+def clean_sql(sql):
+    return re.sub(r'\s+', " ", sql).strip()
+
+
+def db_init(db):
+    global db_ready
+    if db_ready:
+        return
+
+    exists = db.execute("""
+      select exists (
+        select * from sqlite_master where type = "table" and name = "todos"
+      )
+    """).fetchone()[0] == 1
+
+    if not exists:
+        db.execute(clean_sql("""
+           create virtual table todos using fts4(
+                user,
+                text,
+                added,
+                tokenize=porter
+           )"""))
+
+    db.commit()
+
+    db_ready = True
+
+
+def db_getall(db, nick, limit=-1):
+    return db.execute("""
+        select added, text
+            from todos
+            where lower(user) = lower(?)
+            order by added desc
+            limit ?
+
+        """, (nick, limit))
+
+
+def db_get(db, nick, note_id):
+    return db.execute("""
+        select added, text from todos
+        where lower(user) = lower(?)
+        order by added desc
+        limit 1
+        offset ?
+    """, (nick, note_id)).fetchone()
+
+
+def db_del(db, nick, limit='all'):
+    row = db.execute("""
+        delete from todos
+        where rowid in (
+          select rowid from todos
+          where lower(user) = lower(?)
+          order by added desc
+          limit ?
+          offset ?)
+     """, (nick,
+           -1 if limit == 'all' else 1,
+           0 if limit == 'all' else limit))
+    db.commit()
+    return row
+
+
+def db_add(db, nick, text):
+    db.execute("""
+        insert into todos (user, text, added)
+        values (?, ?, CURRENT_TIMESTAMP)
+    """, (nick, text))
+    db.commit()
+
+
+def db_search(db, nick, query):
+    return db.execute("""
+        select added, text
+        from todos
+        where todos match ?
+        and lower(user) = lower(?)
+        order by added desc
+    """, (query, nick))
+
+
+@hook.command(["note", "notes"])
+def note(inp, nick, db, notice):
+    """note(s) <add|del|list|search> args -- Manipulates your list of notes."""
+
+    db_init(db)
+
+    parts = inp.split()
+    cmd = parts[0].lower()
+
+    args = parts[1:]
+
+    # code to allow users to access each others factoids and a copy of help
+    # ".note (add|del|list|search) [@user] args -- Manipulates your list of todos."
+    #if len(args) and args[0].startswith("@"):
+    #    nick = args[0][1:]
+    #    args = args[1:]
+
+    if cmd == 'add':
+        if not len(args):
+            return "no text"
+
+        text = " ".join(args)
+
+        db_add(db, nick, text)
+
+        notice("Note added!")
+        return
+    elif cmd == 'get':
+        if len(args):
+            try:
+                index = int(args[0])
+            except ValueError:
+                notice("Invalid number format.")
+                return
+        else:
+            index = 0
+
+        row = db_get(db, nick, index)
+
+        if not row:
+            notice("No such entry.")
+            return
+        notice("[{}]: {}: {}".format(index, row[0], row[1]))
+    elif cmd == 'del' or cmd == 'delete' or cmd == 'remove':
+        if not len(args):
+            return "error"
+
+        if args[0] == 'all':
+            index = 'all'
+        else:
+            try:
+                index = int(args[0])
+            except ValueError:
+                notice("Invalid number.")
+                return
+
+        rows = db_del(db, nick, index)
+
+        notice("Deleted {} entries".format(rows.rowcount))
+    elif cmd == 'list':
+        limit = -1
+
+        if len(args):
+            try:
+                limit = int(args[0])
+                limit = max(-1, limit)
+            except ValueError:
+                notice("Invalid number.")
+                return
+
+        rows = db_getall(db, nick, limit)
+
+        found = False
+
+        for (index, row) in enumerate(rows):
+            notice("[{}]: {}: {}".format(index, row[0], row[1]))
+            found = True
+
+        if not found:
+            notice("{} has no entries.".format(nick))
+    elif cmd == 'search':
+        if not len(args):
+            notice("No search query given!")
+            return
+        query = " ".join(args)
+        rows = db_search(db, nick, query)
+
+        found = False
+
+        for (index, row) in enumerate(rows):
+            notice("[{}]: {}: {}".format(index, row[0], row[1]))
+            found = True
+
+        if not found:
+            notice("{} has no matching entries for: {}".format(nick, query))
+
+    else:
+        notice("Unknown command: {}".format(cmd))
diff --git a/disabled/op.py b/disabled/op.py
new file mode 100644
index 0000000..df1f887
--- /dev/null
+++ b/disabled/op.py
@@ -0,0 +1,179 @@
+from util import hook
+
+
+def mode_cmd(mode, text, inp, chan, conn, notice):
+    """ generic mode setting function """
+    split = inp.split(" ")
+    if split[0].startswith("#"):
+        channel = split[0]
+        target = split[1]
+        notice("Attempting to {} {} in {}...".format(text, target, channel))
+        conn.send("MODE {} {} {}".format(channel, mode, target))
+    else:
+        channel = chan
+        target = split[0]
+        notice("Attempting to {} {} in {}...".format(text, target, channel))
+        conn.send("MODE {} {} {}".format(channel, mode, target))
+
+
+def mode_cmd_no_target(mode, text, inp, chan, conn, notice):
+    """ generic mode setting function without a target"""
+    split = inp.split(" ")
+    if split[0].startswith("#"):
+        channel = split[0]
+        notice("Attempting to {} {}...".format(text, channel))
+        conn.send("MODE {} {}".format(channel, mode))
+    else:
+        channel = chan
+        notice("Attempting to {} {}...".format(text, channel))
+        conn.send("MODE {} {}".format(channel, mode))
+
+
+@hook.command(permissions=["op_ban", "op"])
+def ban(inp, conn=None, chan=None, notice=None):
+    """ban [channel] <user> -- Makes the bot ban <user> in [channel].
+    If [channel] is blank the bot will ban <user> in
+    the channel the command was used in."""
+    mode_cmd("+b", "ban", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_ban", "op"])
+def unban(inp, conn=None, chan=None, notice=None):
+    """unban [channel] <user> -- Makes the bot unban <user> in [channel].
+    If [channel] is blank the bot will unban <user> in
+    the channel the command was used in."""
+    mode_cmd("-b", "unban", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_quiet", "op"])
+def quiet(inp, conn=None, chan=None, notice=None):
+    """quiet [channel] <user> -- Makes the bot quiet <user> in [channel].
+    If [channel] is blank the bot will quiet <user> in
+    the channel the command was used in."""
+    mode_cmd("+q", "quiet", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_quiet", "op"])
+def unquiet(inp, conn=None, chan=None, notice=None):
+    """unquiet [channel] <user> -- Makes the bot unquiet <user> in [channel].
+    If [channel] is blank the bot will unquiet <user> in
+    the channel the command was used in."""
+    mode_cmd("-q", "unquiet", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_voice", "op"])
+def voice(inp, conn=None, chan=None, notice=None):
+    """voice [channel] <user> -- Makes the bot voice <user> in [channel].
+    If [channel] is blank the bot will voice <user> in
+    the channel the command was used in."""
+    mode_cmd("+v", "voice", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_voice", "op"])
+def devoice(inp, conn=None, chan=None, notice=None):
+    """devoice [channel] <user> -- Makes the bot devoice <user> in [channel].
+    If [channel] is blank the bot will devoice <user> in
+    the channel the command was used in."""
+    mode_cmd("-v", "devoice", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_op", "op"])
+def op(inp, conn=None, chan=None, notice=None):
+    """op [channel] <user> -- Makes the bot op <user> in [channel].
+    If [channel] is blank the bot will op <user> in
+    the channel the command was used in."""
+    mode_cmd("+o", "op", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_op", "op"])
+def deop(inp, conn=None, chan=None, notice=None):
+    """deop [channel] <user> -- Makes the bot deop <user> in [channel].
+    If [channel] is blank the bot will deop <user> in
+    the channel the command was used in."""
+    mode_cmd("-o", "deop", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_topic", "op"])
+def topic(inp, conn=None, chan=None):
+    """topic [channel] <topic> -- Change the topic of a channel."""
+    split = inp.split(" ")
+    if split[0].startswith("#"):
+        message = " ".join(split[1:])
+        chan = split[0]
+    else:
+        message = " ".join(split)
+    conn.send("TOPIC {} :{}".format(chan, message))
+
+
+@hook.command(permissions=["op_kick", "op"])
+def kick(inp, chan=None, conn=None, notice=None):
+    """kick [channel] <user> [reason] -- Makes the bot kick <user> in [channel]
+    If [channel] is blank the bot will kick the <user> in
+    the channel the command was used in."""
+    split = inp.split(" ")
+
+    if split[0].startswith("#"):
+        channel = split[0]
+        target = split[1]
+        if len(split) > 2:
+            reason = " ".join(split[2:])
+            out = "KICK {} {}: {}".format(channel, target, reason)
+        else:
+            out = "KICK {} {}".format(channel, target)
+    else:
+        channel = chan
+        target = split[0]
+        if len(split) > 1:
+            reason = " ".join(split[1:])
+            out = "KICK {} {} :{}".format(channel, target, reason)
+        else:
+            out = "KICK {} {}".format(channel, target)
+
+    notice("Attempting to kick {} from {}...".format(target, channel))
+    conn.send(out)
+
+
+@hook.command(permissions=["op_rem", "op"])
+def remove(inp, chan=None, conn=None):
+    """remove [channel] [user] -- Force a user to part from a channel."""
+    split = inp.split(" ")
+    if split[0].startswith("#"):
+        message = " ".join(split[1:])
+        chan = split[0]
+        out = "REMOVE {} :{}".format(chan, message)
+    else:
+        message = " ".join(split)
+        out = "REMOVE {} :{}".format(chan, message)
+    conn.send(out)
+
+
+@hook.command(permissions=["op_mute", "op"], autohelp=False)
+def mute(inp, conn=None, chan=None, notice=None):
+    """mute [channel] -- Makes the bot mute a channel..
+    If [channel] is blank the bot will mute
+    the channel the command was used in."""
+    mode_cmd_no_target("+m", "mute", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_mute", "op"], autohelp=False)
+def unmute(inp, conn=None, chan=None, notice=None):
+    """mute [channel] -- Makes the bot mute a channel..
+    If [channel] is blank the bot will mute
+    the channel the command was used in."""
+    mode_cmd_no_target("-m", "unmute", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_lock", "op"], autohelp=False)
+def lock(inp, conn=None, chan=None, notice=None):
+    """lock [channel] -- Makes the bot lock a channel.
+    If [channel] is blank the bot will mute
+    the channel the command was used in."""
+    mode_cmd_no_target("+i", "lock", inp, chan, conn, notice)
+
+
+@hook.command(permissions=["op_lock", "op"], autohelp=False)
+def unlock(inp, conn=None, chan=None, notice=None):
+    """unlock [channel] -- Makes the bot unlock a channel..
+    If [channel] is blank the bot will mute
+    the channel the command was used in."""
+    mode_cmd_no_target("-i", "unlock", inp, chan, conn, notice)
diff --git a/disabled/osrc.py b/disabled/osrc.py
new file mode 100644
index 0000000..3dcb0b5
--- /dev/null
+++ b/disabled/osrc.py
@@ -0,0 +1,27 @@
+from util import hook, http, web
+
+
+user_url = "http://osrc.dfm.io/{}"
+
+
+@hook.command
+def osrc(inp):
+    """osrc <github user> -- Gets an Open Source Report Card for <github user>"""
+
+    user_nick = inp.strip()
+    url = user_url.format(user_nick)
+
+    try:
+        soup = http.get_soup(url)
+    except (http.HTTPError, http.URLError):
+        return "Couldn't find any stats for this user."
+
+    report = soup.find("div", {"id": "description"}).find("p").get_text()
+
+    # Split and join to remove all the excess whitespace, slice the
+    # string to remove the trailing full stop.
+    report = " ".join(report.split())[:-1]
+
+    short_url = web.try_isgd(url)
+
+    return "{} - {}".format(report, short_url)
diff --git a/disabled/pagecheck.py b/disabled/pagecheck.py
new file mode 100644
index 0000000..3b6946c
--- /dev/null
+++ b/disabled/pagecheck.py
@@ -0,0 +1,48 @@
+import urllib.parse
+
+from util import hook, http, urlnorm
+
+
+@hook.command
+def down(inp):
+    """down <url> -- Checks if the site at <url> is up or down.
+    :type inp: str
+    """
+
+    if not inp.startswith("http://"):
+        inp = 'http://' + inp
+
+    inp = 'http://' + urllib.parse.urlparse(inp).netloc
+
+    try:
+        http.get(inp, get_method='HEAD')
+        return '{} seems to be up'.format(inp)
+    except http.URLError:
+        return '{} seems to be down'.format(inp)
+
+
+@hook.command
+def isup(inp):
+    """isup -- uses isup.me to see if a site is up or not
+    :type inp: str
+    """
+
+    # slightly overcomplicated, esoteric URL parsing
+    scheme, auth, path, query, fragment = urllib.parse.urlsplit(inp.strip())
+
+    domain = auth or path
+    url = urlnorm.normalize(domain, assume_scheme="http")
+
+    try:
+        soup = http.get_soup('http://isup.me/' + domain)
+    except http.HTTPError:
+        return "Failed to get status."
+
+    content = soup.find('div').text.strip()
+
+    if "not just you" in content:
+        return "It's not just you. {} looks \x02\x034down\x02\x0f from here!".format(url)
+    elif "is up" in content:
+        return "It's just you. {} is \x02\x033up\x02\x0f.".format(url)
+    else:
+        return "Huh? That doesn't look like a site on the interweb."
diff --git a/disabled/password.py b/disabled/password.py
new file mode 100644
index 0000000..5e79d92
--- /dev/null
+++ b/disabled/password.py
@@ -0,0 +1,75 @@
+import string
+
+try:
+    from Crypto.Random import random
+except ImportError:
+    # Just use the regular random module, not the strong one
+    import random
+
+from util import hook
+
+with open("data/password_words.txt") as f:
+    common_words = [line.strip() for line in f.readlines()]
+
+
+@hook.command(autohelp=False)
+def password(text, notice):
+    """password <length> [types] -- Generates a password of <length> (default 10).
+    [types] can include 'alpha', 'no caps', 'numeric', 'symbols' or any combination of the inp, eg. 'numbers symbols'"""
+    okay = []
+
+    # find the length needed for the password
+    numb = text.split(" ")
+
+    try:
+        length = int(numb[0])
+    except ValueError:
+        length = 10
+
+    # add alpha characters
+    if "alpha" in text or "letter" in text:
+        okay = okay + list(string.ascii_lowercase)
+        #adds capital characters if not told not to
+        if "no caps" not in text:
+            okay = okay + list(string.ascii_uppercase)
+
+    # add numbers
+    if "numeric" in text or "number" in text:
+        okay = okay + [str(x) for x in range(0, 10)]
+
+    # add symbols
+    if "symbol" in text:
+        sym = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '=', '_', '+', '[', ']', '{', '}', '\\', '|', ';',
+               ':', "'", '.', '>', ',', '<', '/', '?', '`', '~', '"']
+        okay += okay + sym
+
+    # defaults to lowercase alpha password if the okay list is empty
+    if not okay:
+        okay = okay + list(string.ascii_lowercase)
+
+    pw = ""
+
+    # generates password
+    for x in range(length):
+        pw = pw + random.choice(okay)
+
+    notice(pw)
+
+
+@hook.command(["rpass", "rpassword", "readablepassword"], autohelp=False)
+def readable_password(text, notice):
+    """rpass [length]  -- Generates an easy to remember password with [length] (default 4) commonly used words."""
+    if text:
+        try:
+            length = int(text)
+        except ValueError:
+            notice("Invalid input '{}'".format(text))
+            return
+    else:
+        length = 4
+    words = []
+    # generate password
+    for x in range(length):
+        words.append(random.choice(common_words))
+
+    notice("Your password is '{}'. Feel free to remove the spaces when using it.".format(" ".join(words)))
diff --git a/disabled/ping.py b/disabled/ping.py
new file mode 100644
index 0000000..1ccfce1
--- /dev/null
+++ b/disabled/ping.py
@@ -0,0 +1,44 @@
+# ping plugin by neersighted
+import subprocess
+import re
+import os
+
+from util import hook
+
+ping_regex = re.compile(r"(\d+.\d+)/(\d+.\d+)/(\d+.\d+)/(\d+.\d+)")
+
+
+@hook.command
+def ping(inp, reply=None):
+    """ping <host> [count] -- Pings <host> [count] times."""
+
+    if os.name == "nt":
+        return "Sorry, this command is not supported on Windows systems."
+        # TODO: Rewrite this entire command to work on Windows, somehow
+
+    args = inp.split(' ')
+    host = args[0]
+
+    # check for a second argument and set the ping count
+    if len(args) > 1:
+        count = int(args[1])
+        if count > 20:
+            count = 20
+    else:
+        count = 5
+
+    count = str(count)
+
+    # I suck at regex, but this is causing issues, and I'm just going to remove it
+    # I assume it's no longer needed with the way we run the process
+    # host = re.sub(r'([^\s\w\.])+', '', host)
+
+    reply("Attempting to ping {} {} times...".format(host, count))
+
+    pingcmd = subprocess.check_output(["ping", "-c", count, host]).decode("utf-8")
+    if "request timed out" in pingcmd or "unknown host" in pingcmd:
+        return "error: could not ping host"
+    else:
+        m = re.search(ping_regex, pingcmd)
+        return "min: %sms, max: %sms, average: %sms, range: %sms, count: %s" \
+               % (m.group(1), m.group(3), m.group(2), m.group(4), count)
diff --git a/disabled/plpaste.py b/disabled/plpaste.py
new file mode 100644
index 0000000..a5bdadb
--- /dev/null
+++ b/disabled/plpaste.py
@@ -0,0 +1,20 @@
+from os import listdir
+
+from util import hook, web
+
+
+@hook.command(permissions=["adminonly"])
+def plpaste(text, bot):
+    """
+    :type text: str
+    :type bot: core.bot.CloudBot
+    """
+    if text in bot.plugin_manager.commands:
+        file_path = bot.plugin_manager.commands[text].module.file_path
+        with open(file_path) as f:
+            return web.haste(f.read(), ext='py')
+    elif text + ".py" in listdir('modules/'):
+        with open('modules/{}.py'.format(text)) as f:
+            return web.haste(f.read(), ext='py')
+    else:
+        return "Could not find specified plugin."
diff --git a/disabled/potato.py b/disabled/potato.py
new file mode 100644
index 0000000..9987e18
--- /dev/null
+++ b/disabled/potato.py
@@ -0,0 +1,56 @@
+# coding=utf-8
+import re
+import random
+
+from util import hook
+
+
+potatoes = ['AC Belmont', 'AC Blue Pride', 'AC Brador', 'AC Chaleur', 'AC Domino', 'AC Dubuc', 'AC Glacier Chip',
+            'AC Maple Gold', 'AC Novachip', 'AC Peregrine Red', 'AC Ptarmigan', 'AC Red Island', 'AC Saguenor',
+            'AC Stampede Russet', 'AC Sunbury', 'Abeille', 'Abnaki', 'Acadia', 'Acadia Russet', 'Accent',
+            'Adirondack Blue', 'Adirondack Red', 'Adora', 'Agria', 'All Blue', 'All Red', 'Alpha', 'Alta Russet',
+            'Alturas Russet', 'Amandine', 'Amisk', 'Andover', 'Anoka', 'Anson', 'Aquilon', 'Arran Consul', 'Asterix',
+            'Atlantic', 'Austrian Crescent', 'Avalanche', 'Banana', 'Bannock Russet', 'Batoche', 'BeRus',
+            'Belle De Fonteney', 'Belleisle', 'Bintje', 'Blossom', 'Blue Christie', 'Blue Mac', 'Brigus',
+            'Brise du Nord', 'Butte', 'Butterfinger', 'Caesar', 'CalWhite', 'CalRed', 'Caribe', 'Carlingford',
+            'Carlton', 'Carola', 'Cascade', 'Castile', 'Centennial Russet', 'Century Russet', 'Charlotte', 'Cherie',
+            'Cherokee', 'Cherry Red', 'Chieftain', 'Chipeta', 'Coastal Russet', 'Colorado Rose', 'Concurrent',
+            'Conestoga', 'Cowhorn', 'Crestone Russet', 'Crispin', 'Cupids', 'Daisy Gold', 'Dakota Pearl', 'Defender',
+            'Delikat', 'Denali', 'Desiree', 'Divina', 'Dundrod', 'Durango Red', 'Early Rose', 'Elba', 'Envol',
+            'Epicure', 'Eramosa', 'Estima', 'Eva', 'Fabula', 'Fambo', 'Fremont Russet', 'French Fingerling',
+            'Frontier Russet', 'Fundy', 'Garnet Chile', 'Gem Russet', 'GemStar Russet', 'Gemchip', 'German Butterball',
+            'Gigant', 'Goldrush', 'Granola', 'Green Mountain', 'Haida', 'Hertha', 'Hilite Russet', 'Huckleberry',
+            'Hunter', 'Huron', 'IdaRose', 'Innovator', 'Irish Cobbler', 'Island Sunshine', 'Ivory Crisp',
+            'Jacqueline Lee', 'Jemseg', 'Kanona', 'Katahdin', 'Kennebec', "Kerr's Pink", 'Keswick', 'Keuka Gold',
+            'Keystone Russet', 'King Edward VII', 'Kipfel', 'Klamath Russet', 'Krantz', 'LaRatte', 'Lady Rosetta',
+            'Latona', 'Lemhi Russet', 'Liberator', 'Lili', 'MaineChip', 'Marfona', 'Maris Bard', 'Maris Piper',
+            'Matilda', 'Mazama', 'McIntyre', 'Michigan Purple', 'Millenium Russet', 'Mirton Pearl', 'Modoc', 'Mondial',
+            'Monona', 'Morene', 'Morning Gold', 'Mouraska', 'Navan', 'Nicola', 'Nipigon', 'Niska', 'Nooksack',
+            'NorValley', 'Norchip', 'Nordonna', 'Norgold Russet', 'Norking Russet', 'Norland', 'Norwis', 'Obelix',
+            'Ozette', 'Peanut', 'Penta', 'Peribonka', 'Peruvian Purple', 'Pike', 'Pink Pearl', 'Prospect', 'Pungo',
+            'Purple Majesty', 'Purple Viking', 'Ranger Russet', 'Reba', 'Red Cloud', 'Red Gold', 'Red La Soda',
+            'Red Pontiac', 'Red Ruby', 'Red Thumb', 'Redsen', 'Rocket', 'Rose Finn Apple', 'Rose Gold', 'Roselys',
+            'Rote Erstling', 'Ruby Crescent', 'Russet Burbank', 'Russet Legend', 'Russet Norkotah', 'Russet Nugget',
+            'Russian Banana', 'Saginaw Gold', 'Sangre', 'Sant', 'Satina', 'Saxon', 'Sebago', 'Shepody', 'Sierra',
+            'Silverton Russet', 'Simcoe', 'Snowden', 'Spunta', "St. John's", 'Summit Russet', 'Sunrise', 'Superior',
+            'Symfonia', 'Tolaas', 'Trent', 'True Blue', 'Ulla', 'Umatilla Russet', 'Valisa', 'Van Gogh', 'Viking',
+            'Wallowa Russet', 'Warba', 'Western Russet', 'White Rose', 'Willamette', 'Winema', 'Yellow Finn',
+            'Yukon Gold']
+
+
+@hook.command
+def potato(inp, action=None):
+    """potato <user> - Makes <user> a tasty little potato."""
+    inp = inp.strip()
+
+    if not re.match("^[A-Za-z0-9_|.-\]\[]*$", inp.lower()):
+        return "I cant make a tasty potato for that user!"
+
+    potato_type = random.choice(potatoes)
+    size = random.choice(['small', 'little', 'mid-sized', 'medium-sized', 'large', 'gigantic'])
+    flavor = random.choice(['tasty', 'delectable', 'delicious', 'yummy', 'toothsome', 'scrumptious', 'luscious'])
+    method = random.choice(['bakes', 'fries', 'boils', 'roasts'])
+    side_dish = random.choice(['side salad', 'dollop of sour cream', 'piece of chicken', 'bowl of shredded bacon'])
+
+    action("{} a {} {} {} potato for {} and serves it with a small {}!".format(method, flavor, size, potato_type, inp,
+                                                                               side_dish))
diff --git a/disabled/prefixes.py b/disabled/prefixes.py
new file mode 100644
index 0000000..ce575fd
--- /dev/null
+++ b/disabled/prefixes.py
@@ -0,0 +1,83 @@
+import re
+
+from sqlalchemy import Table, Column, String, UniqueConstraint
+
+from core import main
+
+from util import hook, botvars
+
+table = Table(
+    "prefixes",
+    botvars.metadata,
+    Column("connection", String),
+    Column("channel", String),
+    Column("prefix", String),
+    UniqueConstraint("connection", "channel", "prefix")
+)
+
+
+@hook.onload()
+def load_command_re(db):
+    """
+    :type db: sqlalchemy.orm.Session
+    """
+    global chan_re
+    channel_prefixes = {}
+    for row in db.execute(table.select()):
+        connection = row["connection"]
+        channel = row["channel"]
+        prefix = row["prefix"]
+        key = (connection, channel)
+        if key in channel_prefixes:
+            channel_prefixes[key].append(re.escape(prefix))
+        else:
+            channel_prefixes[key] = [re.escape(prefix)]
+
+    chan_re = {}
+    for key, prefixes in channel_prefixes.items():
+        command_re = r"([{}])(\w+)(?:$|\s+)(.*)".format("".join(prefixes))
+        chan_re[key] = re.compile(command_re)
+
+
+@hook.command(permissions=["botcontrol"])
+def addprefix(text, conn, chan, db):
+    """delprefix <prefix> - Adds a command prefix <prefix> to the current channel
+    :type text: str
+    :type chan: str
+    :type db: sqlalchemy.orm.Session
+    """
+    print("Adding prefix {} to {}".format(text, chan))
+    db.execute(table.insert().values(connection=conn.name, channel=chan, prefix=text))
+    db.commit()
+    load_command_re(db)
+    return "Added command prefix {} to {}".format(text, chan)
+
+
+@hook.command(permissions=["botcontrol"])
+def delprefix(text, chan, db):
+    """delprefix <prefix> - Removes command prefix <prefix> from the current channel
+    :type text: str
+    :type chan: str
+    :type db: sqlalchemy.orm.Session
+    """
+    print("Removing prefix {} from {}".format(text, chan))
+    db.execute(table.delete().where(table.c.channel == chan).where(table.c.prefix == text))
+    db.commit()
+    load_command_re(db)
+    return "Removed command prefix {} from {}".format(text, chan)
+
+
+@hook.event("PRIVMSG", threaded=False)
+def run_extra_prefix(input, bot, conn, chan, lastparam):
+    key = (conn.name, chan)
+    if key in chan_re:
+        match = chan_re[key].match(lastparam)
+        if match:
+            command = match.group(2).lower()
+            if command in bot.plugin_manager.commands:
+                plugin = bot.plugin_manager.commands[command]
+                # this input is a one-use input, so we can just modify it and send it to the plugin
+                input.trigger = command
+                input.text = match.group(3).strip()
+                input.inp = input.text  # re-set inp as well, for compatibilty
+                yield from main.dispatch(bot, input, plugin)
diff --git a/disabled/python.py b/disabled/python.py
new file mode 100644
index 0000000..5cdc524
--- /dev/null
+++ b/disabled/python.py
@@ -0,0 +1,9 @@
+from util import hook
+from util.pyexec import eval_py
+
+
+@hook.command
+def python(inp):
+    """python <prog> -- Executes <prog> as Python code."""
+
+    return eval_py(inp)
diff --git a/disabled/qrcode.py b/disabled/qrcode.py
new file mode 100644
index 0000000..9d481e0
--- /dev/null
+++ b/disabled/qrcode.py
@@ -0,0 +1,18 @@
+# Plugin by https://github.com/Mu5tank05
+from util import hook, web, http
+
+
+@hook.command('qr')
+@hook.command
+def qrcode(inp):
+    """qrcode [link] returns a link for a QR code."""
+
+    args = {
+        "cht": "qr",  # chart type (QR)
+        "chs": "200x200",  # dimensions
+        "chl": inp  # data
+    }
+
+    link = http.prepare_url("http://chart.googleapis.com/chart", args)
+
+    return web.try_isgd(link)
diff --git a/disabled/quote.py b/disabled/quote.py
new file mode 100644
index 0000000..6beefc5
--- /dev/null
+++ b/disabled/quote.py
@@ -0,0 +1,149 @@
+import random
+import re
+import time
+
+from util import hook
+
+
+def format_quote(q, num, n_quotes):
+    """Returns a formatted string of a quote"""
+    ctime, nick, msg = q
+    return "[{}/{}] <{}> {}".format(num, n_quotes,
+                                    nick, msg)
+
+
+def create_table_if_not_exists(db):
+    """Creates an empty quote table if one does not already exist"""
+    db.execute("create table if not exists quote"
+               "(chan, nick, add_nick, msg, time real, deleted default 0, "
+               "primary key (chan, nick, msg))")
+    db.commit()
+
+
+def add_quote(db, chan, nick, add_nick, msg):
+    """Adds a quote to a nick, returns message string"""
+    try:
+        db.execute('''INSERT OR FAIL INTO quote
+                      (chan, nick, add_nick, msg, time)
+                      VALUES(?,?,?,?,?)''',
+                   (chan, nick, add_nick, msg, time.time()))
+        db.commit()
+    except db.IntegrityError:
+        return "Message already stored, doing nothing."
+    return "Quote added."
+
+
+def del_quote(db, chan, nick, add_nick, msg):
+    """Deletes a quote from a nick"""
+    db.execute('''UPDATE quote SET deleted = 1 WHERE
+                  chan=? AND lower(nick)=lower(?) AND msg=msg''')
+    db.commit()
+
+
+def get_quote_num(num, count, name):
+    """Returns the quote number to fetch from the DB"""
+    if num:  # Make sure num is a number if it isn't false
+        num = int(num)
+    if count == 0:  # Error on no quotes
+        raise Exception("No quotes found for {}.".format(name))
+    if num and num < 0:  # Count back if possible
+        num = count + num + 1 if num + count > -1 else count + 1
+    if num and num > count:  # If there are not enough quotes, raise an error
+        raise Exception("I only have {} quote{} for {}.".format(count, ('s', '')[count == 1], name))
+    if num and num == 0:  # If the number is zero, set it to one
+        num = 1
+    if not num:  # If a number is not given, select a random one
+        num = random.randint(1, count)
+    return num
+
+
+def get_quote_by_nick(db, nick, num=False):
+    """Returns a formatted quote from a nick, random or selected by number"""
+    count = db.execute('''SELECT COUNT(*) FROM quote WHERE deleted != 1
+                          AND lower(nick) = lower(?)''', [nick]).fetchall()[0][0]
+
+    try:
+        num = get_quote_num(num, count, nick)
+    except Exception as error_message:
+        return error_message
+
+    quote = db.execute('''SELECT time, nick, msg
+                          FROM quote
+                          WHERE deleted != 1
+                          AND lower(nick) = lower(?)
+                          ORDER BY time
+                          LIMIT ?, 1''', (nick, (num - 1))).fetchall()[0]
+    return format_quote(quote, num, count)
+
+
+def get_quote_by_nick_chan(db, chan, nick, num=False):
+    """Returns a formatted quote from a nick in a channel, random or selected by number"""
+    count = db.execute('''SELECT COUNT(*)
+                          FROM quote
+                          WHERE deleted != 1
+                          AND chan = ?
+                          AND lower(nick) = lower(?)''', (chan, nick)).fetchall()[0][0]
+
+    try:
+        num = get_quote_num(num, count, nick)
+    except Exception as error_message:
+        return error_message
+
+    quote = db.execute('''SELECT time, nick, msg
+                          FROM quote
+                          WHERE deleted != 1
+                          AND chan = ?
+                          AND lower(nick) = lower(?)
+                          ORDER BY time
+                          LIMIT ?, 1''', (chan, nick, (num - 1))).fetchall()[0]
+    return format_quote(quote, num, count)
+
+
+def get_quote_by_chan(db, chan, num=False):
+    """Returns a formatted quote from a channel, random or selected by number"""
+    count = db.execute('''SELECT COUNT(*)
+                          FROM quote
+                          WHERE deleted != 1
+                          AND chan = ?''', (chan,)).fetchall()[0][0]
+
+    try:
+        num = get_quote_num(num, count, chan)
+    except Exception as error_message:
+        return error_message
+
+    quote = db.execute('''SELECT time, nick, msg
+                          FROM quote
+                          WHERE deleted != 1
+                          AND chan = ?
+                          ORDER BY time
+                          LIMIT ?, 1''', (chan, (num - 1))).fetchall()[0]
+    return format_quote(quote, num, count)
+
+
+@hook.command('q')
+@hook.command
+def quote(inp, nick='', chan='', db=None, notice=None):
+    """quote [#chan] [nick] [#n]/.quote add <nick> <msg>
+    Gets random or [#n]th quote by <nick> or from <#chan>/adds quote."""
+    create_table_if_not_exists(db)
+
+    add = re.match(r"add[^\w@]+(\S+?)>?\s+(.*)", inp, re.I)
+    retrieve = re.match(r"(\S+)(?:\s+#?(-?\d+))?$", inp)
+    retrieve_chan = re.match(r"(#\S+)\s+(\S+)(?:\s+#?(-?\d+))?$", inp)
+
+    if add:
+        quoted_nick, msg = add.groups()
+        notice(add_quote(db, chan, quoted_nick, nick, msg))
+        return
+    elif retrieve:
+        select, num = retrieve.groups()
+        by_chan = True if select.startswith('#') else False
+        if by_chan:
+            return get_quote_by_chan(db, select, num)
+        else:
+            return get_quote_by_nick(db, select, num)
+    elif retrieve_chan:
+        chan, nick, num = retrieve_chan.groups()
+        return get_quote_by_nick_chan(db, chan, nick, num)
+
+    notice(quote.__doc__)
diff --git a/disabled/rdio.py b/disabled/rdio.py
new file mode 100644
index 0000000..d56bbf0
--- /dev/null
+++ b/disabled/rdio.py
@@ -0,0 +1,131 @@
+import urllib
+import json
+import re
+
+oauth = None  # import oauth2 as oauth
+
+from util import hook
+
+
+def getdata(inp, types, api_key, api_secret):
+    consumer = oauth.Consumer(api_key, api_secret)
+    client = oauth.Client(consumer)
+    response = client.request('http://api.rdio.com/1/', 'POST',
+                              urllib.parse.urlencode({'method': 'search', 'query': inp, 'types': types, 'count': '1'}))
+    data = json.loads(response[1])
+    return data
+
+
+@hook.command
+def rdio(inp, bot=None):
+    """ rdio <search term> - alternatives: .rdiot (track), .rdioar (artist), .rdioal (album) """
+    api_key = bot.config.get("api_keys", {}).get("rdio_key")
+    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
+    if not api_key:
+        return "error: no api key set"
+    data = getdata(inp, "Track,Album,Artist", api_key, api_secret)
+    try:
+        info = data['result']['results'][0]
+    except IndexError:
+        return "No results."
+    if 'name' in info:
+        if 'artist' in info and 'album' in info:  # Track
+            name = info['name']
+            artist = info['artist']
+            album = info['album']
+            url = info['shortUrl']
+            return "\x02{}\x02 by \x02{}\x02 - {} {}".format(name, artist, album, url)
+        elif 'artist' in info and not 'album' in info:  # Album
+            name = info['name']
+            artist = info['artist']
+            url = info['shortUrl']
+            return "\x02{}\x02 by \x02{}\x02 - {}".format(name, artist, url)
+        else:  # Artist
+            name = info['name']
+            url = info['shortUrl']
+            return "\x02{}\x02 - {}".format(name, url)
+
+
+@hook.command
+def rdiot(inp, bot=None):
+    """ rdiot <search term> - Search for tracks on rdio """
+    api_key = bot.config.get("api_keys", {}).get("rdio_key")
+    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
+    if not api_key:
+        return "error: no api key set"
+    data = getdata(inp, "Track", api_key, api_secret)
+    try:
+        info = data['result']['results'][0]
+    except IndexError:
+        return "No results."
+    name = info['name']
+    artist = info['artist']
+    album = info['album']
+    url = info['shortUrl']
+    return "\x02{}\x02 by \x02{}\x02 - {} - {}".format(name, artist, album, url)
+
+
+@hook.command
+def rdioar(inp, bot=None):
+    """ rdioar <search term> - Search for artists on rdio """
+    api_key = bot.config.get("api_keys", {}).get("rdio_key")
+    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
+    if not api_key:
+        return "error: no api key set"
+    data = getdata(inp, "Artist", api_key, api_secret)
+    try:
+        info = data['result']['results'][0]
+    except IndexError:
+        return "No results."
+    name = info['name']
+    url = info['shortUrl']
+    return "\x02{}\x02 - {}".format(name, url)
+
+
+@hook.command
+def rdioal(inp, bot=None):
+    """ rdioal <search term> - Search for albums on rdio """
+    api_key = bot.config.get("api_keys", {}).get("rdio_key")
+    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
+    if not api_key:
+        return "error: no api key set"
+    data = getdata(inp, "Album", api_key, api_secret)
+    try:
+        info = data['result']['results'][0]
+    except IndexError:
+        return "No results."
+    name = info['name']
+    artist = info['artist']
+    url = info['shortUrl']
+    return "\x02{}\x02 by \x02{}\x02 - {}".format(name, artist, url)
+
+
+rdio_re = (r'(.*:)//(rd.io|www.rdio.com|rdio.com)(:[0-9]+)?(.*)', re.I)
+
+
+@hook.regex(*rdio_re)
+def rdio_url(match, bot=None):
+    api_key = bot.config.get("api_keys", {}).get("rdio_key")
+    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
+    if not api_key:
+        return None
+    url = match.group(1) + "//" + match.group(2) + match.group(4)
+    consumer = oauth.Consumer(api_key, api_secret)
+    client = oauth.Client(consumer)
+    response = client.request('http://api.rdio.com/1/', 'POST',
+                              urllib.parse.urlencode({'method': 'getObjectFromUrl', 'url': url}))
+    data = json.loads(response[1])
+    info = data['result']
+    if 'name' in info:
+        if 'artist' in info and 'album' in info:  # Track
+            name = info['name']
+            artist = info['artist']
+            album = info['album']
+            return "Rdio track: \x02{}\x02 by \x02{}\x02 - {}".format(name, artist, album)
+        elif 'artist' in info and not 'album' in info:  # Album
+            name = info['name']
+            artist = info['artist']
+            return "Rdio album: \x02{}\x02 by \x02{}\x02".format(name, artist)
+        else:  # Artist
+            name = info['name']
+            return "Rdio artist: \x02{}\x02".format(name)
diff --git a/disabled/recipe.py b/disabled/recipe.py
new file mode 100644
index 0000000..5f7b742
--- /dev/null
+++ b/disabled/recipe.py
@@ -0,0 +1,111 @@
+import random
+
+from util import hook, http, web
+
+metadata_url = "http://omnidator.appspot.com/microdata/json/?url={}"
+
+base_url = "http://www.cookstr.com"
+search_url = base_url + "/searches"
+random_url = search_url + "/surprise"
+
+# set this to true to censor this plugin!
+censor = True
+phrases = [
+    "EAT SOME FUCKING \x02{}\x02",
+    "YOU WON'T NOT MAKE SOME FUCKING \x02{}\x02",
+    "HOW ABOUT SOME FUCKING \x02{}?\x02",
+    "WHY DON'T YOU EAT SOME FUCKING \x02{}?\x02",
+    "MAKE SOME FUCKING \x02{}\x02",
+    "INDUCE FOOD COMA WITH SOME FUCKING \x02{}\x02"
+    "CLASSILY PARTAKE IN SOME FUCKING \x02{}\x02",
+    "COOK UP SOME FUCKING \x02{}\x02",
+    "CURE YOUR MOUTH'S POST TRAUMATIC STRESS DISORDER WITH SOME FUCKING \x02{}\x02",
+    "PROCURE SOME CHILD LABOR TO COOK UP SOME FUCKING \x02{}\x02",
+    "YOUR INDECISION IS FAR LESS APPETIZING THAN SOME FUCKING \x02{}\x02"
+]
+
+clean_key = lambda i: i.split("#")[1]
+
+
+class ParseError(Exception):
+    pass
+
+
+def get_data(url):
+    """ Uses the omnidator API to parse the metadata from the provided URL """
+    try:
+        omni = http.get_json(metadata_url.format(url))
+    except (http.HTTPError, http.URLError) as e:
+        raise ParseError(e)
+    schemas = omni["@"]
+    for d in schemas:
+        if d["a"] == "<http://schema.org/Recipe>":
+            data = {clean_key(key): value for (key, value) in d.items()
+                    if key.startswith("http://schema.org/Recipe")}
+            return data
+    raise ParseError("No recipe data found")
+
+
+@hook.command(autohelp=False)
+def recipe(text):
+    """recipe [term] - Gets a recipe for [term], or ets a random recipe if [term] is not provided"""
+    if text:
+        # get the recipe URL by searching
+        try:
+            search = http.get_soup(search_url, query=text.strip())
+        except (http.HTTPError, http.URLError) as e:
+            return "Could not get recipe: {}".format(e)
+
+        # find the list of results
+        result_list = search.find('div', {'class': 'found_results'})
+
+        if result_list:
+            results = result_list.find_all('div', {'class': 'recipe_result'})
+        else:
+            return "No results"
+
+        # pick a random front page result
+        result = random.choice(results)
+
+        # extract the URL from the result
+        url = base_url + result.find('div', {'class': 'image-wrapper'}).find('a')['href']
+
+    else:
+        # get a random recipe URL
+        try:
+            page = http.open(random_url)
+        except (http.HTTPError, http.URLError) as e:
+            return "Could not get recipe: {}".format(e)
+        url = page.geturl()
+
+    # use get_data() to get the recipe info from the URL
+    try:
+        data = get_data(url)
+    except ParseError as e:
+        return "Could not parse recipe: {}".format(e)
+
+    name = data["name"].strip()
+    return "Try eating \x02{}!\x02 - {}".format(name, web.try_isgd(url))
+
+
+@hook.command(autohelp=False)
+def dinner():
+    """dinner - WTF IS FOR DINNER"""
+    try:
+        page = http.open(random_url)
+    except (http.HTTPError, http.URLError) as e:
+        return "Could not get recipe: {}".format(e)
+    url = page.geturl()
+
+    try:
+        data = get_data(url)
+    except ParseError as e:
+        return "Could not parse recipe: {}".format(e)
+
+    name = data["name"].strip().upper()
+    text = random.choice(phrases).format(name)
+
+    if censor:
+        text = text.replace("FUCK", "F**K")
+
+    return "{} - {}".format(text, web.try_isgd(url))
diff --git a/disabled/reddit.py b/disabled/reddit.py
new file mode 100644
index 0000000..963ed12
--- /dev/null
+++ b/disabled/reddit.py
@@ -0,0 +1,79 @@
+from datetime import datetime
+import re
+import random
+
+from util import hook, http, formatting, timesince
+
+
+reddit_re = re.compile(r'.*(((www\.)?reddit\.com/r|redd\.it)[^ ]+)', re.I)
+
+base_url = "http://reddit.com/r/{}/.json"
+short_url = "http://redd.it/{}"
+
+
+@hook.regex(reddit_re)
+def reddit_url(match):
+    thread = http.get_html(match.group(1))
+
+    title = thread.xpath('//title/text()')[0]
+    upvotes = thread.xpath("//span[@class='upvotes']/span[@class='number']/text()")[0]
+    downvotes = thread.xpath("//span[@class='downvotes']/span[@class='number']/text()")[0]
+    author = thread.xpath("//div[@id='siteTable']//a[contains(@class,'author')]/text()")[0]
+    timeago = thread.xpath("//div[@id='siteTable']//p[@class='tagline']/time/text()")[0]
+    comments = thread.xpath("//div[@id='siteTable']//a[@class='comments']/text()")[0]
+
+    return '\x02{}\x02 - posted by \x02{}\x02 {} ago - {} upvotes, {} downvotes - {}'.format(
+        title, author, timeago, upvotes, downvotes, comments)
+
+
+@hook.command(autohelp=False)
+def reddit(inp):
+    """reddit <subreddit> [n] -- Gets a random post from <subreddit>, or gets the [n]th post in the subreddit."""
+    id_num = None
+
+    if inp:
+        # clean and split the input
+        parts = inp.lower().strip().split()
+
+        # find the requested post number (if any)
+        if len(parts) > 1:
+            url = base_url.format(parts[0].strip())
+            try:
+                id_num = int(parts[1]) - 1
+            except ValueError:
+                return "Invalid post number."
+        else:
+            url = base_url.format(parts[0].strip())
+    else:
+        url = "http://reddit.com/.json"
+
+    try:
+        data = http.get_json(url, user_agent=http.ua_chrome)
+    except Exception as e:
+        return "Error: " + str(e)
+    data = data["data"]["children"]
+
+    # get the requested/random post
+    if id_num is not None:
+        try:
+            item = data[id_num]["data"]
+        except IndexError:
+            length = len(data)
+            return "Invalid post number. Number must be between 1 and {}.".format(length)
+    else:
+        item = random.choice(data)["data"]
+
+    item["title"] = formatting.truncate_str(item["title"], 50)
+    item["link"] = short_url.format(item["id"])
+
+    raw_time = datetime.fromtimestamp(int(item["created_utc"]))
+    item["timesince"] = timesince.timesince(raw_time)
+
+    if item["over_18"]:
+        item["warning"] = " \x02NSFW\x02"
+    else:
+        item["warning"] = ""
+
+    return "\x02{title} : {subreddit}\x02 - posted by \x02{author}\x02" \
+           " {timesince} ago - {ups} upvotes, {downs} downvotes -" \
+           " {link}{warning}".format(**item)
diff --git a/disabled/regex_chans.py b/disabled/regex_chans.py
new file mode 100644
index 0000000..0ef8f82
--- /dev/null
+++ b/disabled/regex_chans.py
@@ -0,0 +1,142 @@
+from sqlalchemy import Table, Column, UniqueConstraint, String
+
+from util import hook, botvars
+
+table = Table(
+    "regex_chans",
+    botvars.metadata,
+    Column("connection", String),
+    Column("channel", String),
+    Column("status", String),
+    UniqueConstraint("connection", "channel")
+)
+
+# Default value.
+# If True, all channels without a setting will have regex enabled
+# If False, all channels without a setting will have regex disabled
+default_enabled = False
+
+
+@hook.onload()
+def load_cache(db):
+    """
+    :type db: sqlalchemy.orm.Session
+    """
+    global status_cache
+    status_cache = {}
+    for row in db.execute(table.select()):
+        conn = row["connection"]
+        chan = row["channel"]
+        status = row["status"]
+        status_cache[(conn, chan)] = status
+
+
+def set_status(db, conn, chan, status):
+    """
+    :type db: sqlalchemy.orm.Session
+    :type conn: str
+    :type chan: str
+    :type status: str
+    """
+    if (conn, chan) in status_cache:
+        # if we have a set value, update
+        db.execute(
+            table.update().values(status=status).where(table.c.connection == conn).where(table.c.channel == chan))
+    else:
+        # otherwise, insert
+        db.execute(table.insert().values(connection=conn, channel=chan, status=status))
+    db.commit()
+
+
+def delete_status(db, conn, chan):
+    db.execute(table.delete().where(table.c.connection == conn).where(table.c.channel == chan))
+    db.commit()
+
+
+@hook.sieve()
+def sieve_regex(bot, input, plugin):
+    if plugin.type == "regex" and input.chan.startswith("#") and plugin.module.title != "factoids":
+        status = status_cache.get((input.conn.name, input.chan))
+        if status != "ENABLED" and (status == "DISABLED" or not default_enabled):
+            bot.logger.info("[{}] Denying {} from {}"
+                            .format(input.conn.readable_name, plugin.function_name, input.chan))
+            return None
+        bot.logger.info("[{}] Allowing {} to {}".format(input.conn.readable_name, plugin.function_name, input.chan))
+
+    return input
+
+
+@hook.command(autohelp=False, permissions=["botcontrol"])
+def enableregex(text, db, conn, chan, nick, message, notice):
+    text = text.strip().lower()
+    if not text:
+        channel = chan
+    elif text.startswith("#"):
+        channel = text
+    else:
+        channel = "#{}".format(text)
+
+    message("Enabling regex matching (youtube, etc) (issued by {})".format(nick), target=channel)
+    notice("Enabling regex matching (youtube, etc) in channel {}".format(channel))
+    set_status(db, conn.name, channel, "ENABLED")
+    load_cache(db)
+
+
+@hook.command(autohelp=False, permissions=["botcontrol"])
+def disableregex(text, db, conn, chan, nick, message, notice):
+    text = text.strip().lower()
+    if not text:
+        channel = chan
+    elif text.startswith("#"):
+        channel = text
+    else:
+        channel = "#{}".format(text)
+
+    message("Disabling regex matching (youtube, etc) (issued by {})".format(nick), target=channel)
+    notice("Disabling regex matching (youtube, etc) in channel {}".format(channel))
+    set_status(db, conn.name, channel, "DISABLED")
+    load_cache(db)
+
+
+@hook.command(autohelp=False, permissions=["botcontrol"])
+def resetregex(text, db, conn, chan, nick, message, notice):
+    text = text.strip().lower()
+    if not text:
+        channel = chan
+    elif text.startswith("#"):
+        channel = text
+    else:
+        channel = "#{}".format(text)
+
+    message("Resetting regex matching setting (youtube, etc) (issued by {})".format(nick), target=channel)
+    notice("Resetting regex matching setting (youtube, etc) in channel {}".format(channel))
+    delete_status(db, conn.name, channel)
+    load_cache(db)
+
+
+@hook.command(autohelp=False, permissions=["botcontrol"])
+def regexstatus(text, conn, chan):
+    text = text.strip().lower()
+    if not text:
+        channel = chan
+    elif text.startswith("#"):
+        channel = text
+    else:
+        channel = "#{}".format(text)
+    status = status_cache.get((conn.name, chan))
+    if status is None:
+        if default_enabled:
+            status = "ENABLED"
+        else:
+            status = "DISABLED"
+    return "Regex status for {}: {}".format(channel, status)
+
+
+@hook.command(autohelp=False, permissions=["botcontrol"])
+def listregex(conn):
+    values = []
+    for (conn_name, chan), status in status_cache.values():
+        if conn_name != conn.name:
+            continue
+        values.append("{}: {}".format(chan, status))
+    return ", ".join(values)
diff --git a/disabled/rottentomatoes.py b/disabled/rottentomatoes.py
new file mode 100644
index 0000000..34e6f6e
--- /dev/null
+++ b/disabled/rottentomatoes.py
@@ -0,0 +1,39 @@
+from util import http, hook
+
+api_root = 'http://api.rottentomatoes.com/api/public/v1.0/'
+movie_search_url = api_root + 'movies.json'
+movie_reviews_url = api_root + 'movies/%s/reviews.json'
+
+
+@hook.command('rt')
+def rottentomatoes(inp, bot=None):
+    """rt <title> -- gets ratings for <title> from Rotten Tomatoes"""
+
+    api_key = bot.config.get("api_keys", {}).get("rottentomatoes", None)
+    if not api_key:
+        return "error: no api key set"
+
+    title = inp.strip()
+
+    results = http.get_json(movie_search_url, q=title, apikey=api_key)
+    if results['total'] == 0:
+        return 'No results.'
+
+    movie = results['movies'][0]
+    title = movie['title']
+    movie_id = movie['id']
+    critics_score = movie['ratings']['critics_score']
+    audience_score = movie['ratings']['audience_score']
+    url = movie['links']['alternate']
+
+    if critics_score == -1:
+        return
+
+    reviews = http.get_json(movie_reviews_url % movie_id, apikey=api_key, review_type='all')
+    review_count = reviews['total']
+
+    fresh = critics_score * review_count / 100
+    rotten = review_count - fresh
+
+    return "{} - Critics Rating: \x02{}%\x02 ({} liked, {} disliked) " \
+           "Audience Rating: \x02{}%\x02 - {}".format(title, critics_score, fresh, rotten, audience_score, url)
diff --git a/disabled/rss.py b/disabled/rss.py
new file mode 100644
index 0000000..a87e460
--- /dev/null
+++ b/disabled/rss.py
@@ -0,0 +1,40 @@
+from util import hook, http, web, formatting
+
+
+@hook.command("feed")
+@hook.command
+def rss(text, message):
+    """rss <feed> -- Gets the first three items from the RSS feed <feed>."""
+    limit = 3
+
+    # preset news feeds
+    strip = text.lower().strip()
+    if strip == "bukkit":
+        feed = "http://dl.bukkit.org/downloads/craftbukkit/feeds/latest-rb.rss"
+        limit = 1
+    elif strip == "xkcd":
+        feed = "http://xkcd.com/rss.xml"
+    elif strip == "ars":
+        feed = "http://feeds.arstechnica.com/arstechnica/index"
+    else:
+        feed = text
+
+    query = "SELECT title, link FROM rss WHERE url=@feed LIMIT @limit"
+    result = web.query(query, {"feed": feed, "limit": limit})
+
+    if not result.rows:
+        return "Could not find/read RSS feed."
+
+    for row in result.rows:
+        title = formatting.truncate_str(row["title"], 100)
+        try:
+            link = web.isgd(row["link"])
+        except (web.ShortenError, http.HTTPError, http.URLError):
+            link = row["link"]
+        message("{} - {}".format(title, link))
+
+
+@hook.command(autohelp=False)
+def rb(message):
+    """rb -- Shows the latest Craftbukkit recommended build"""
+    rss("bukkit", message)
diff --git a/disabled/scene.py b/disabled/scene.py
new file mode 100644
index 0000000..b4d94e4
--- /dev/null
+++ b/disabled/scene.py
@@ -0,0 +1,39 @@
+import datetime
+
+from util import hook, http, timesince
+
+
+@hook.command("scene")
+@hook.command
+def pre(inp):
+    """pre <query> -- searches scene releases using orlydb.com"""
+
+    try:
+        h = http.get_html("http://orlydb.com/", q=inp)
+    except http.HTTPError as e:
+        return 'Unable to fetch results: {}'.format(e)
+
+    results = h.xpath("//div[@id='releases']/div/span[@class='release']/..")
+
+    if not results:
+        return "No results found."
+
+    result = results[0]
+
+    date = result.xpath("span[@class='timestamp']/text()")[0]
+    section = result.xpath("span[@class='section']//text()")[0]
+    name = result.xpath("span[@class='release']/text()")[0]
+
+    # parse date/time
+    date = datetime.datetime.strptime(date, "%Y-%m-%d %H:%M:%S")
+    date_string = date.strftime("%d %b %Y")
+    since = timesince.timesince(date)
+
+    size = result.xpath("span[@class='inforight']//text()")
+    if size:
+        size = ' - ' + size[0].split()[0]
+    else:
+        size = ''
+
+    return '{} - {}{} - {} ({} ago)'.format(section, name, size, date_string, since)
+
diff --git a/disabled/shorten.py b/disabled/shorten.py
new file mode 100644
index 0000000..39d993b
--- /dev/null
+++ b/disabled/shorten.py
@@ -0,0 +1,11 @@
+from util import hook, http, web
+
+
+@hook.command
+def shorten(inp):
+    """shorten <url> - Makes an is.gd shortlink to the url provided."""
+
+    try:
+        return web.isgd(inp)
+    except (web.ShortenError, http.HTTPError) as error:
+        return error
diff --git a/disabled/slap.py b/disabled/slap.py
new file mode 100644
index 0000000..4147781
--- /dev/null
+++ b/disabled/slap.py
@@ -0,0 +1,33 @@
+import json
+
+from util import hook, textgen
+
+
+def get_generator(_json, variables):
+    data = json.loads(_json)
+    return textgen.TextGenerator(data["templates"],
+                                 data["parts"], variables=variables)
+
+
+@hook.command
+def slap(inp, action=None, nick=None, conn=None, notice=None):
+    """slap <user> -- Makes the bot slap <user>."""
+    target = inp.strip()
+
+    if " " in target:
+        notice("Invalid username!")
+        return
+
+    # if the user is trying to make the bot slap itself, slap them
+    if target.lower() == conn.nick.lower() or target.lower() == "itself":
+        target = nick
+
+    variables = {
+        "user": target
+    }
+
+    with open("./data/slaps.json") as f:
+        generator = get_generator(f.read(), variables)
+
+    # act out the message
+    action(generator.generate_string())
diff --git a/disabled/slogan.py b/disabled/slogan.py
new file mode 100644
index 0000000..8bbd87e
--- /dev/null
+++ b/disabled/slogan.py
@@ -0,0 +1,17 @@
+import random
+
+from util import hook, formatting
+
+with open("./data/slogans.txt") as f:
+    slogans = [line.strip() for line in f.readlines()
+               if not line.startswith("//")]
+
+
+@hook.command
+def slogan(text):
+    """slogan <word> -- Makes a slogan for <word>."""
+    out = random.choice(slogans)
+    if text.lower() and out.startswith("<text>"):
+        text = formatting.capitalize_first(text)
+
+    return out.replace('<text>', text)
diff --git a/disabled/snopes.py b/disabled/snopes.py
new file mode 100644
index 0000000..c97628e
--- /dev/null
+++ b/disabled/snopes.py
@@ -0,0 +1,34 @@
+import re
+
+from util import hook, http
+
+
+search_url = "http://search.atomz.com/search/?sp_a=00062d45-sp00000000"
+
+
+@hook.command
+def snopes(inp):
+    """snopes <topic> -- Searches snopes for an urban legend about <topic>."""
+
+    search_page = http.get_html(search_url, sp_q=inp, sp_c="1")
+    result_urls = search_page.xpath("//a[@target='_self']/@href")
+
+    if not result_urls:
+        return "no matching pages found"
+
+    snopes_page = http.get_html(result_urls[0])
+    snopes_text = snopes_page.text_content()
+
+    claim = re.search(r"Claim: .*", snopes_text).group(0).strip()
+    status = re.search(r"Status: .*", snopes_text)
+
+    if status is not None:
+        status = status.group(0).strip()
+    else:  # new-style statuses
+        status = "Status: {}.".format(re.search(r"FALSE|TRUE|MIXTURE|UNDETERMINED",
+                                                snopes_text).group(0).title())
+
+    claim = re.sub(r"[\s\xa0]+", " ", claim)  # compress whitespace
+    status = re.sub(r"[\s\xa0]+", " ", status)
+
+    return "{} {} {}".format(claim, status, result_urls[0])
diff --git a/disabled/soundcloud.py b/disabled/soundcloud.py
new file mode 100644
index 0000000..d6f73e8
--- /dev/null
+++ b/disabled/soundcloud.py
@@ -0,0 +1,49 @@
+import re
+from urllib.parse import urlencode
+
+from util import hook, http, web, formatting
+
+sc_re = (r'(.*:)//(www.)?(soundcloud.com)(.*)', re.I)
+api_url = "http://api.soundcloud.com"
+sndsc_re = (r'(.*:)//(www.)?(snd.sc)(.*)', re.I)
+
+
+def soundcloud(url, api_key):
+    data = http.get_json(api_url + '/resolve.json?' + urlencode({'url': url, 'client_id': api_key}))
+
+    if data['description']:
+        desc = ": {} ".format(formatting.truncate_str(data['description'], 50))
+    else:
+        desc = ""
+    if data['genre']:
+        genre = "- Genre: \x02{}\x02 ".format(data['genre'])
+    else:
+        genre = ""
+
+    url = web.try_isgd(data['permalink_url'])
+
+    return "SoundCloud track: \x02{}\x02 by \x02{}\x02 {}{}- {} plays, {} downloads, {} comments - {}".format(
+        data['title'], data['user']['username'], desc, genre, data['playback_count'], data['download_count'],
+        data['comment_count'], url)
+
+
+@hook.regex(*sc_re)
+def soundcloud_url(match, bot=None):
+    api_key = bot.config.get("api_keys", {}).get("soundcloud")
+    if not api_key:
+        print("Error: no api key set")
+        return None
+    url = match.group(1).split(' ')[-1] + "//" + (match.group(2) if match.group(2) else "") + match.group(3) + \
+          match.group(4).split(' ')[0]
+    return soundcloud(url, api_key)
+
+
+@hook.regex(*sndsc_re)
+def sndsc_url(match, bot=None):
+    api_key = bot.config.get("api_keys", {}).get("soundcloud")
+    if not api_key:
+        print("Error: no api key set")
+        return None
+    url = match.group(1).split(' ')[-1] + "//" + (match.group(2) if match.group(2) else "") + match.group(3) + \
+          match.group(4).split(' ')[0]
+    return soundcloud(http.open(url).url, api_key)
diff --git a/disabled/spellcheck.py b/disabled/spellcheck.py
new file mode 100644
index 0000000..1630a0d
--- /dev/null
+++ b/disabled/spellcheck.py
@@ -0,0 +1,47 @@
+from enchant.checker import SpellChecker
+import enchant
+
+from util import hook
+
+
+locale = "en_US"
+
+
+@hook.command
+def spell(inp):
+    """spell <word/sentence> -- Check spelling of a word or sentence."""
+
+    if not enchant.dict_exists(locale):
+        return "Could not find dictionary: {}".format(locale)
+
+    if len(inp.split(" ")) > 1:
+        # input is a sentence
+        checker = SpellChecker(locale)
+        checker.set_text(inp)
+
+        offset = 0
+        for err in checker:
+            # find the location of the incorrect word
+            start = err.wordpos + offset
+            finish = start + len(err.word)
+            # get some suggestions for it
+            suggestions = err.suggest()
+            s_string = '/'.join(suggestions[:3])
+            s_string = "\x02{}\x02".format(s_string)
+            # calculate the offset for the next word
+            offset = (offset + len(s_string)) - len(err.word)
+            # replace the word with the suggestions
+            inp = inp[:start] + s_string + inp[finish:]
+        return inp
+    else:
+        # input is a word
+        dictionary = enchant.Dict(locale)
+        is_correct = dictionary.check(inp)
+        suggestions = dictionary.suggest(inp)
+        s_string = ', '.join(suggestions[:10])
+        if is_correct:
+            return '"{}" appears to be \x02valid\x02! ' \
+                   '(suggestions: {})'.format(inp, s_string)
+        else:
+            return '"{}" appears to be \x02invalid\x02! ' \
+                   '(suggestions: {})'.format(inp, s_string)
diff --git a/disabled/spotify.py b/disabled/spotify.py
new file mode 100644
index 0000000..e562a01
--- /dev/null
+++ b/disabled/spotify.py
@@ -0,0 +1,110 @@
+import re
+from urllib.parse import urlencode
+
+from util import hook, http, web
+
+gateway = 'http://open.spotify.com/{}/{}'  # http spotify gw address
+spuri = 'spotify:{}:{}'
+
+spotify_re = (r'(spotify:(track|album|artist|user):([a-zA-Z0-9]+))', re.I)
+http_re = (r'(open\.spotify\.com\/(track|album|artist|user)\/'
+           '([a-zA-Z0-9]+))', re.I)
+
+
+def sptfy(inp, sptfy=False):
+    if sptfy:
+        shortenurl = "http://sptfy.com/index.php"
+        data = urlencode({'longUrl': inp, 'shortUrlDomain': 1, 'submitted': 1, "shortUrlFolder": 6, "customUrl": "",
+                          "shortUrlPassword": "", "shortUrlExpiryDate": "", "shortUrlUses": 0, "shortUrlType": 0})
+        try:
+            soup = http.get_soup(shortenurl, post_data=data, cookies=True)
+        except:
+            return inp
+        try:
+            link = soup.find('div', {'class': 'resultLink'}).text.strip()
+            return link
+        except:
+            message = "Unable to shorten URL: {}".format(soup.find('div', {
+                'class': 'messagebox_text'}).find('p').text.split("<br/>")[0])
+            return message
+    else:
+        return web.try_isgd(inp)
+
+
+@hook.command('sptrack')
+@hook.command
+def spotify(inp):
+    """spotify <song> -- Search Spotify for <song>"""
+    try:
+        data = http.get_json("http://ws.spotify.com/search/1/track.json", q=inp.strip())
+    except Exception as e:
+        return "Could not get track information: {}".format(e)
+
+    try:
+        type, id = data["tracks"][0]["href"].split(":")[1:]
+    except IndexError:
+        return "Could not find track."
+    url = sptfy(gateway.format(type, id))
+
+    return "\x02{}\x02 by \x02{}\x02 - {}".format(data["tracks"][0]["name"],
+                                                  data["tracks"][0]["artists"][0]["name"], url)
+
+
+@hook.command
+def spalbum(inp):
+    """spalbum <album> -- Search Spotify for <album>"""
+    try:
+        data = http.get_json("http://ws.spotify.com/search/1/album.json", q=inp.strip())
+    except Exception as e:
+        return "Could not get album information: {}".format(e)
+
+    try:
+        type, id = data["albums"][0]["href"].split(":")[1:]
+    except IndexError:
+        return "Could not find album."
+    url = sptfy(gateway.format(type, id))
+
+    return "\x02{}\x02 by \x02{}\x02 - {}".format(data["albums"][0]["name"],
+                                                  data["albums"][0]["artists"][0]["name"], url)
+
+
+@hook.command
+def spartist(inp):
+    """spartist <artist> -- Search Spotify for <artist>"""
+    try:
+        data = http.get_json("http://ws.spotify.com/search/1/artist.json", q=inp.strip())
+    except Exception as e:
+        return "Could not get artist information: {}".format(e)
+
+    try:
+        type, id = data["artists"][0]["href"].split(":")[1:]
+    except IndexError:
+        return "Could not find artist."
+    url = sptfy(gateway.format(type, id))
+
+    return "\x02{}\x02 - {}".format(data["artists"][0]["name"], url)
+
+
+@hook.regex(*http_re)
+@hook.regex(*spotify_re)
+def spotify_url(match):
+    type = match.group(2)
+    spotify_id = match.group(3)
+    url = spuri.format(type, spotify_id)
+    # no error catching here, if the API is down fail silently
+    data = http.get_json("http://ws.spotify.com/lookup/1/.json", uri=url)
+    if type == "track":
+        name = data["track"]["name"]
+        artist = data["track"]["artists"][0]["name"]
+        album = data["track"]["album"]["name"]
+
+        return "Spotify Track: \x02{}\x02 by \x02{}\x02 from the album \x02{}\x02 - {}".format(name, artist,
+                                                                                               album, sptfy(
+                gateway.format(type, spotify_id)))
+    elif type == "artist":
+        return "Spotify Artist: \x02{}\x02 - {}".format(data["artist"]["name"],
+                                                        sptfy(gateway.format(type, spotify_id)))
+    elif type == "album":
+        return "Spotify Album: \x02{}\x02 - \x02{}\x02 - {}".format(data["album"]["artist"],
+                                                                    data["album"]["name"],
+                                                                    sptfy(gateway.format(type, spotify_id)))
diff --git a/disabled/steal.py b/disabled/steal.py
new file mode 100644
index 0000000..21d61bc
--- /dev/null
+++ b/disabled/steal.py
@@ -0,0 +1,77 @@
+from random import randint
+
+from sqlalchemy import Table, Column, String
+from sqlalchemy.exc import IntegrityError
+
+from util import hook, botvars
+
+table = Table(
+    'stolen',
+    botvars.metadata,
+    Column('word', String, primary_key=True)
+)
+
+
+def get_random(db):
+    """
+    :type db: sqlalchemy.orm.session.Session
+    """
+    count = db.execute(table.select().count()).fetchone()[0]
+    offset = randint(0, int(count - 1))
+    row = db.execute(table.select().limit(1).offset(offset)).fetchone()
+    if row:
+        return row[0]
+    else:
+        return None
+
+
+def list_steals(db):
+    """
+    :type db: sqlalchemy.orm.session.Session
+    """
+    row = db.execute(table.select()).fetchall()
+    return row
+
+
+def add_word(db, stolen):
+    """
+    :type db: sqlalchemy.orm.session.Session
+    """
+    try:
+        db.execute(table.insert().values(word=stolen))
+        db.commit()
+    except IntegrityError:
+        pass  # for lack of a better thing to do
+
+
+@hook.command(["steal", "stealit"], autohelp=False)
+def stealit(inp, db, nick, action):
+    """steal [username [object]] - Steals an object from a user, or a random previously stolen object."""
+    args = inp.strip().split()
+    if not args:
+        steal_from = nick
+        to_steal = get_random(db)
+        action("steals {}'s {}".format(steal_from, to_steal))
+    elif len(args) < 2:
+        steal_from = args[0]
+        to_steal = get_random(db)
+        action("steals {}'s {}".format(steal_from, to_steal))
+    else:
+        steal_from = args[0]
+        to_steal = " ".join(args[1:])
+        action("steals {}'s {}".format(steal_from, to_steal))
+        add_word(db, to_steal)
+
+
+@hook.command(autohelp=False, permissions=["adminonly"])
+def liststolen(db, reply):
+    text = False
+    for word in list_steals(db):
+        if not text:
+            text = word[0]
+        else:
+            text += ", {}".format(word[0])
+        if len(text) > 400:
+            reply(text.rsplit(', ', 1)[0])
+            text = word[0]
+    return text
diff --git a/disabled/steam.py b/disabled/steam.py
new file mode 100644
index 0000000..02a29f8
--- /dev/null
+++ b/disabled/steam.py
@@ -0,0 +1,72 @@
+import re
+
+from bs4 import BeautifulSoup, NavigableString, Tag
+
+from util import hook, http, web
+from util.formatting import truncate_str
+
+steam_re = (r'(.*:)//(store.steampowered.com)(:[0-9]+)?(.*)', re.I)
+
+
+def get_steam_info(url):
+    page = http.get(url)
+    soup = BeautifulSoup(page, 'lxml', from_encoding="utf-8")
+
+    data = {"name": soup.find('div', {'class': 'apphub_AppName'}).text,
+            "desc": truncate_str(soup.find('meta', {'name': 'description'})['content'].strip(), 80)}
+
+    # get the element details_block
+    details = soup.find('div', {'class': 'details_block'})
+
+    # loop over every <b></b> tag in details_block
+    for b in details.findAll('b'):
+        # get the contents of the <b></b> tag, which is our title
+        title = b.text.lower().replace(":", "")
+        if title == "languages":
+            # we have all we need!
+            break
+
+        # find the next element directly after the <b></b> tag
+        next_element = b.nextSibling
+        if next_element:
+            # if the element is some text
+            if isinstance(next_element, NavigableString):
+                text = next_element.string.strip()
+                if text:
+                    # we found valid text, save it and continue the loop
+                    data[title] = text
+                    continue
+                else:
+                    # the text is blank - sometimes this means there are
+                    # useless spaces or tabs between the <b> and <a> tags.
+                    # so we find the next <a> tag and carry on to the next
+                    # bit of code below
+                    next_element = next_element.find_next('a', href=True)
+
+            # if the element is an <a></a> tag
+            if isinstance(next_element, Tag) and next_element.name == 'a':
+                text = next_element.string.strip()
+                if text:
+                    # we found valid text (in the <a></a> tag),
+                    # save it and continue the loop
+                    data[title] = text
+                    continue
+
+    data["price"] = soup.find('div', {'class': 'game_purchase_price price'}).text.strip()
+
+    return "\x02{name}\x02: {desc}, \x02Genre\x02: {genre}, \x02Release Date\x02: {release date}," \
+           " \x02Price\x02: {price}".format(**data)
+
+
+@hook.regex(*steam_re)
+def steam_url(match):
+    return get_steam_info("http://store.steampowered.com" + match.group(4))
+
+
+@hook.command
+def steam(inp):
+    """steam [search] - Search for specified game/trailer/DLC"""
+    page = http.get("http://store.steampowered.com/search/?term=" + inp)
+    soup = BeautifulSoup(page, 'lxml', from_encoding="utf-8")
+    result = soup.find('a', {'class': 'search_result_row'})
+    return get_steam_info(result['href']) + " - " + web.isgd(result['href'])
diff --git a/disabled/steam_calc.py b/disabled/steam_calc.py
new file mode 100644
index 0000000..acf70f2
--- /dev/null
+++ b/disabled/steam_calc.py
@@ -0,0 +1,120 @@
+import csv
+import io
+
+from util import hook, http
+
+
+gauge_url = "http://www.mysteamgauge.com/search?username={}"
+
+api_url = "http://mysteamgauge.com/user/{}.csv"
+steam_api_url = "http://steamcommunity.com/id/{}/?xml=1"
+
+
+def refresh_data(name):
+    http.get(gauge_url.format(name), timeout=25, get_method='HEAD')
+
+
+def get_data(name):
+    return http.get(api_url.format(name))
+
+
+def is_number(s):
+    try:
+        float(s)
+        return True
+    except ValueError:
+        return False
+
+
+def unicode_dictreader(utf8_data, **kwargs):
+    csv_reader = csv.DictReader(utf8_data, **kwargs)
+    for row in csv_reader:
+        yield dict([(key.lower(), str(value, 'utf-8')) for key, value in row.items()])
+
+
+@hook.command('sc')
+@hook.command
+def steamcalc(inp, reply=None):
+    """steamcalc <username> [currency] - Gets value of steam account and
+       total hours played. Uses steamcommunity.com/id/<nickname>. """
+
+    # check if the user asked us to force reload
+    force_reload = inp.endswith(" forcereload")
+    if force_reload:
+        name = inp[:-12].strip().lower()
+    else:
+        name = inp.strip()
+
+    if force_reload:
+        try:
+            reply("Collecting data, this may take a while.")
+            refresh_data(name)
+            request = get_data(name)
+            do_refresh = False
+        except (http.HTTPError, http.URLError):
+            return "Could not get data for this user."
+    else:
+        try:
+            request = get_data(name)
+            do_refresh = True
+        except (http.HTTPError, http.URLError):
+            try:
+                reply("Collecting data, this may take a while.")
+                refresh_data(name)
+                request = get_data(name)
+                do_refresh = False
+            except (http.HTTPError, http.URLError):
+                return "Could not get data for this user."
+
+    csv_data = io.StringIO(request)  # we use StringIO because CSV can't read a string
+    reader = unicode_dictreader(csv_data)
+
+    # put the games in a list
+    games = []
+    for row in reader:
+        games.append(row)
+
+    data = {}
+
+    # basic information
+    steam_profile = http.get_xml(steam_api_url.format(name))
+    try:
+        data["name"] = steam_profile.find('steamID').text
+        online_state = steam_profile.find('stateMessage').text
+    except AttributeError:
+        return "Could not get data for this user."
+
+    online_state = online_state.replace("<br/>", ": ")  # will make this pretty later
+    data["state"] = text.strip_html(online_state)
+
+    # work out the average metascore for all games
+    ms = [float(game["metascore"]) for game in games if is_number(game["metascore"])]
+    metascore = float(sum(ms)) / len(ms) if len(ms) > 0 else float('nan')
+    data["average_metascore"] = "{0:.1f}".format(metascore)
+
+    # work out the totals
+    data["games"] = len(games)
+
+    total_value = sum([float(game["value"]) for game in games if is_number(game["value"])])
+    data["value"] = str(int(round(total_value)))
+
+    # work out the total size
+    total_size = 0.0
+
+    for game in games:
+        if not is_number(game["size"]):
+            continue
+
+        if game["unit"] == "GB":
+            total_size += float(game["size"])
+        else:
+            total_size += float(game["size"]) / 1024
+
+    data["size"] = "{0:.1f}".format(total_size)
+
+    reply("{name} ({state}) has {games} games with a total value of ${value}"
+          " and a total size of {size}GB! The average metascore for these"
+          " games is {average_metascore}.".format(**data))
+
+    if do_refresh:
+        refresh_data(name)
diff --git a/disabled/stock.py b/disabled/stock.py
new file mode 100644
index 0000000..f61fc5c
--- /dev/null
+++ b/disabled/stock.py
@@ -0,0 +1,30 @@
+from util import hook, web
+
+
+@hook.command
+def stock(inp):
+    """stock <symbol> -- gets stock information"""
+    sym = inp.strip().lower()
+
+    query = "SELECT * FROM yahoo.finance.quote WHERE symbol=@symbol LIMIT 1"
+    quote = web.query(query, {"symbol": sym}).one()
+
+    # if we don't get a company name back, the symbol doesn't match a company
+    if quote['Change'] is None:
+        return "Unknown ticker symbol: {}".format(sym)
+
+    change = float(quote['Change'])
+    price = float(quote['LastTradePriceOnly'])
+
+    if change < 0:
+        quote['color'] = "5"
+    else:
+        quote['color'] = "3"
+
+    quote['PercentChange'] = 100 * change / (price - change)
+    print(quote)
+
+    return "\x02{Name}\x02 (\x02{symbol}\x02) - {LastTradePriceOnly} " \
+           "\x03{color}{Change} ({PercentChange:.2f}%)\x03 " \
+           "Day Range: {DaysRange} " \
+           "MCAP: {MarketCapitalization}".format(**quote)
diff --git a/disabled/suggest.py b/disabled/suggest.py
new file mode 100644
index 0000000..9a9d21e
--- /dev/null
+++ b/disabled/suggest.py
@@ -0,0 +1,28 @@
+import json
+
+from bs4 import BeautifulSoup
+
+from util import hook, http, formatting
+
+
+@hook.command
+def suggest(text):
+    """suggest <phrase> -- Gets suggested phrases for a google search"""
+
+    page = http.get('http://google.com/complete/search',
+                    output='json', client='hp', q=text)
+    page_json = page.split('(', 1)[1][:-1]
+
+    suggestions = json.loads(page_json)[1]
+    suggestions = [suggestion[0] for suggestion in suggestions]
+
+    if not suggestions:
+        return 'no suggestions found'
+
+    out = ", ".join(suggestions)
+
+    # defuckify text (might not be needed now, but I'll keep it)
+    soup = BeautifulSoup(out)
+    out = soup.get_text()
+
+    return formatting.truncate_str(out, 200)
diff --git a/disabled/tell.py b/disabled/tell.py
new file mode 100644
index 0000000..306f03b
--- /dev/null
+++ b/disabled/tell.py
@@ -0,0 +1,142 @@
+import re
+from datetime import datetime
+
+from sqlalchemy import Table, Column, String, Boolean, DateTime
+from sqlalchemy.sql import select
+
+from util import hook, timesince, botvars
+
+table = Table(
+    'tells',
+    botvars.metadata,
+    Column('connection', String),
+    Column('sender', String),
+    Column('target', String),
+    Column('message', String),
+    Column('is_read', Boolean),
+    Column('time_sent', DateTime),
+    Column('time_read', DateTime)
+)
+
+
+def get_unread(db, server, target):
+    query = select([table.c.sender, table.c.message, table.c.time_sent]) \
+        .where(table.c.connection == server) \
+        .where(table.c.target == target.lower()) \
+        .where(table.c.is_read == 0) \
+        .order_by(table.c.time_sent)
+    return db.execute(query).fetchall()
+
+
+def count_unread(db, server, target):
+    query = select([table]) \
+        .where(table.c.connection == server) \
+        .where(table.c.target == target.lower()) \
+        .where(table.c.is_read == 0) \
+        .count()
+    return db.execute(query).fetchone()[0]
+
+
+def read_all_tells(db, server, target):
+    query = table.update() \
+        .where(table.c.connection == server) \
+        .where(table.c.target == target.lower()) \
+        .where(table.c.is_read == 0) \
+        .values(is_read=1)
+    db.execute(query)
+    db.commit()
+
+
+def read_tell(db, server, target, message):
+    query = table.update() \
+        .where(table.c.connection == server) \
+        .where(table.c.target == target.lower()) \
+        .where(table.c.message == message) \
+        .values(is_read=1)
+    db.execute(query)
+    db.commit()
+
+
+def add_tell(db, server, sender, target, message):
+    query = table.insert().values(
+        connection=server,
+        sender=sender,
+        target=target,
+        message=message,
+        is_read=False,
+        time_sent=datetime.today()
+    )
+    db.execute(query)
+    db.commit()
+
+
+@hook.event('PRIVMSG', singlethread=True)
+def tellinput(input, notice, db, nick, conn):
+    if 'showtells' in input.msg.lower():
+        return
+
+    tells = get_unread(db, conn.server, nick)
+
+    if tells:
+        user_from, message, time_sent = tells[0]
+        reltime = timesince.timesince(time_sent)
+
+        reply = "{} sent you a message {} ago: {}".format(user_from, reltime, message)
+        if len(tells) > 1:
+            reply += " (+{} more, {}showtells to view)".format(len(tells) - 1, conn.config["command_prefix"])
+
+        read_tell(db, conn.server, nick, message)
+        notice(reply)
+
+
+@hook.command(autohelp=False)
+def showtells(nick, notice, db, conn):
+    """showtells -- View all pending tell messages (sent in a notice)."""
+
+    tells = get_unread(db, conn.server, nick)
+
+    if not tells:
+        notice("You have no pending messages.")
+        return
+
+    for tell in tells:
+        sender, message, time_sent = tell
+        past = timesince.timesince(time_sent)
+        notice("{} sent you a message {} ago: {}".format(sender, past, message))
+
+    read_all_tells(db, conn.server, nick)
+
+
+@hook.command("tell")
+def tell_cmd(inp, nick, db, notice, conn):
+    """tell <nick> <message> -- Relay <message> to <nick> when <nick> is around."""
+    query = inp.split(' ', 1)
+
+    if len(query) != 2:
+        notice(conn.config("command_prefix") + tell_cmd.__doc__)
+        return
+
+    target = query[0].lower()
+    message = query[1].strip()
+    sender = nick
+
+    if target == sender.lower():
+        notice("Have you looked in a mirror lately?")
+        return
+
+    if target.lower() == conn.nick.lower():
+        # we can't send messages to ourselves
+        notice("Invalid nick '{}'.".format(target))
+        return
+
+    if not re.match("^[A-Za-z0-9_|.\-\]\[]*$", target.lower()):
+        notice("Invalid nick '{}'.".format(target))
+        return
+
+    if count_unread(db, conn.server, target) >= 10:
+        notice("Sorry, {} has too many messages queued already.".format(target))
+        return
+
+    add_tell(db, conn.server, sender, target, message)
+
+    notice("Your message has been sent!")
diff --git a/disabled/time_plugin.py b/disabled/time_plugin.py
new file mode 100644
index 0000000..9247952
--- /dev/null
+++ b/disabled/time_plugin.py
@@ -0,0 +1,62 @@
+import time
+
+from util import hook, http
+from util.formatting import capitalize_first
+
+
+api_url = 'http://api.wolframalpha.com/v2/query?format=plaintext'
+
+
+@hook.command("time")
+def time_command(inp, bot=None):
+    """time <area> -- Gets the time in <area>"""
+
+    query = "current time in {}".format(inp)
+
+    api_key = bot.config.get("api_keys", {}).get("wolframalpha", None)
+    if not api_key:
+        return "error: no wolfram alpha api key set"
+
+    request = http.get_xml(api_url, input=query, appid=api_key)
+    current_time = " ".join(request.xpath("//pod[@title='Result']/subpod/plaintext/text()"))
+    current_time = current_time.replace("  |  ", ", ")
+
+    if current_time:
+        # nice place name for UNIX time
+        if inp.lower() == "unix":
+            place = "Unix Epoch"
+        else:
+            place = capitalize_first(" ".join(request.xpath("//pod[@"
+                                                            "title='Input interpretation']/subpod/plaintext/text()"))[
+                                     16:])
+        return "{} - \x02{}\x02".format(current_time, place)
+    else:
+        return "Could not get the time for '{}'.".format(inp)
+
+
+@hook.command(autohelp=False)
+def beats(inp):
+    """beats -- Gets the current time in .beats (Swatch Internet Time). """
+
+    if inp.lower() == "wut":
+        return "Instead of hours and minutes, the mean solar day is divided " \
+               "up into 1000 parts called \".beats\". Each .beat lasts 1 minute and" \
+               " 26.4 seconds. Times are notated as a 3-digit number out of 1000 af" \
+               "ter midnight. So, @248 would indicate a time 248 .beats after midni" \
+               "ght representing 248/1000 of a day, just over 5 hours and 57 minute" \
+               "s. There are no timezones."
+    elif inp.lower() == "guide":
+        return "1 day = 1000 .beats, 1 hour = 41.666 .beats, 1 min = 0.6944 .beats, 1 second = 0.01157 .beats"
+
+    t = time.gmtime()
+    h, m, s = t.tm_hour, t.tm_min, t.tm_sec
+
+    utc = 3600 * h + 60 * m + s
+    bmt = utc + 3600  # Biel Mean Time (BMT)
+
+    beat = bmt / 86.4
+
+    if beat > 1000:
+        beat -= 1000
+
+    return "Swatch Internet Time: @%06.2f" % beat
diff --git a/disabled/title.py b/disabled/title.py
new file mode 100644
index 0000000..a31dc42
--- /dev/null
+++ b/disabled/title.py
@@ -0,0 +1,23 @@
+from bs4 import BeautifulSoup
+
+from util import hook, http, urlnorm
+
+
+@hook.command
+def title(inp):
+    """title <url> -- gets the title of a web page"""
+    url = urlnorm.normalize(inp, assume_scheme="http")
+
+    try:
+        page = http.open(url)
+        real_url = page.geturl()
+        soup = BeautifulSoup(page.read())
+    except (http.HTTPError, http.URLError):
+        return "Could not fetch page."
+
+    page_title = soup.find('title').contents[0]
+
+    if not page_title:
+        return "Could not find title."
+
+    return "{} [{}]".format(page_title, real_url)
diff --git a/disabled/tvdb.py b/disabled/tvdb.py
new file mode 100644
index 0000000..46b25db
--- /dev/null
+++ b/disabled/tvdb.py
@@ -0,0 +1,154 @@
+import datetime
+
+from util import hook, http
+
+
+base_url = "http://thetvdb.com/api/"
+api_key = "469B73127CA0C411"
+
+
+def get_episodes_for_series(series_name, api_key):
+    res = {"error": None, "ended": False, "episodes": None, "name": None}
+    # http://thetvdb.com/wiki/index.php/API:GetSeries
+    try:
+        query = http.get_xml(base_url + 'GetSeries.php', seriesname=series_name)
+    except http.URLError:
+        res["error"] = "error contacting thetvdb.com"
+        return res
+
+    series_id = query.xpath('//seriesid/text()')
+
+    if not series_id:
+        res["error"] = "Unknown TV series. (using www.thetvdb.com)"
+        return res
+
+    series_id = series_id[0]
+
+    try:
+        series = http.get_xml(base_url + '%s/series/%s/all/en.xml' % (api_key, series_id))
+    except http.URLError:
+        res["error"] = "Error contacting thetvdb.com."
+        return res
+
+    series_name = series.xpath('//SeriesName/text()')[0]
+
+    if series.xpath('//Status/text()')[0] == 'Ended':
+        res["ended"] = True
+
+    res["episodes"] = series.xpath('//Episode')
+    res["name"] = series_name
+    return res
+
+
+def get_episode_info(episode, api_key):
+    first_aired = episode.findtext("FirstAired")
+
+    try:
+        air_date = datetime.date(*list(map(int, first_aired.split('-'))))
+    except (ValueError, TypeError):
+        return None
+
+    episode_num = "S%02dE%02d" % (int(episode.findtext("SeasonNumber")),
+                                  int(episode.findtext("EpisodeNumber")))
+
+    episode_name = episode.findtext("EpisodeName")
+    # in the event of an unannounced episode title, users either leave the
+    # field out (None) or fill it with TBA
+    if episode_name == "TBA":
+        episode_name = None
+
+    episode_desc = '{}'.format(episode_num)
+    if episode_name:
+        episode_desc += ' - {}'.format(episode_name)
+    return first_aired, air_date, episode_desc
+
+
+@hook.command
+@hook.command('tv')
+def tv_next(inp, bot=None):
+    """tv <series> -- Get the next episode of <series>."""
+
+    api_key = bot.config.get("api_keys", {}).get("tvdb", None)
+    if api_key is None:
+        return "error: no api key set"
+    episodes = get_episodes_for_series(inp, api_key)
+
+    if episodes["error"]:
+        return episodes["error"]
+
+    series_name = episodes["name"]
+    ended = episodes["ended"]
+    episodes = episodes["episodes"]
+
+    if ended:
+        return "{} has ended.".format(series_name)
+
+    next_eps = []
+    today = datetime.date.today()
+
+    for episode in reversed(episodes):
+        ep_info = get_episode_info(episode, api_key)
+
+        if ep_info is None:
+            continue
+
+        (first_aired, air_date, episode_desc) = ep_info
+
+        if air_date > today:
+            next_eps = ['{} ({})'.format(first_aired, episode_desc)]
+        elif air_date == today:
+            next_eps = ['Today ({})'.format(episode_desc)] + next_eps
+        else:
+            # we're iterating in reverse order with newest episodes last
+            # so, as soon as we're past today, break out of loop
+            break
+
+    if not next_eps:
+        return "There are no new episodes scheduled for {}.".format(series_name)
+
+    if len(next_eps) == 1:
+        return "The next episode of {} airs {}".format(series_name, next_eps[0])
+    else:
+        next_eps = ', '.join(next_eps)
+        return "The next episodes of {}: {}".format(series_name, next_eps)
+
+
+@hook.command
+@hook.command('tv_prev')
+def tv_last(inp, bot=None):
+    """tv_last <series> -- Gets the most recently aired episode of <series>."""
+
+    api_key = bot.config.get("api_keys", {}).get("tvdb", None)
+    if api_key is None:
+        return "error: no api key set"
+    episodes = get_episodes_for_series(inp, api_key)
+
+    if episodes["error"]:
+        return episodes["error"]
+
+    series_name = episodes["name"]
+    ended = episodes["ended"]
+    episodes = episodes["episodes"]
+
+    prev_ep = None
+    today = datetime.date.today()
+
+    for episode in reversed(episodes):
+        ep_info = get_episode_info(episode, api_key)
+
+        if ep_info is None:
+            continue
+
+        (first_aired, air_date, episode_desc) = ep_info
+
+        if air_date < today:
+            #iterating in reverse order, so the first episode encountered
+            #before today was the most recently aired
+            prev_ep = '{} ({})'.format(first_aired, episode_desc)
+            break
+
+    if not prev_ep:
+        return "There are no previously aired episodes for {}.".format(series_name)
+    if ended:
+        return '{} ended. The last episode aired {}.'.format(series_name, prev_ep)
+    return "The last episode of {} aired {}.".format(series_name, prev_ep)
diff --git a/disabled/twitch.py b/disabled/twitch.py
new file mode 100644
index 0000000..2405f64
--- /dev/null
+++ b/disabled/twitch.py
@@ -0,0 +1,115 @@
+import re
+
+from html.parser import HTMLParser
+from util import hook, http
+
+
+twitch_re = (r'(.*:)//(twitch.tv|www.twitch.tv)(:[0-9]+)?(.*)', re.I)
+multitwitch_re = (r'(.*:)//(www.multitwitch.tv|multitwitch.tv)/(.*)', re.I)
+
+
+def test(s):
+    valid = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_/')
+    return set(s) <= valid
+
+
+def truncate(msg):
+    nmsg = msg.split(" ")
+    out = None
+    x = 0
+    for i in nmsg:
+        if x <= 7:
+            if out:
+                out = out + " " + nmsg[x]
+            else:
+                out = nmsg[x]
+        x += 1
+    if x <= 7:
+        return out
+    else:
+        return out + "..."
+
+
+@hook.regex(*multitwitch_re)
+def multitwitch_url(match):
+    usernames = match.group(3).split("/")
+    out = ""
+    for i in usernames:
+        if not test(i):
+            print("Not a valid username")
+            return None
+        if out == "":
+            out = twitch_lookup(i)
+        else:
+            out = out + " \x02|\x02 " + twitch_lookup(i)
+    return out
+
+
+@hook.regex(*twitch_re)
+def twitch_url(match):
+    bit = match.group(4).split("#")[0]
+    location = "/".join(bit.split("/")[1:])
+    if not test(location):
+        print("Not a valid username")
+        return None
+    return twitch_lookup(location)
+
+
+@hook.command('twitchviewers')
+@hook.command
+def twviewers(inp):
+    inp = inp.split("/")[-1]
+    if test(inp):
+        location = inp
+    else:
+        return "Not a valid channel name."
+    return twitch_lookup(location).split("(")[-1].split(")")[0].replace("Online now! ", "")
+
+
+def twitch_lookup(location):
+    locsplit = location.split("/")
+    if len(locsplit) > 1 and len(locsplit) == 3:
+        channel = locsplit[0]
+        type = locsplit[1]  # should be b or c
+        id = locsplit[2]
+    else:
+        channel = locsplit[0]
+        type = None
+        id = None
+    h = HTMLParser()
+    fmt = "{}: {} playing {} ({})"  # Title: nickname playing Game (x views)
+    if type and id:
+        if type == "b":  # I haven't found an API to retrieve broadcast info
+            soup = http.get_soup("http://twitch.tv/" + location)
+            title = soup.find('span', {'class': 'real_title js-title'}).text
+            playing = soup.find('a', {'class': 'game js-game'}).text
+            views = soup.find('span', {'id': 'views-count'}).text + " view"
+            views = views + "s" if not views[0:2] == "1 " else views
+            return h.unescape(fmt.format(title, channel, playing, views))
+        elif type == "c":
+            data = http.get_json("https://api.twitch.tv/kraken/videos/" + type + id)
+            title = data['title']
+            playing = data['game']
+            views = str(data['views']) + " view"
+            views = views + "s" if not views[0:2] == "1 " else views
+            return h.unescape(fmt.format(title, channel, playing, views))
+    else:
+        data = http.get_json("http://api.justin.tv/api/stream/list.json?channel=" + channel)
+        if data and len(data) >= 1:
+            data = data[0]
+            title = data['title']
+            playing = data['meta_game']
+            viewers = "\x033\x02Online now!\x02\x0f " + str(data["channel_count"]) + " viewer"
+            print(viewers)
+            viewers = viewers + "s" if not " 1 view" in viewers else viewers
+            print(viewers)
+            return h.unescape(fmt.format(title, channel, playing, viewers))
+        else:
+            try:
+                data = http.get_json("https://api.twitch.tv/kraken/channels/" + channel)
+            except:
+                return
+            title = data['status']
+            playing = data['game']
+            viewers = "\x034\x02Offline\x02\x0f"
+            return h.unescape(fmt.format(title, channel, playing, viewers))
diff --git a/disabled/twitter.py b/disabled/twitter.py
new file mode 100644
index 0000000..60a3c1e
--- /dev/null
+++ b/disabled/twitter.py
@@ -0,0 +1,178 @@
+import re
+import random
+from datetime import datetime
+
+import tweepy
+
+from util import hook, timesince
+
+
+TWITTER_RE = (r"(?:(?:www.twitter.com|twitter.com)/(?:[-_a-zA-Z0-9]+)/status/)([0-9]+)", re.I)
+
+
+def get_api(bot):
+    consumer_key = bot.config.get("api_keys", {}).get("twitter_consumer_key")
+    consumer_secret = bot.config.get("api_keys", {}).get("twitter_consumer_secret")
+
+    oauth_token = bot.config.get("api_keys", {}).get("twitter_access_token")
+    oauth_secret = bot.config.get("api_keys", {}).get("twitter_access_secret")
+
+    if not consumer_key:
+        return False
+
+    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
+    auth.set_access_token(oauth_token, oauth_secret)
+
+    return tweepy.API(auth)
+
+
+@hook.regex(*TWITTER_RE)
+def twitter_url(match, bot=None):
+    # Find the tweet ID from the URL
+    tweet_id = match.group(1)
+
+    # Get the tweet using the tweepy API
+    api = get_api(bot)
+    if not api:
+        return
+    try:
+        tweet = api.get_status(tweet_id)
+        user = tweet.user
+    except tweepy.error.TweepError:
+        return
+
+    # Format the return the text of the tweet
+    text = " ".join(tweet.text.split())
+
+    if user.verified:
+        prefix = "\u2713"
+    else:
+        prefix = ""
+
+    time = timesince.timesince(tweet.created_at, datetime.utcnow())
+
+    return "{}@\x02{}\x02 ({}): {} ({} ago)".format(prefix, user.screen_name, user.name, text, time)
+
+
+@hook.command("tw")
+@hook.command("twatter")
+@hook.command
+def twitter(inp, bot=None):
+    """twitter <user> [n] -- Gets last/[n]th tweet from <user>"""
+
+    api = get_api(bot)
+    if not api:
+        return "Error: No Twitter API details."
+
+    if re.match(r'^\d+$', inp):
+        # user is getting a tweet by id
+
+        try:
+            # get tweet by id
+            tweet = api.get_status(inp)
+        except tweepy.error.TweepError as e:
+            if e[0][0]['code'] == 34:
+                return "Could not find tweet."
+            else:
+                return "Error {}: {}".format(e[0][0]['code'], e[0][0]['message'])
+
+        user = tweet.user
+
+    elif re.match(r'^\w{1,15}$', inp) or re.match(r'^\w{1,15}\s+\d+$', inp):
+        # user is getting a tweet by name
+
+        if inp.find(' ') == -1:
+            username = inp
+            tweet_number = 0
+        else:
+            username, tweet_number = inp.split()
+            tweet_number = int(tweet_number) - 1
+
+        if tweet_number > 300:
+            return "This command can only find the last \x02300\x02 tweets."
+
+        try:
+            # try to get user by username
+            user = api.get_user(username)
+        except tweepy.error.TweepError as e:
+            if e[0][0]['code'] == 34:
+                return "Could not find user."
+            else:
+                return "Error {}: {}".format(e[0][0]['code'], e[0][0]['message'])
+
+        # get the users tweets
+        user_timeline = api.user_timeline(id=user.id, count=tweet_number + 1)
+
+        # if the timeline is empty, return an error
+        if not user_timeline:
+            return "The user \x02{}\x02 has no tweets.".format(user.screen_name)
+
+        # grab the newest tweet from the users timeline
+        try:
+            tweet = user_timeline[tweet_number]
+        except IndexError:
+            tweet_count = len(user_timeline)
+            return "The user \x02{}\x02 only has \x02{}\x02 tweets.".format(user.screen_name, tweet_count)
+
+    elif re.match(r'^#\w+$', inp):
+        # user is searching by hashtag
+        search = api.search(inp)
+
+        if not search:
+            return "No tweets found."
+
+        tweet = random.choice(search)
+        user = tweet.user
+    else:
+        # ???
+        return "Invalid Input"
+
+    # Format the return the text of the tweet
+    text = " ".join(tweet.text.split())
+
+    if user.verified:
+        prefix = "\u2713"
+    else:
+        prefix = ""
+
+    time = timesince.timesince(tweet.created_at, datetime.utcnow())
+
+    return "{}@\x02{}\x02 ({}): {} ({} ago)".format(prefix, user.screen_name, user.name, text, time)
+
+
+@hook.command("twinfo")
+@hook.command
+def twuser(inp, bot=None):
+    """twuser <user> -- Get info on the Twitter user <user>"""
+
+    api = get_api(bot)
+    if not api:
+        return "Error: No Twitter API details."
+
+    try:
+        # try to get user by username
+        user = api.get_user(inp)
+    except tweepy.error.TweepError as e:
+        if e[0][0]['code'] == 34:
+            return "Could not find user."
+        else:
+            return "Unknown error"
+
+    if user.verified:
+        prefix = "\u2713"
+    else:
+        prefix = ""
+
+    if user.location:
+        loc_str = " is located in \x02{}\x02 and".format(user.location)
+    else:
+        loc_str = ""
+
+    if user.description:
+        desc_str = " The users description is \"{}\"".format(user.description)
+    else:
+        desc_str = ""
+
+    return "{}@\x02{}\x02 ({}){} has \x02{:,}\x02 tweets and \x02{:,}\x02 followers.{}" \
+           "".format(prefix, user.screen_name, user.name, loc_str, user.statuses_count, user.followers_count,
+                     desc_str)
diff --git a/disabled/update.py b/disabled/update.py
new file mode 100644
index 0000000..c867505
--- /dev/null
+++ b/disabled/update.py
@@ -0,0 +1,43 @@
+from git import Repo
+
+from util import hook, web
+
+
+@hook.command
+def update():
+    repo = Repo()
+    git = repo.git
+    try:
+        pull = git.pull()
+    except Exception as e:
+        return e
+    if "\n" in pull:
+        return web.haste(pull)
+    else:
+        return pull
+
+
+@hook.command
+def version():
+    repo = Repo()
+
+    # get origin and fetch it
+    origin = repo.remotes.origin
+    info = origin.fetch()
+
+    # get objects
+    head = repo.head
+    origin_head = info[0]
+    current_commit = head.commit
+    remote_commit = origin_head.commit
+
+    if current_commit == remote_commit:
+        in_sync = True
+    else:
+        in_sync = False
+
+    # output
+    return "Local \x02{}\x02 is at commit \x02{}\x02, remote \x02{}\x02 is at commit \x02{}\x02." \
+           " You {} running the latest version.".format(head, current_commit.name_rev[:7],
+                                                        origin_head, remote_commit.name_rev[:7],
+                                                        "are" if in_sync else "are not")
diff --git a/disabled/urban.py b/disabled/urban.py
new file mode 100644
index 0000000..1d3691c
--- /dev/null
+++ b/disabled/urban.py
@@ -0,0 +1,64 @@
+import random
+
+from util import hook, http, formatting
+
+base_url = 'http://api.urbandictionary.com/v0'
+define_url = base_url + "/define"
+random_url = base_url + "/random"
+
+
+@hook.command(["urban", "u"], autohelp=False)
+def urban(text):
+    """urban <phrase> [id] -- Looks up <phrase> on urbandictionary.com."""
+
+    if text:
+        # clean and split the input
+        text = text.lower().strip()
+        parts = text.split()
+
+        # if the last word is a number, set the ID to that number
+        if parts[-1].isdigit():
+            id_num = int(parts[-1])
+            # remove the ID from the input string
+            del parts[-1]
+            text = " ".join(parts)
+        else:
+            id_num = 1
+
+        # fetch the definitions
+        page = http.get_json(define_url, term=text, referer="http://m.urbandictionary.com")
+
+        if page['result_type'] == 'no_results':
+            return 'Not found.'
+    else:
+        # get a random definition!
+        page = http.get_json(random_url, referer="http://m.urbandictionary.com")
+        id_num = None
+
+    definitions = page['list']
+
+    if id_num:
+        # try getting the requested definition
+        try:
+            definition = definitions[id_num - 1]
+
+            def_text = " ".join(definition['definition'].split())  # remove excess spaces
+            def_text = formatting.truncate_str(def_text, 200)
+        except IndexError:
+            return 'Not found.'
+
+        url = definition['permalink']
+
+        output = "[{}/{}] {} :: {}".format(id_num, len(definitions), def_text, url)
+
+    else:
+        definition = random.choice(definitions)
+
+        def_text = " ".join(definition['definition'].split())  # remove excess spaces
+        def_text = formatting.truncate_str(def_text, 200)
+
+        name = definition['word']
+        url = definition['permalink']
+        output = "\x02{}\x02: {} :: {}".format(name, def_text, url)
+
+    return output
diff --git a/disabled/utility.py b/disabled/utility.py
new file mode 100644
index 0000000..878d76b
--- /dev/null
+++ b/disabled/utility.py
@@ -0,0 +1,194 @@
+import base64
+import codecs
+import hashlib
+import collections
+import re
+import binascii
+
+from util import hook, formatting
+
+colors = collections.OrderedDict([
+    ('red', '\x0304'),
+    ('orange', '\x0307'),
+    ('yellow', '\x0308'),
+    ('green', '\x0309'),
+    ('cyan', '\x0303'),
+    ('ltblue', '\x0310'),
+    ('rylblue', '\x0312'),
+    ('blue', '\x0302'),
+    ('magenta', '\x0306'),
+    ('pink', '\x0313'),
+    ('maroon', '\x0305')
+])
+
+# helper functions
+
+strip_re = re.compile("(\x03|\x02|\x1f|\x0f)(?:,?\d{1,2}(?:,\d{1,2})?)?")
+
+
+def strip(string):
+    return strip_re.sub('', string)
+
+
+# basic text tools
+
+
+## TODO: make this capitalize sentences correctly
+@hook.command("capitalise")
+@hook.command
+def capitalize(text):
+    """capitalize <string> -- Capitalizes <string>.
+    :type text: str
+    """
+    return ". ".join([sentence.capitalize() for sentence in text.split(". ")])
+
+
+@hook.command
+def upper(inp):
+    """upper <string> -- Convert string to uppercase."""
+    return inp.upper()
+
+
+@hook.command
+def lower(inp):
+    """lower <string> -- Convert string to lowercase."""
+    return inp.lower()
+
+
+@hook.command
+def titlecase(inp):
+    """title <string> -- Convert string to title case."""
+    return inp.title()
+
+
+@hook.command
+def swapcase(inp):
+    """swapcase <string> -- Swaps the capitalization of <string>."""
+    return inp.swapcase()
+
+
+# encoding
+
+
+@hook.command("rot13")
+def rot13_encode(text):
+    """rot13 <string> -- Encode <string> with rot13."""
+    encoder = codecs.getencoder("rot-13")
+    return encoder(text)[0]
+
+
+@hook.command("base64")
+def base64_encode(text):
+    """base64 <string> -- Encode <string> with base64."""
+    return base64.b64encode(text.encode()).decode()
+
+
+@hook.command(["debase64", "unbase64"])
+def base64_decode(text, notice):
+    """unbase64 <string> -- Decode <string> with base64."""
+    try:
+        return base64.b64decode(text.encode()).decode()
+    except binascii.Error:
+        notice("Invalid base64 string '{}'".format(text))
+
+
+@hook.command(["isbase64", "checkbase64"])
+def base64_check(text):
+    """isbase64 <string> -- Checks if <string> is a valid base64 encoded string"""
+    try:
+        base64.b64decode(text.encode())
+    except binascii.Error:
+        return "'{}' is not a valid base64 encoded string".format(text)
+    else:
+        return "'{}' is a valid base64 encoded string".format(text)
+
+
+@hook.command
+def unescape(text):
+    """unescape <string> -- Unicode unescapes <string>."""
+    decoder = codecs.getdecoder("unicode_escape")
+    return decoder(text)[0]
+
+
+@hook.command
+def escape(text):
+    """escape <string> -- Unicode escapes <string>."""
+    encoder = codecs.getencoder("unicode_escape")
+    return encoder(text)[0].decode()
+
+# length
+
+
+@hook.command
+def length(text):
+    """length <string> -- Gets the length of <string>"""
+    return "The length of that string is {} characters.".format(len(text))
+
+
+# reverse
+
+
+@hook.command
+def reverse(text):
+    """reverse <string> -- Reverses <string>."""
+    return text[::-1]
+
+
+# hashing
+
+
+@hook.command("hash")
+def hash_command(text):
+    """hash <string> -- Returns hashes of <string>."""
+    return ', '.join(x + ": " + getattr(hashlib, x)(text.encode("utf-8")).hexdigest()
+                     for x in ['md5', 'sha1', 'sha256'])
+
+
+# novelty
+
+
+@hook.command
+def munge(text):
+    """munge <text> -- Munges up <text>."""
+    return formatting.munge(text)
+
+
+# colors - based on code by Reece Selwood - <https://github.com/hitzler/homero>
+
+
+@hook.command
+def rainbow(text):
+    text = str(text)
+    text = strip(text)
+    col = list(colors.items())
+    out = ""
+    l = len(colors)
+    for i, t in enumerate(text):
+        if t == " ":
+            out += t
+        else:
+            out += col[i % l][1] + t
+    return out
+
+
+@hook.command
+def wrainbow(text):
+    text = str(text)
+    col = list(colors.items())
+    text = strip(text).split(' ')
+    out = []
+    l = len(colors)
+    for i, t in enumerate(text):
+        out.append(col[i % l][1] + t)
+    return ' '.join(out)
+
+
+@hook.command
+def usa(text):
+    text = strip(text)
+    c = [colors['red'], '\x0300', colors['blue']]
+    l = len(c)
+    out = ''
+    for i, t in enumerate(text):
+        out += c[i % l] + t
+    return out
diff --git a/disabled/validate.py b/disabled/validate.py
new file mode 100644
index 0000000..88022b7
--- /dev/null
+++ b/disabled/validate.py
@@ -0,0 +1,26 @@
+"""
+Runs a given url through the w3c validator
+
+by Vladi
+"""
+
+from util import hook, http
+
+
+@hook.command('w3c')
+@hook.command
+def validate(inp):
+    """validate <url> -- Runs url through the w3c markup validator."""
+
+    if not inp.startswith('http://'):
+        inp = 'http://' + inp
+
+    url = 'http://validator.w3.org/check?uri=' + http.quote_plus(inp)
+    info = dict(http.open(url).info())
+
+    status = info['x-w3c-validator-status'].lower()
+    if status in ("valid", "invalid"):
+        error_count = info['x-w3c-validator-errors']
+        warning_count = info['x-w3c-validator-warnings']
+        return "{} was found to be {} with {} errors and {} warnings." \
+               " see: {}".format(inp, status, error_count, warning_count, url)
diff --git a/disabled/valvesounds.py b/disabled/valvesounds.py
new file mode 100644
index 0000000..1f5facc
--- /dev/null
+++ b/disabled/valvesounds.py
@@ -0,0 +1,92 @@
+import json
+import urllib
+
+from util import hook, http, web
+
+
+def get_sound_info(game, search):
+    search = search.replace(" ", "+")
+    try:
+        data = http.get_json("http://p2sounds.blha303.com.au/search/%s/%s?format=json" % (game, search))
+    except urllib.error.HTTPError as e:
+        return "Error: " + json.loads(e.read())["error"]
+    items = []
+    for item in data["items"]:
+        if "music" in game:
+            textsplit = item["text"].split('"')
+            text = ""
+            for i in range(len(textsplit)):
+                if i % 2 != 0 and i < 6:
+                    if text:
+                        text += " / " + textsplit[i]
+                    else:
+                        text = textsplit[i]
+        else:
+            text = item["text"]
+        items.append("{} - {} {}".format(item["who"],
+                                         text if len(text) < 325 else text[:325] + "...",
+                                         item["listen"]))
+    if len(items) == 1:
+        return items[0]
+    else:
+        return "{} (and {} others: {})".format(items[0], len(items) - 1, web.haste("\n".join(items)))
+
+
+@hook.command
+def portal2(inp):
+    """portal2 <quote> - Look up Portal 2 quote.
+    Example: .portal2 demand to see life's manager"""
+    return get_sound_info("portal2", inp)
+
+
+@hook.command
+def portal2dlc(inp):
+    """portal2dlc <quote> - Look up Portal 2 DLC quote.
+    Example: .portal2dlc1 these exhibits are interactive"""
+    return get_sound_info("portal2dlc1", inp)
+
+
+@hook.command("portal2pti")
+@hook.command
+def portal2dlc2(inp):
+    """portal2dlc2 <quote> - Look up Portal 2 Perpetual Testing Inititive quote.
+    Example: .portal2 Cave here."""
+    return get_sound_info("portal2dlc2", inp)
+
+
+@hook.command
+def portal2music(inp):
+    """portal2music <title> - Look up Portal 2 music.
+    Example: .portal2music turret opera"""
+    return get_sound_info("portal2music", inp)
+
+
+@hook.command('portal1')
+@hook.command
+def portal(inp):
+    """portal <quote> - Look up Portal quote.
+    Example: .portal The last thing you want to do is hurt me"""
+    return get_sound_info("portal1", inp)
+
+
+@hook.command('portal1music')
+@hook.command
+def portalmusic(inp):
+    """portalmusic <title> - Look up Portal music.
+    Example: .portalmusic still alive"""
+    return get_sound_info("portal1music", inp)
+
+
+@hook.command('tf2sound')
+@hook.command
+def tf2(inp):
+    """tf2 [who - ]<quote> - Look up TF2 quote.
+    Example: .tf2 may i borrow your earpiece"""
+    return get_sound_info("tf2", inp)
+
+
+@hook.command
+def tf2music(inp):
+    """tf2music title - Look up TF2 music lyrics.
+    Example: .tf2music rocket jump waltz"""
+    return get_sound_info("tf2music", inp)
diff --git a/disabled/vimeo.py b/disabled/vimeo.py
new file mode 100644
index 0000000..0a55549
--- /dev/null
+++ b/disabled/vimeo.py
@@ -0,0 +1,20 @@
+from util import hook, http, timeformat
+
+
+@hook.regex(r'vimeo.com/([0-9]+)')
+def vimeo_url(match):
+    """vimeo <url> -- returns information on the Vimeo video at <url>"""
+    info = http.get_json('http://vimeo.com/api/v2/video/%s.json'
+                         % match.group(1))
+
+    if info:
+        info[0]["duration"] = timeformat.format_time(info[0]["duration"])
+        info[0]["stats_number_of_likes"] = format(
+            info[0]["stats_number_of_likes"], ",d")
+        info[0]["stats_number_of_plays"] = format(
+            info[0]["stats_number_of_plays"], ",d")
+        return ("\x02%(title)s\x02 - length \x02%(duration)s\x02 - "
+                "\x02%(stats_number_of_likes)s\x02 likes - "
+                "\x02%(stats_number_of_plays)s\x02 plays - "
+                "\x02%(user_name)s\x02 on \x02%(upload_date)s\x02"
+                % info[0])
diff --git a/disabled/weather.py b/disabled/weather.py
new file mode 100644
index 0000000..b56e2b4
--- /dev/null
+++ b/disabled/weather.py
@@ -0,0 +1,100 @@
+from util import hook, http, web
+
+base_url = "http://api.wunderground.com/api/{}/{}/q/{}.json"
+
+
+@hook.command(autohelp=None)
+def weather(inp, reply=None, db=None, nick=None, bot=None, notice=None):
+    """weather <location> [dontsave] -- Gets weather data
+    for <location> from Wunderground."""
+
+    api_key = bot.config.get("api_keys", {}).get("wunderground")
+
+    if not api_key:
+        return "Error: No wunderground API details."
+
+    # initialise weather DB
+    db.execute("create table if not exists weather(nick primary key, loc)")
+
+    # if there is no input, try getting the users last location from the DB
+    if not inp:
+        location = db.execute("select loc from weather where nick=lower(:nick)",
+                              {"nick": nick}).fetchone()
+        print(location)
+        if not location:
+            # no location saved in the database, send the user help text
+            notice(weather.__doc__)
+            return
+        loc = location[0]
+
+        # no need to save a location, we already have it
+        dontsave = True
+    else:
+        # see if the input ends with "dontsave"
+        dontsave = inp.endswith(" dontsave")
+
+        # remove "dontsave" from the input string after checking for it
+        if dontsave:
+            loc = inp[:-9].strip().lower()
+        else:
+            loc = inp
+
+    location = http.quote_plus(loc)
+
+    request_url = base_url.format(api_key, "geolookup/forecast/conditions", location)
+    response = http.get_json(request_url)
+
+    if 'location' not in response:
+        try:
+            location_id = response['response']['results'][0]['zmw']
+        except KeyError:
+            return "Could not get weather for that location."
+
+        # get the weather again, using the closest match
+        request_url = base_url.format(api_key, "geolookup/forecast/conditions", "zmw:" + location_id)
+        response = http.get_json(request_url)
+
+    if response['location']['state']:
+        place_name = "\x02{}\x02, \x02{}\x02 (\x02{}\x02)".format(response['location']['city'],
+                                                                  response['location']['state'],
+                                                                  response['location']['country'])
+    else:
+        place_name = "\x02{}\x02 (\x02{}\x02)".format(response['location']['city'],
+                                                      response['location']['country'])
+
+    forecast_today = response["forecast"]["simpleforecast"]["forecastday"][0]
+    forecast_tomorrow = response["forecast"]["simpleforecast"]["forecastday"][1]
+
+    # put all the stuff we want to use in a dictionary for easy formatting of the output
+    weather_data = {
+        "place": place_name,
+        "conditions": response['current_observation']['weather'],
+        "temp_f": response['current_observation']['temp_f'],
+        "temp_c": response['current_observation']['temp_c'],
+        "humidity": response['current_observation']['relative_humidity'],
+        "wind_kph": response['current_observation']['wind_kph'],
+        "wind_mph": response['current_observation']['wind_mph'],
+        "wind_direction": response['current_observation']['wind_dir'],
+        "today_conditions": forecast_today['conditions'],
+        "today_high_f": forecast_today['high']['fahrenheit'],
+        "today_high_c": forecast_today['high']['celsius'],
+        "today_low_f": forecast_today['low']['fahrenheit'],
+        "today_low_c": forecast_today['low']['celsius'],
+        "tomorrow_conditions": forecast_tomorrow['conditions'],
+        "tomorrow_high_f": forecast_tomorrow['high']['fahrenheit'],
+        "tomorrow_high_c": forecast_tomorrow['high']['celsius'],
+        "tomorrow_low_f": forecast_tomorrow['low']['fahrenheit'],
+        "tomorrow_low_c": forecast_tomorrow['low']['celsius'],
+        "url": web.isgd(response["current_observation"]['forecast_url'] + "?apiref=e535207ff4757b18")
+    }
+
+    reply("{place} - \x02Current:\x02 {conditions}, {temp_f}F/{temp_c}C, {humidity}, "
+          "Wind: {wind_kph}KPH/{wind_mph}MPH {wind_direction}, \x02Today:\x02 {today_conditions}, "
+          "High: {today_high_f}F/{today_high_c}C, Low: {today_low_f}F/{today_low_c}C. "
+          "\x02Tomorrow:\x02 {tomorrow_conditions}, High: {tomorrow_high_f}F/{tomorrow_high_c}C, "
+          "Low: {tomorrow_low_f}F/{tomorrow_low_c}C - {url}".format(**weather_data))
+
+    if location and not dontsave:
+        db.execute("insert or replace into weather(nick, loc) values (:nick, :loc)",
+                   {"nick": nick.lower(), "loc": loc})
+        db.commit()
diff --git a/disabled/wikipedia.py b/disabled/wikipedia.py
new file mode 100644
index 0000000..e28dd27
--- /dev/null
+++ b/disabled/wikipedia.py
@@ -0,0 +1,49 @@
+"""Searches wikipedia and returns first sentence of article
+Scaevolus 2009"""
+
+import re
+
+from util import hook, http, formatting
+
+
+api_prefix = "http://en.wikipedia.org/w/api.php"
+search_url = api_prefix + "?action=opensearch&format=xml"
+
+paren_re = re.compile('\s*\(.*\)$')
+
+
+@hook.command('w')
+@hook.command
+def wiki(inp):
+    """wiki <phrase> -- Gets first sentence of Wikipedia article on <phrase>."""
+
+    x = http.get_xml(search_url, search=inp)
+
+    ns = '{http://opensearch.org/searchsuggest2}'
+    items = x.findall(ns + 'Section/' + ns + 'Item')
+
+    if not items:
+        if x.find('error') is not None:
+            return 'error: %(code)s: %(info)s' % x.find('error').attrib
+        else:
+            return 'No results found.'
+
+    def extract(item):
+        return [item.find(ns + x).text for x in
+                ('Text', 'Description', 'Url')]
+
+    title, desc, url = extract(items[0])
+
+    if 'may refer to' in desc:
+        title, desc, url = extract(items[1])
+
+    title = paren_re.sub('', title)
+
+    if title.lower() not in desc.lower():
+        desc = title + desc
+
+    desc = ' '.join(desc.split())  # remove excess spaces
+
+    desc = formatting.truncate_str(desc, 200)
+
+    return '{} :: {}'.format(desc, http.quote(url, ':/'))
diff --git a/disabled/wolframalpha.py b/disabled/wolframalpha.py
new file mode 100644
index 0000000..a439897
--- /dev/null
+++ b/disabled/wolframalpha.py
@@ -0,0 +1,55 @@
+import re
+
+from util import hook, http, formatting, web
+
+
+@hook.command(["wa", "calc", "math", "wolframalpha"])
+def wolframalpha(text, bot):
+    """wa <query> -- Computes <query> using Wolfram Alpha."""
+    api_key = bot.config.get("api_keys", {}).get("wolframalpha", None)
+
+    if not api_key:
+        return "error: missing api key"
+
+    url = 'http://api.wolframalpha.com/v2/query?format=plaintext'
+
+    result = http.get_xml(url, input=text, appid=api_key)
+
+    # get the URL for a user to view this query in a browser
+    query_url = "http://www.wolframalpha.com/input/?i=" + \
+                http.quote_plus(text.encode('utf-8'))
+    short_url = web.try_isgd(query_url)
+
+    pod_texts = []
+    for pod in result.xpath("//pod[@primary='true']"):
+        title = pod.attrib['title']
+        if pod.attrib['id'] == 'Input':
+            continue
+
+        results = []
+        for subpod in pod.xpath('subpod/plaintext/text()'):
+            subpod = subpod.strip().replace('\\n', '; ')
+            subpod = re.sub(r'\s+', ' ', subpod)
+            if subpod:
+                results.append(subpod)
+        if results:
+            pod_texts.append(title + ': ' + ', '.join(results))
+
+    ret = ' - '.join(pod_texts)
+
+    if not pod_texts:
+        return 'No results.'
+
+    ret = re.sub(r'\\(.)', r'\1', ret)
+
+    def unicode_sub(match):
+        return chr(int(match.group(1), 16))
+
+    ret = re.sub(r'\\:([0-9a-z]{4})', unicode_sub, ret)
+
+    ret = formatting.truncate_str(ret, 250)
+
+    if not ret:
+        return 'No results.'
+
+    return "{} - {}".format(ret, short_url)
diff --git a/disabled/xkcd.py b/disabled/xkcd.py
new file mode 100644
index 0000000..6ec286c
--- /dev/null
+++ b/disabled/xkcd.py
@@ -0,0 +1,43 @@
+import re
+
+from util import hook, http
+
+
+xkcd_re = (r'(.*:)//(www.xkcd.com|xkcd.com)(.*)', re.I)
+months = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August',
+          9: 'September', 10: 'October', 11: 'November', 12: 'December'}
+
+
+def xkcd_info(xkcd_id, url=False):
+    """ takes an XKCD entry ID and returns a formatted string """
+    data = http.get_json("http://www.xkcd.com/" + xkcd_id + "/info.0.json")
+    date = "{} {} {}".format(data['day'], months[int(data['month'])], data['year'])
+    if url:
+        url = " | http://xkcd.com/" + xkcd_id.replace("/", "")
+    return "xkcd: \x02{}\x02 ({}){}".format(data['title'], date, url if url else "")
+
+
+def xkcd_search(term):
+    search_term = http.quote_plus(term)
+    soup = http.get_soup("http://www.ohnorobot.com/index.pl?s={}&Search=Search&"
+                         "comic=56&e=0&n=0&b=0&m=0&d=0&t=0".format(search_term))
+    result = soup.find('li')
+    if result:
+        url = result.find('div', {'class': 'tinylink'}).text
+        xkcd_id = url[:-1].split("/")[-1]
+        print(xkcd_id)
+        return xkcd_info(xkcd_id, url=True)
+    else:
+        return "No results found!"
+
+
+@hook.regex(*xkcd_re)
+def xkcd_url(match):
+    xkcd_id = match.group(3).split(" ")[0].split("/")[1]
+    return xkcd_info(xkcd_id)
+
+
+@hook.command
+def xkcd(inp):
+    """xkcd <search term> - Search for xkcd comic matching <search term>"""
+    return xkcd_search(inp)
diff --git a/disabled/yahooanswers.py b/disabled/yahooanswers.py
new file mode 100644
index 0000000..55b07c6
--- /dev/null
+++ b/disabled/yahooanswers.py
@@ -0,0 +1,16 @@
+from util import hook, web, formatting
+
+
+@hook.command
+def answer(text):
+    """answer <query> -- find the answer to a question on Yahoo! Answers"""
+
+    query = "SELECT Subject, ChosenAnswer, Link FROM answers.search WHERE query=@query LIMIT 1"
+    result = web.query(query, {"query": text.strip()}).one()
+
+    short_url = web.try_isgd(result["Link"])
+
+    # we split the answer and .join() it to remove newlines/extra spaces
+    answer_text = formatting.truncate_str(' '.join(result["ChosenAnswer"].split()), 80)
+
+    return '\x02{}\x02 "{}" - {}'.format(result["Subject"], answer_text, short_url)
diff --git a/disabled/youtube.py b/disabled/youtube.py
new file mode 100644
index 0000000..6fbdaa9
--- /dev/null
+++ b/disabled/youtube.py
@@ -0,0 +1,137 @@
+import re
+import time
+
+from util import hook, http, timeformat
+
+
+youtube_re = (r'(?:youtube.*?(?:v=|/v/)|youtu\.be/|yooouuutuuube.*?id=)'
+              '([-_a-zA-Z0-9]+)', re.I)
+
+base_url = 'http://gdata.youtube.com/feeds/api/'
+api_url = base_url + 'videos/{}?v=2&alt=jsonc'
+search_api_url = base_url + 'videos?v=2&alt=jsonc&max-results=1'
+video_url = "http://youtu.be/%s"
+
+
+def plural(num=0, text=''):
+    return "{:,} {}{}".format(num, text, "s"[num == 1:])
+
+
+def get_video_description(video_id):
+    request = http.get_json(api_url.format(video_id))
+
+    if request.get('error'):
+        return
+
+    data = request['data']
+
+    out = '\x02{}\x02'.format(data['title'])
+
+    if not data.get('duration'):
+        return out
+
+    length = data['duration']
+    out += ' - length \x02{}\x02'.format(timeformat.format_time(length, simple=True))
+
+    if 'ratingCount' in data:
+        # format
+        likes = plural(int(data['likeCount']), "like")
+        dislikes = plural(data['ratingCount'] - int(data['likeCount']), "dislike")
+
+        percent = 100 * float(data['likeCount']) / float(data['ratingCount'])
+        out += ' - {}, {} (\x02{:.1f}\x02%)'.format(likes,
+                                                    dislikes, percent)
+
+    if 'viewCount' in data:
+        views = data['viewCount']
+        out += ' - \x02{:,}\x02 view{}'.format(views, "s"[views == 1:])
+
+    try:
+        uploader = http.get_json(base_url + "users/{}?alt=json".format(data["uploader"]))["entry"]["author"][0]["name"][
+            "$t"]
+    except:
+        uploader = data["uploader"]
+
+    upload_time = time.strptime(data['uploaded'], "%Y-%m-%dT%H:%M:%S.000Z")
+    out += ' - \x02{}\x02 on \x02{}\x02'.format(uploader,
+                                                time.strftime("%Y.%m.%d", upload_time))
+
+    if 'contentRating' in data:
+        out += ' - \x034NSFW\x02'
+
+    return out
+
+
+@hook.regex(*youtube_re)
+def youtube_url(match):
+    return get_video_description(match.group(1))
+
+
+@hook.command('you')
+@hook.command('yt')
+@hook.command('y')
+@hook.command
+def youtube(inp):
+    """youtube <query> -- Returns the first YouTube search result for <query>."""
+    request = http.get_json(search_api_url, q=inp)
+
+    if 'error' in request:
+        return 'error performing search'
+
+    if request['data']['totalItems'] == 0:
+        return 'no results found'
+
+    video_id = request['data']['items'][0]['id']
+
+    return get_video_description(video_id) + " - " + video_url % video_id
+
+
+@hook.command('ytime')
+@hook.command
+def youtime(inp):
+    """youtime <query> -- Gets the total run time of the first YouTube search result for <query>."""
+    request = http.get_json(search_api_url, q=inp)
+
+    if 'error' in request:
+        return 'error performing search'
+
+    if request['data']['totalItems'] == 0:
+        return 'no results found'
+
+    video_id = request['data']['items'][0]['id']
+    request = http.get_json(api_url.format(video_id))
+
+    if request.get('error'):
+        return
+    data = request['data']
+
+    if not data.get('duration'):
+        return
+
+    length = data['duration']
+    views = data['viewCount']
+    total = int(length * views)
+
+    length_text = timeformat.format_time(length, simple=True)
+    total_text = timeformat.format_time(total, accuracy=8)
+
+    return 'The video \x02{}\x02 has a length of {} and has been viewed {:,} times for ' \
+           'a total run time of {}!'.format(data['title'], length_text, views,
+                                            total_text)
+
+
+ytpl_re = (r'(.*:)//(www.youtube.com/playlist|youtube.com/playlist)(:[0-9]+)?(.*)', re.I)
+
+
+@hook.regex(*ytpl_re)
+def ytplaylist_url(match):
+    location = match.group(4).split("=")[-1]
+    try:
+        soup = http.get_soup("https://www.youtube.com/playlist?list=" + location)
+    except Exception:
+        return "\x034\x02Invalid response."
+    title = soup.find('title').text.split('-')[0].strip()
+    author = soup.find('img', {'class': 'channel-header-profile-image'})['title']
+    num_videos = soup.find('ul', {'class': 'header-stats'}).findAll('li')[0].text.split(' ')[0]
+    views = soup.find('ul', {'class': 'header-stats'}).findAll('li')[1].text.split(' ')[0]
+    return "\x02{}\x02 - \x02{}\x02 views - \x02{}\x02 videos - \x02{}\x02".format(title, views, num_videos, author)
diff --git a/modules/attacks.py b/modules/attacks.py
deleted file mode 100644
index 39a3bb7..0000000
--- a/modules/attacks.py
+++ /dev/null
@@ -1,90 +0,0 @@
-import random
-import re
-
-from util import hook
-
-with open("data/larts.txt") as f:
-    larts = [line.strip() for line in f.readlines()
-             if not line.startswith("//")]
-
-with open("data/insults.txt") as f:
-    insults = [line.strip() for line in f.readlines()
-               if not line.startswith("//")]
-
-with open("data/flirts.txt") as f:
-    flirts = [line.strip() for line in f.readlines()
-              if not line.startswith("//")]
-
-
-def is_self(conn, target):
-    """
-    :type conn: core.irc.BotConnection
-    :type target: str
-    """
-    if re.search("(^..?.?.?self|{})".format(re.escape(conn.nick.lower())), target.lower()):
-        return True
-    else:
-        return False
-
-
-@hook.command(threaded=False)
-def lart(text, conn, nick, notice, action):
-    """lart <user> -- LARTs <user>.
-    :type text: str
-    :type conn: core.irc.BotConnection
-    :type nick: str
-    """
-    target = text.strip()
-
-    if " " in target:
-        notice("Invalid username!")
-        return
-
-    # if the user is trying to make the bot target itself, target them
-    if is_self(conn, target):
-        target = nick
-
-    phrase = random.choice(larts)
-
-    # act out the message
-    action(phrase.format(user=target))
-
-
-@hook.command(threaded=False)
-def insult(text, conn, nick, notice, message):
-    """insult <user> -- Makes the bot insult <user>.
-    :type text: str
-    :type conn: core.irc.BotConnection
-    :type nick: str
-    """
-    target = text.strip()
-
-    if " " in target:
-        notice("Invalid username!")
-        return
-
-    # if the user is trying to make the bot target itself, target them
-    if is_self(conn, target):
-        target = nick
-
-    message("{}, {}".format(target, random.choice(insults)))
-
-
-@hook.command(threaded=False)
-def flirt(text, conn, nick, notice, message):
-    """flirt <user> -- Makes the bot flirt with <user>.
-    :type text: str
-    :type conn: core.irc.BotConnection
-    :type nick: str
-    """
-    target = text.strip()
-
-    # if the user is trying to make the bot target itself, target them
-    if " " in target:
-        notice("Invalid username!")
-        return
-
-    if is_self(conn, target):
-        target = nick
-
-    message('{}, {}'.format(target, random.choice(flirts)))
diff --git a/modules/brainfuck.py b/modules/brainfuck.py
deleted file mode 100644
index 9f04bcc..0000000
--- a/modules/brainfuck.py
+++ /dev/null
@@ -1,89 +0,0 @@
-"""brainfuck interpreter adapted from (public domain) code at
-http://brainfuck.sourceforge.net/brain.py"""
-
-import re
-import random
-
-from util import hook
-
-BUFFER_SIZE = 5000
-MAX_STEPS = 1000000
-
-
-@hook.command(["brainfuck", "bf"], threaded=False)
-def bf(text):
-    """bf <prog> -- Executes <prog> as Brainfuck code.
-    :type text: str
-    """
-
-    program = re.sub('[^][<>+-.,]', '', text)
-
-    # create a dict of brackets pairs, for speed later on
-    brackets = {}
-    open_brackets = []
-    for pos in range(len(program)):
-        if program[pos] == '[':
-            open_brackets.append(pos)
-        elif program[pos] == ']':
-            if len(open_brackets) > 0:
-                brackets[pos] = open_brackets[-1]
-                brackets[open_brackets[-1]] = pos
-                open_brackets.pop()
-            else:
-                return "Unbalanced brackets"
-    if len(open_brackets) != 0:
-        return "Unbalanced brackets"
-
-    # now we can start interpreting
-    ip = 0  # instruction pointer
-    mp = 0  # memory pointer
-    steps = 0
-    memory = [0] * BUFFER_SIZE  # initial memory area
-    rightmost = 0
-    output = ""  # we'll save the output here
-
-    # the main program loop:
-    while ip < len(program):
-        c = program[ip]
-        if c == '+':
-            memory[mp] += 1 % 256
-        elif c == '-':
-            memory[mp] -= 1 % 256
-        elif c == '>':
-            mp += 1
-            if mp > rightmost:
-                rightmost = mp
-                if mp >= len(memory):
-                    # no restriction on memory growth!
-                    memory.extend([0] * BUFFER_SIZE)
-        elif c == '<':
-            mp -= 1 % len(memory)
-        elif c == '.':
-            output += chr(memory[mp])
-            if len(output) > 500:
-                break
-        elif c == ',':
-            memory[mp] = random.randint(1, 255)
-        elif c == '[':
-            if memory[mp] == 0:
-                ip = brackets[ip]
-        elif c == ']':
-            if memory[mp] != 0:
-                ip = brackets[ip]
-
-        ip += 1
-        steps += 1
-        if steps > MAX_STEPS:
-            if not output:
-                output = "(no output)"
-            output += "(exceeded {} iterations)".format(MAX_STEPS)
-            break
-
-    stripped_output = re.sub(r'[\x00-\x1F]', '', output)
-
-    if not stripped_output:
-        if output:
-            return "No printable output"
-        return "No output"
-
-    return stripped_output[:430]
diff --git a/modules/cake.py b/modules/cake.py
deleted file mode 100644
index c6f81c9..0000000
--- a/modules/cake.py
+++ /dev/null
@@ -1,24 +0,0 @@
-# coding=utf-8
-import re
-import random
-
-from util import hook
-
-cakes = ['Chocolate', 'Ice Cream', 'Angel', 'Boston Cream', 'Birthday', 'Bundt', 'Carrot', 'Coffee', 'Devils', 'Fruit', 'Gingerbread', 'Pound', 'Red Velvet', 'Stack', 'Welsh', 'Yokan']
-
-
-@hook.command(threaded=False)
-def cake(inp, action=None):
-    """cake <user> - Gives <user> an awesome cake."""
-    inp = inp.strip()
-
-    if not re.match("^[A-Za-z0-9_|.-\]\[]*$", inp.lower()):
-        return "I can't give an awesome cake to that user!"
-
-    cake_type = random.choice(cakes)
-    size = random.choice(['small', 'little', 'mid-sized', 'medium-sized', 'large', 'gigantic'])
-    flavor = random.choice(['tasty', 'delectable', 'delicious', 'yummy', 'toothsome', 'scrumptious', 'luscious'])
-    method = random.choice(['makes', 'gives', 'gets', 'buys'])
-    side_dish = random.choice(['glass of chocolate milk', 'bowl of ice cream', 'jar of cookies', 'bowl of chocolate sauce'])
-
-    action("{} {} a {} {} {} cake and serves it with a small {}!".format(method, inp, flavor, size, cake_type, side_dish))
diff --git a/modules/choose.py b/modules/choose.py
deleted file mode 100644
index 2fba5cc..0000000
--- a/modules/choose.py
+++ /dev/null
@@ -1,16 +0,0 @@
-import re
-import random
-
-from util import hook
-
-
-@hook.command(threaded=False)
-def choose(text, notice):
-    """choose <choice1>, [choice2], [choice3], etc. -- Randomly picks one of the given choices.
-    :type text: str
-    """
-    choices = re.findall(r'([^,\s]+)', text)
-    if len(choices) == 1:
-        notice(choose.__doc__)
-        return
-    return random.choice(choices)
diff --git a/modules/coin.py b/modules/coin.py
deleted file mode 100644
index a55fc2e..0000000
--- a/modules/coin.py
+++ /dev/null
@@ -1,28 +0,0 @@
-import random
-
-from util import hook
-
-
-@hook.command(threaded=False, autohelp=False)
-def coin(text, notice, action):
-    """coin [amount] -- Flips [amount] of coins.
-    :type text: str
-    """
-
-    if text:
-        try:
-            amount = int(text)
-        except (ValueError, TypeError):
-            notice("Invalid input '{}': not a number".format(text))
-            return
-    else:
-        amount = 1
-
-    if amount == 1:
-        action("flips a coin and gets {}.".format(random.choice(["heads", "tails"])))
-    elif amount == 0:
-        action("makes a coin flipping motion")
-    else:
-        heads = int(random.normalvariate(.5 * amount, (.75 * amount) ** .5))
-        tails = amount - heads
-        action("flips {} coins and gets {} heads and {} tails.".format(amount, heads, tails))
diff --git a/modules/correction.py b/modules/correction.py
deleted file mode 100644
index c5c574c..0000000
--- a/modules/correction.py
+++ /dev/null
@@ -1,40 +0,0 @@
-import re
-
-from util import hook
-
-correction_re = re.compile(r"^[sS]/([^/]*)/([^/]*)(/.*)?\s*$")
-
-
-@hook.regex(correction_re, threaded=False)
-def correction(match, conn, chan, message):
-    """
-    :type match: re.__Match
-    :type conn: core.irc.BotConnection
-    :type chan: str
-    """
-    print(match.groups())
-    to_find, replacement, find_nick = match.groups()
-    if find_nick:
-        find_nick = find_nick[1:].lower()  # Remove the '/'
-
-    find_re = re.compile("(?i){}".format(re.escape(to_find)))
-
-    for item in conn.history[chan].__reversed__():
-        nick, timestamp, msg = item
-        if correction_re.match(msg):
-            # don't correct corrections, it gets really confusing
-            continue
-        if find_nick:
-            if find_nick != nick.lower():
-                continue
-        if find_re.search(msg):
-            if "\x01ACTION" in msg:
-                msg = msg.replace("\x01ACTION ", "/me ").replace("\x01", "")
-            message("Correction, <{}> {}".format(nick, find_re.sub("\x02" + replacement + "\x02", msg)))
-            return
-        else:
-            continue
-    if find_nick:
-        return "Did not find {} in any recent messages from {}.".format(to_find, find_nick)
-    else:
-        return "Did not find {} in any recent messages.".format(to_find)
diff --git a/modules/cryptocoins.py b/modules/cryptocoins.py
deleted file mode 100644
index 6a449a6..0000000
--- a/modules/cryptocoins.py
+++ /dev/null
@@ -1,63 +0,0 @@
-from util import http, hook
-
-## CONSTANTS
-
-exchanges = {
-    "blockchain": {
-        "api_url": "https://blockchain.info/ticker",
-        "func": lambda data: "Blockchain // Buy: \x0307${:,.2f}\x0f -"
-                             " Sell: \x0307${:,.2f}\x0f".format(data["USD"]["buy"], data["USD"]["sell"])
-    },
-    "coinbase": {
-        "api_url": "https://coinbase.com/api/v1/prices/spot_rate",
-        "func": lambda data: "Coinbase // Current: \x0307${:,.2f}\x0f".format(float(data['amount']))
-    },
-    "bitpay": {
-        "api_url": "https://bitpay.com/api/rates",
-        "func": lambda data: "Bitpay // Current: \x0307${:,.2f}\x0f".format(data[0]['rate'])
-    },
-    "bitstamp": {
-        "api_url": "https://www.bitstamp.net/api/ticker/",
-        "func": lambda data: "BitStamp // Current: \x0307${:,.2f}\x0f - High: \x0307${:,.2f}\x0f -"
-                             " Low: \x0307${:,.2f}\x0f - Volume: {:,.2f} BTC".format(float(data['last']),
-                                                                                     float(data['high']),
-                                                                                     float(data['low']),
-                                                                                     float(data['volume']))
-    }
-}
-
-
-## HOOK FUNCTIONS
-
-@hook.command(["btc", "bitcoin"], threaded=True, autohelp=False)
-def bitcoin(text, notice):
-    """bitcoin <exchange> -- Gets current exchange rate for bitcoins from several exchanges, default is Blockchain.
-    Supports MtGox, Bitpay, Coinbase and BitStamp.
-    :type text: str
-    """
-    text = text.lower()
-
-    if text:
-        if text in exchanges:
-            exchange = exchanges[text]
-        else:
-            valid_exchanges = list(exchanges.keys())
-            notice("Invalid exchange '{}', valid exchanges are {} and {}".format(text, ", ".join(valid_exchanges[:-1]),
-                                                                                 valid_exchanges[-1]))
-            return
-    else:
-        exchange = exchanges["blockchain"]
-
-    data = http.get_json(exchange["api_url"])
-    func = exchange["func"]
-    return func(data)
-
-
-@hook.command(["ltc", "litecoin"], threaded=True, autohelp=False)
-def litecoin(message):
-    """litecoin -- gets current exchange rate for litecoins from BTC-E"""
-    data = http.get_json("https://btc-e.com/api/2/ltc_usd/ticker")
-    ticker = data['ticker']
-    message("Current: \x0307${:,.2f}\x0f - High: \x0307${:,.2f}\x0f"
-            " - Low: \x0307${:,.2f}\x0f - Volume: {:,.2f} LTC".format(ticker['buy'], ticker['high'], ticker['low'],
-                                                                      ticker['vol_cur']))
diff --git a/modules/cypher.py b/modules/cypher.py
deleted file mode 100644
index e2fcc7e..0000000
--- a/modules/cypher.py
+++ /dev/null
@@ -1,63 +0,0 @@
-import base64
-import binascii
-
-from util import hook
-
-
-def encode(password, text):
-    """
-    :type password: str
-    :type text: str
-    """
-    enc = []
-    for i in range(len(text)):
-        key_c = password[i % len(password)]
-        enc_c = chr((ord(text[i]) + ord(key_c)) % 256)
-        enc.append(enc_c)
-    return base64.urlsafe_b64encode("".join(enc).encode()).decode()
-
-
-def decode(password, encoded, notice):
-    """
-    :type password: str
-    :type encoded: str
-    """
-    dec = []
-    try:
-        encoded_bytes = base64.urlsafe_b64decode(encoded.encode()).decode()
-    except binascii.Error:
-        notice("Invalid input '{}'".format(encoded))
-        return
-    for i in range(len(encoded_bytes)):
-        key_c = password[i % len(password)]
-        dec_c = chr((256 + ord(encoded_bytes[i]) - ord(key_c)) % 256)
-        dec.append(dec_c)
-    return "".join(dec)
-
-
-@hook.command(threaded=False)
-def cypher(text, notice):
-    """cypher <pass> <string> -- Cyphers <string> with <password>.
-    :type text: str
-    """
-    split = text.split(None, 1)
-    if len(split) < 2:
-        notice(cypher.__doc__)
-        return
-    password = split[0]
-    plaintext = split[1]
-    return encode(password, plaintext)
-
-
-@hook.command(threaded=False)
-def decypher(text, notice):
-    """decypher <pass> <string> -- Decyphers <string> with <password>.
-    :type text: str
-    """
-    split = text.split(None, 1)
-    if len(split) < 2:
-        notice(decypher.__doc__)
-        return
-    password = split[0]
-    encoded = split[1]
-    return decode(password, encoded, notice)
diff --git a/modules/dbtest.py b/modules/dbtest.py
deleted file mode 100644
index 1fe7a98..0000000
--- a/modules/dbtest.py
+++ /dev/null
@@ -1,36 +0,0 @@
-from sqlalchemy import Table, Column, String
-
-from util import hook, botvars
-
-users = Table(
-    'user_table', botvars.metadata,
-    Column('name', String),
-    Column('phone', String)
-)
-
-
-@hook.command(threaded=True)
-def dbadduser(text, db):
-    """
-    :type text: str
-    :type db: sqlalchemy.orm.Session
-    """
-
-    data = text.split()
-    values = {
-        "name": data[0],
-        "phone": data[1]
-    }
-
-    query = users.insert(values=values)
-    # OR users.insert().values(**values) - http://docs.sqlalchemy.org/en/rel_0_9/core/tutorial.html
-
-    db.execute(query)
-    db.commit()
-
-
-@hook.command(threaded=True, autohelp=False)
-def select(db, message):
-    results = db.execute(users.select())
-    for row in results:
-        message("name: {}, phone: {}".format(row.name, row.phone))
diff --git a/modules/dice.py b/modules/dice.py
deleted file mode 100644
index bafb513..0000000
--- a/modules/dice.py
+++ /dev/null
@@ -1,97 +0,0 @@
-# Written by Scaevolus, updated by Lukeroge
-
-
-import re
-import random
-
-from util import hook
-
-whitespace_re = re.compile(r'\s+')
-valid_diceroll = re.compile(r'^([+-]?(?:\d+|\d*d(?:\d+|F))(?:[+-](?:\d+|\d*d(?:\d+|F)))*)( .+)?$', re.I)
-sign_re = re.compile(r'[+-]?(?:\d*d)?(?:\d+|F)', re.I)
-split_re = re.compile(r'([\d+-]*)d?(F|\d*)', re.I)
-
-
-def n_rolls(count, n):
-    """roll an n-sided die count times
-    :type count: int | str
-    :type n: int
-    """
-    if n == "F":
-        return [random.randint(-1, 1) for x in range(min(count, 100))]
-    if n < 2:  # it's a coin
-        if count < 100:
-            return [random.randint(0, 1) for x in range(count)]
-        else:  # fake it
-            return [int(random.normalvariate(.5 * count, (.75 * count) ** .5))]
-    else:
-        if count < 100:
-            return [random.randint(1, n) for x in range(count)]
-        else:  # fake it
-            return [int(random.normalvariate(.5 * (1 + n) * count,
-                                             (((n + 1) * (2 * n + 1) / 6. -
-                                               (.5 * (1 + n)) ** 2) * count) ** .5))]
-
-
-#@hook.regex(valid_diceroll, re.I)
-@hook.command(["roll", "dice"], threaded=False)
-def dice(text, notice):
-    """dice <dice roll> -- Simulates dice rolls. Example: 'dice 2d20-d5+4 roll 2': D20s, subtract 1D5, add 4
-    :type text: str
-    """
-
-    if hasattr(text, "groups"):
-        text, desc = text.groups()
-    else:  # type(text) == str
-        match = valid_diceroll.match(whitespace_re.sub("", text))
-        if match:
-            text, desc = match.groups()
-        else:
-            notice("Invalid dice roll '{}'".format(text))
-            return
-
-    if "d" not in text:
-        return
-
-    spec = whitespace_re.sub('', text)
-    if not valid_diceroll.match(spec):
-        notice("Invalid dice roll '{}'".format(text))
-        return
-    groups = sign_re.findall(spec)
-
-    total = 0
-    rolls = []
-
-    for roll in groups:
-        count, side = split_re.match(roll).groups()
-        count = int(count) if count not in " +-" else 1
-        if side.upper() == "F":  # fudge dice are basically 1d3-2
-            for fudge in n_rolls(count, "F"):
-                if fudge == 1:
-                    rolls.append("\x033+\x0F")
-                elif fudge == -1:
-                    rolls.append("\x034-\x0F")
-                else:
-                    rolls.append("0")
-                total += fudge
-        elif side == "":
-            total += count
-        else:
-            side = int(side)
-            try:
-                if count > 0:
-                    d = n_rolls(count, side)
-                    rolls += list(map(str, d))
-                    total += sum(d)
-                else:
-                    d = n_rolls(-count, side)
-                    rolls += [str(-x) for x in d]
-                    total -= sum(d)
-            except OverflowError:
-                # I have never seen this happen. If you make this happen, you win a cookie
-                return "Thanks for overflowing a float, jerk >:["
-
-    if desc:
-        return "{}: {} ({})".format(desc.strip(), total, ", ".join(rolls))
-    else:
-        return "{} ({})".format(total, ", ".join(rolls))
diff --git a/modules/dictionary.py b/modules/dictionary.py
deleted file mode 100644
index 10a4fee..0000000
--- a/modules/dictionary.py
+++ /dev/null
@@ -1,96 +0,0 @@
-# Plugin by GhettoWizard and Scaevolus
-import re
-
-from util import hook
-from util import http
-
-
-def format_output(h, definition, show_examples):
-    """
-    :type h: lxml.etree._Element._Element
-    :type definition: tuple
-    """
-    result = '{}: '.format(h.xpath('//dt[@class="title-word"]/a/text()')[0])
-
-    correction = h.xpath('//span[@class="correct-word"]/text()')
-    if correction:
-        result = 'Definition for "{}": '.format(correction[0])
-
-    sections = []
-    for section in definition:
-        if section.attrib['class'] == 'article':
-            sections += [[section.text_content() + ': ']]
-        elif section.attrib['class'] == 'example':
-            if show_examples:
-                sections[-1][-1] += ' ' + section.text_content()
-        else:
-            sections[-1] += [section.text_content()]
-
-    for article in sections:
-        result += article[0]
-        if len(article) > 2:
-            result += ' '.join('{}. {}'.format(n + 1, section)
-                               for n, section in enumerate(article[1:]))
-        else:
-            result += article[1] + ' '
-
-    synonyms = h.xpath('//dd[@class="synonyms"]')
-    if synonyms:
-        result += synonyms[0].text_content()
-
-    result = re.sub(r'\s+', ' ', result)
-    result = re.sub('\xb0', '', result)
-    return result
-
-
-@hook.command(["dictionary", "define"], threaded=True)
-def define(text):
-    """define <word> -- Fetches definition of <word>.
-    :type text: str
-    """
-
-    url = 'http://ninjawords.com/'
-
-    h = http.get_html(url + http.quote_plus(text))
-
-    definition = h.xpath('//dd[@class="article"] | '
-                         '//div[@class="definition"] |'
-                         '//div[@class="example"]')
-
-    if not definition:
-        return 'No results for ' + text + ' :('
-
-    result = format_output(h, definition, True)
-    if len(result) > 450:
-        result = format_output(h, definition, False)
-
-    if len(result) > 450:
-        result = result[:result.rfind(' ', 0, 450)]
-        result = re.sub(r'[^A-Za-z]+\.?$', '', result) + ' ...'
-
-    return result
-
-
-@hook.command(["e", "etymology"], threaded=True)
-def etymology(text):
-    """etymology <word> -- Retrieves the etymology of <word>.
-    :type text: str
-    """
-
-    url = 'http://www.etymonline.com/index.php'
-
-    h = http.get_html(url, term=text)
-
-    etym = h.xpath('//dl')
-
-    if not etym:
-        return 'No etymology found for {} :('.format(text)
-
-    etym = etym[0].text_content()
-
-    etym = ' '.join(etym.split())
-
-    if len(etym) > 400:
-        etym = etym[:etym.rfind(' ', 0, 400)] + ' ...'
-
-    return etym
diff --git a/modules/domainr.py b/modules/domainr.py
deleted file mode 100644
index 4707dc9..0000000
--- a/modules/domainr.py
+++ /dev/null
@@ -1,34 +0,0 @@
-from util import hook, http
-
-formats = {
-    "taken": "\x034{domain}\x0f{path}",
-    "available": "\x033{domain}\x0f{path}",
-    "other": "\x031{domain}\x0f{path}"
-}
-
-
-def format_domain(domain):
-    """
-    :type domain: dict[str, str]
-    """
-    if domain["availability"] in formats:
-        domainformat = formats[domain["availability"]]
-    else:
-        domainformat = formats["other"]
-    return domainformat.format(**domain)
-
-
-@hook.command(["domain", "domainr"], threaded=True)
-def domainr(text):
-    """domainr <domain> - Use domain.nr's API to search for a domain, and similar domains.
-    :type text: str
-    """
-    try:
-        data = http.get_json('http://domai.nr/api/json/search?q=' + text)
-    except (http.URLError, http.HTTPError):
-        return "Unable to get data for some reason. Try again later."
-    if data['query'] == "":
-        return "An error occurred: {status} - {message}".format(**data['error'])
-
-    domains = [format_domain(domain) for domain in data["results"]]
-    return "Domains: {}".format(", ".join(domains))
diff --git a/modules/drama.py b/modules/drama.py
deleted file mode 100644
index f41b34b..0000000
--- a/modules/drama.py
+++ /dev/null
@@ -1,32 +0,0 @@
-import re
-from urllib import parse
-
-from util import hook, http, formatting
-
-
-api_url = "http://encyclopediadramatica.se/api.php?action=opensearch"
-ed_url = "http://encyclopediadramatica.se/"
-
-
-@hook.command(threaded=True)
-def drama(text):
-    """drama <phrase> -- Gets the first paragraph of
-    the Encyclopedia Dramatica article on <phrase>."""
-
-    data = http.get_json(api_url, search=text)
-
-    if not data[1]:
-        return "No results found."
-    article_name = data[1][0].replace(' ', '_')
-
-    url = ed_url + parse.quote(article_name, '')
-    page = http.get_html(url)
-
-    for p in page.xpath('//div[@id="bodyContent"]/p'):
-        if p.text_content():
-            summary = " ".join(p.text_content().splitlines())
-            summary = re.sub("\[\d+\]", "", summary)
-            summary = formatting.truncate_str(summary, 220)
-            return "{} - {}".format(summary, url)
-
-    return "Unknown Error."
diff --git a/modules/eightball.py b/modules/eightball.py
deleted file mode 100644
index dd3e316..0000000
--- a/modules/eightball.py
+++ /dev/null
@@ -1,27 +0,0 @@
-import os
-import random
-
-from util import hook, formatting
-
-color_codes = {
-    "<r>": "\x02\x0305",
-    "<g>": "\x02\x0303",
-    "<y>": "\x02"
-}
-
-
-@hook.onload()
-def load_responses(bot):
-    path = os.path.join(bot.data_dir, "8ball_responses.txt")
-    global responses
-    with open(path) as f:
-        responses = [line.strip() for line in
-                     f.readlines() if not line.startswith("//")]
-
-
-@hook.command(["8ball", "8", "eightball"], threaded=False)
-def eightball(action):
-    """8ball <question> -- The all knowing magic eight ball, in electronic form. Ask and it shall be answered!"""
-
-    magic = formatting.multiword_replace(random.choice(responses), color_codes)
-    action("shakes the magic 8 ball... {}".format(magic))
diff --git a/modules/eliralin_teamcity.py b/modules/eliralin_teamcity.py
deleted file mode 100644
index 2e5ecf1..0000000
--- a/modules/eliralin_teamcity.py
+++ /dev/null
@@ -1,158 +0,0 @@
-from xml.etree.ElementTree import ParseError
-import traceback
-from xml.etree import ElementTree
-import time
-
-import requests
-from requests.auth import HTTPBasicAuth
-
-from util import hook
-
-teamcity_url = "http://ci.daboross.net/ci"
-
-
-class ProjectDatabase:
-    def __init__(self):
-        self.reload_timestamp = 0
-        self.projects = []
-        self.username = "default"
-        self.password = "default"
-        self.teamcity_url = teamcity_url
-        self.loaded_key = False
-
-    def download(self, url):
-        if url.startswith("/httpAuth"):
-            data = requests.get(self.teamcity_url + url, auth=HTTPBasicAuth(self.username, self.password)).text
-        elif url.startswith("/guestAuth"):
-            data = requests.get(self.teamcity_url + url).text
-        elif self.loaded_key:
-            data = requests.get("{}/httpAuth{}".format(self.teamcity_url, url),
-                                auth=HTTPBasicAuth(self.username, self.password)).text
-        else:
-            data = requests.get("{}/guestAuth{}".format(self.teamcity_url, url)).text
-        try:
-            return ElementTree.fromstring(data)
-        except ParseError:
-            print("Error loading {} ({})".format(url, data))
-            raise
-
-    def load_key(self, bot):
-        if not self.loaded_key:
-            api_keys = bot.config.get("api_keys", None)
-            if api_keys:
-                self.username = api_keys.get("teamcity_username")
-                self.password = api_keys.get("teamcity_password")
-                self.loaded_key = True
-            else:
-                print("Warning, couldn't find teamcity api key")
-
-    def reload_database(self):
-        self.reload_timestamp = time.time()
-        self.projects = []
-        root = self.download("/app/rest/projects")
-        for project in root:
-            if project.get("id") != "_Root":
-                self.projects.append(Project(project))
-
-    def ensure_loaded(self, bot=None):
-        if bot and not self.loaded_key:
-            self.load_key(bot)
-        if self.reload_timestamp == 0:
-            self.reload_database()
-
-    def after_check(self):
-        if time.time() > self.reload_timestamp + 300:
-            self.reload_database()
-
-
-class Project:
-    def __init__(self, project):
-        self.name = project.get("name")
-        self.project_id = project.get("id")
-        self.project_url = project.get("href")
-        self.downloads = []
-        project_element = database.download(self.project_url)
-        build_types = project_element.find("buildTypes")
-        if build_types and len(build_types) > 0:
-            for build_type in build_types.findall("buildType"):
-                download = find_download_url(build_type)
-                if download:
-                    self.downloads.append(download)
-
-        self.search_name = self.name.lower()
-        self.search_id = self.project_id.lower()
-
-    def search(self, search):
-        if search == self.search_name or search == self.search_id:
-            return 2
-        elif search in self.search_name or search in self.search_id:
-            return 1
-        return 0
-
-
-def find_download_url(build_type_element):
-    try:
-        build_type_id = build_type_element.get("id")
-        href = build_type_element.get("href")
-        builds_url = database.download(href).find("builds").get("href")
-        build_url = database.download(builds_url).find("build").get("href")
-        artifacts_url = database.download(build_url).find("artifacts").get("href")
-        files = database.download(artifacts_url).findall("file")
-        filenames = [download_file.get("name") for download_file in files]
-        return {"id": build_type_id, "files": filenames}
-    except AttributeError:
-        traceback.print_exc()
-        return None
-    except ParseError:
-        traceback.print_exc()
-        return None
-
-
-database = ProjectDatabase()
-
-
-@hook.command(["teamcity", "ci"])
-def teamcity(inp, bot, reply, message):
-    """teamcity [project] - Searches for project on teamcity, and displays project URL and download"""
-    database.ensure_loaded(bot=bot)
-    search = inp.lower()
-    level_found = 0
-    project_found = None
-    other_matches = []
-    for project in database.projects:
-        level = project.search(search)
-        if level > level_found:
-            if project_found:
-                other_matches.append(project_found.name)
-            project_found = project
-            level_found = level
-        elif level > 0:
-            other_matches.append(project.name)
-
-    if project_found is not None:
-        reply("{} - Project: http://ci.daboross.net/p/{}".format(project_found.name, project_found.project_id))
-        for download in project_found.downloads:
-            for download_file in download["files"]:
-                message("Download: http://ci.daboross.net/d/{}/{}".format(download["id"], download_file))
-        if len(other_matches) > 0:
-            message("(Other matches: {})".format(", ".join(other_matches)))
-    else:
-        reply("No projects found matching '{}'".format(inp))
-    database.after_check()
-
-
-@hook.command(["reloadci", "reload_teamcity"], permissions=["botcontrol"], autohelp=False)
-def reload_teamcity(bot, reply):
-    """reloadci - Reloads teamcity database manually"""
-    database.load_key(bot)
-    database.reload_database()
-    reply("Reloaded teamcity, found {} projects.".format(len(database.projects)))
-    database.after_check()
-
-
-@hook.command(["listci", "list_teamcity"], permissions=["botcontrol"], autohelp=False)
-def list_teamcity(bot, reply):
-    """listci - Lists all projects loaded into database from teamcity"""
-    database.ensure_loaded(bot=bot)
-    reply("Projects: {}".format(", ".join([project.name for project in database.projects])))
-    database.after_check()
diff --git a/modules/eliralin_utility.py b/modules/eliralin_utility.py
deleted file mode 100644
index 6de03eb..0000000
--- a/modules/eliralin_utility.py
+++ /dev/null
@@ -1,118 +0,0 @@
-from random import random
-import socket
-
-from util import hook
-
-
-@hook.command(["josephus", "jose"])
-def josephus(text):
-    """jose [size] [every x] [starting person] - Calculates who dies last """
-    split = text.split()
-    if len(split) != 3:
-        return "Not enough / too many arguments. {}".format(len(split))
-    size, every_x, current = [int(x) for x in split]
-    alive, till_kill = [True] * size, 0
-    while True:
-        if alive[current]:
-            if sum(alive) == 1:
-                break
-            elif till_kill == 0:
-                alive[current] = False
-                till_kill = every_x - 1
-            else:
-                till_kill -= 1
-        current += 1 if current < size - 1 else 1 - size
-    return "Josephus should be at position {} to survive.".format(current)
-
-
-@hook.regex("(?i)(^ )*pets Eliralin *$")
-def pet(action, nick):
-    r = random()
-    if r > 0.7:
-        action("huggles {}".format(nick))
-
-
-@hook.command(["hug", "huggle"])
-def huggle(text, action, nick):
-    if text:
-        action("huggles {}".format(text))
-    else:
-        action("huggles {}".format(nick))
-
-
-@hook.command()
-def colors(text):
-    if text:
-        intinp = int(text)
-        if intinp > 70:
-            return "Please use a number smaller than or equal to 70"
-        forrange = range(intinp)
-    else:
-        forrange = range(30)
-    result = ""
-    for i in forrange if text else range(30):
-        result += "\x03{0:02d} {0}".format(i)
-    return result
-
-
-@hook.command(permissions=["adminonly"])
-def tree(text, message, notice):
-    """tree [type] [text] - Tree text"""
-    type_input = text.split(None, 1)
-    if len(type_input) < 2:
-        notice("tree [type] [text] - Tree text")
-        return
-    tree_type = type_input[0]
-    if tree_type == "1":
-        func = lambda c: c[1:-1]
-    elif tree_type == "2":
-        func = lambda c: c[2:]
-    elif tree_type == "3":
-        func = lambda c: c[:-2]
-    else:
-        return "Invalid tree type '{}'.".format(tree_type)
-    current = type_input[1]
-    spaces = 7
-    while len(current) > 0:
-        spaces += 1
-        message(spaces * ' ' + current)
-        current = func(current)
-
-    message((spaces - 1) * ' ' + ('----' if len(type_input[1]) % 2 == 0 else '---'))
-
-
-@hook.command
-def dns(text):
-    """dns [domain] - Resolves the IP of a domain"""
-    try:
-        socket.setdefaulttimeout(5)
-        ip = None
-        for info in socket.getaddrinfo(text, 80, 0, 0, socket.SOL_TCP):
-            print(info)
-            if ip is None:
-                ip = info[-1][0]
-            else:
-                ip = "{}, {}".format(ip, info[-1][0])
-        return "{} resolves to {}".format(text, ip)
-    except socket.gaierror:
-        return "Resolve Failed!"
-
-
-@hook.command
-def rdns(inp):
-    """rdns [ip] - Resolves the hostname of an IP"""
-    try:
-        socket.setdefaulttimeout(5)
-        domain = socket.gethostbyaddr(inp)[0]
-        return "{} resolves to {}".format(inp, domain)
-    except socket.gaierror:
-        return "Resolve Failed!"
-
-
-@hook.command("unicode")
-def unicodecommand(inp, reply):
-    try:
-        return "'{}'".format(chr(int(inp)))
-    except ValueError:
-        reply("Failed")
-        raise
diff --git a/modules/encrypt.py b/modules/encrypt.py
deleted file mode 100644
index f441a1b..0000000
--- a/modules/encrypt.py
+++ /dev/null
@@ -1,139 +0,0 @@
-import os
-import base64
-import hashlib
-import traceback
-
-from pbkdf2 import PBKDF2
-
-from Crypto import Random
-from Crypto.Cipher import AES
-
-from util import hook
-
-BS = AES.block_size
-
-# helper functions to pad and unpad a string to a specified block size
-# <http://stackoverflow.com/questions/12524994/encrypt-decrypt-using-pycrypto-aes-256>
-
-
-def pad(s):
-    return s + (BS - len(s) % BS) * chr(BS - len(s) % BS)
-
-
-def unpad(s):
-    return s[0:-ord(s[-1])]
-
-
-# helper functions to encrypt and encode a string with AES and base64
-
-def encode_aes(c, s):
-    return base64.b64encode(c.encrypt(pad(s)))
-
-
-def decode_aes(c, s):
-    decoded = c.decrypt(base64.b64decode(s))
-    try:
-        return unpad(decoded.decode())
-    except UnicodeDecodeError:
-        print("Failed to encode an encrypted message result as UTF-8")
-        traceback.print_exc()
-        # This usually happens if password is invalid
-        return "Invalid password for the given message (couldn't encode result as utf-8)"
-
-
-@hook.onload()
-def create_db(db):
-    """check to see that our db has the the encryption table.
-    :type db: sqlalchemy.orm.session.Session
-    """
-    db.execute("create table if not exists encryption(encrypted, iv, "
-               "primary key(encrypted))")
-    db.commit()
-
-
-def get_salt(bot):
-    """generate an encryption salt if none exists, then returns the salt
-    :type bot: core.bot.CloudBot
-    """
-    if not bot.config.get("random_salt", False):
-        bot.config["random_salt"] = hashlib.md5(os.urandom(16)).hexdigest()
-        bot.config.save_config()
-    return bot.config.get("random_salt")
-
-
-@hook.command(threaded=False)
-def encrypt(text, bot, db, notice):
-    """encrypt <pass> <string> -- Encrypts <string> with <pass>. (<string> can only be decrypted using this bot)
-    :type text: str
-    :type bot: core.bot.CloudBot
-    :type db: sqlalchemy.orm.session.Session
-    """
-
-    text_split = text.split(" ")
-
-    # if there is only one argument, return the help message
-    if len(text_split) == 1:
-        notice(encrypt.__doc__)
-        return
-
-    # generate the key from the password and salt
-    password = text_split[0]
-    salt = get_salt(bot)
-    key = PBKDF2(password, salt).read(32)
-
-    # generate the IV and encode it to store in the database
-    iv = Random.new().read(AES.block_size)
-    iv_encoded = base64.b64encode(iv)
-
-    # create the AES cipher and encrypt/encode the text with it
-    text = " ".join(text_split[1:])
-    cipher = AES.new(key, AES.MODE_CBC, iv)
-    encoded = encode_aes(cipher, text)
-
-    # store the encoded text and IV in the DB for decoding later
-    db.execute("insert or replace into encryption(encrypted, iv)"
-               "values(:encoded,:iv)", {'encoded': encoded,
-                                        'iv': iv_encoded})
-    db.commit()
-
-    return encoded.decode()
-
-
-@hook.command(threaded=False)
-def decrypt(text, bot, db, notice):
-    """decrypt <pass> <string> -- Decrypts <string> with <pass>. (can only decrypt strings encrypted on this bot)
-    :type bot: core.bot.CloudBot
-    :type db: sqlalchemy.orm.session.Session
-    """
-
-    inp_split = text.split(" ")
-
-    # if there is only one argument, return the help message
-    if len(inp_split) == 1:
-        notice(decrypt.__doc__)
-        return
-
-    encrypted_str = " ".join(inp_split[1:])
-
-    # generate the key from the password and salt
-    password = inp_split[0]
-    salt = get_salt(bot)
-    key = PBKDF2(password, salt).read(32)
-
-    encrypted_bytes = encrypted_str.encode("utf-8")
-
-    # get the encoded IV from the database
-    database_result = db.execute("select iv from encryption where"
-                                 " encrypted=:key", {'key': encrypted_bytes}).fetchone()
-
-    if database_result is None:
-        notice("Unknown encrypted string '{}'".format(encrypted_str))
-        return
-
-    # decode the IV
-    iv_encoded = database_result[0]
-    iv = base64.b64decode(iv_encoded)
-
-    # create AES cipher, decode text, decrypt text, and unpad it
-    cipher = AES.new(key, AES.MODE_CBC, iv)
-    return decode_aes(cipher, encrypted_bytes)
diff --git a/modules/fact.py b/modules/fact.py
deleted file mode 100644
index 48501a7..0000000
--- a/modules/fact.py
+++ /dev/null
@@ -1,37 +0,0 @@
-from util import hook, http, web
-
-
-@hook.command(autohelp=False, threaded=True)
-def fact():
-    """fact -- Gets a random fact from OMGFACTS."""
-
-    attempts = 0
-
-    # all of this is because omgfacts is fail
-    while True:
-        try:
-            soup = http.get_soup('http://www.omg-facts.com/random')
-        except (http.HTTPError, http.URLError):
-            if attempts > 2:
-                return "Could not find a fact!"
-            else:
-                attempts += 1
-                continue
-
-        response = soup.find('a', {'class': 'surprise'})
-        link = response['href']
-        fact_data = ''.join(response.find(text=True))
-
-        if fact_data:
-            fact_data = fact_data.strip()
-            break
-        else:
-            if attempts > 2:
-                return "Could not find a fact!"
-            else:
-                attempts += 1
-                continue
-
-    url = web.try_isgd(link)
-
-    return "{} - {}".format(fact_data, url)
diff --git a/modules/factoids.py b/modules/factoids.py
deleted file mode 100644
index eee1d46..0000000
--- a/modules/factoids.py
+++ /dev/null
@@ -1,188 +0,0 @@
-# Written by Scaevolus 2010
-import string
-import re
-
-from sqlalchemy import Table, Column, String
-
-from util import hook, botvars, http, formatting, pyexec
-
-re_lineends = re.compile(r'[\r\n]*')
-
-
-# some simple "shortcodes" for formatting purposes
-shortcodes = {
-    '[b]': '\x02',
-    '[/b]': '\x02',
-    '[u]': '\x1F',
-    '[/u]': '\x1F',
-    '[i]': '\x16',
-    '[/i]': '\x16'
-}
-
-table = Table(
-    "mem",
-    botvars.metadata,
-    Column("word", String, primary_key=True),
-    Column("data", String),
-    Column("nick", String)
-)
-
-
-@hook.onload()
-def load_cache(db):
-    """
-    :type db: sqlalchemy.orm.Session
-    """
-    global factoid_cache
-    factoid_cache = {}
-    for row in db.execute(table.select()):
-        word = row["word"]
-        data = row["data"]
-        # nick = row["nick"]
-        factoid_cache[word] = data  # we might want (data, nick) sometime later
-
-
-def add_factoid(db, word, data, nick):
-    """
-    :type db: sqlalchemy.orm.Session
-    :type word: str
-    :type data: str
-    :type nick: str
-    """
-    if word in factoid_cache:
-        # if we have a set value, update
-        db.execute(table.update().values(data=data, nick=nick).where(table.c.word == word))
-    else:
-        # otherwise, insert
-        db.execute(table.insert().values(word=word, data=data, nick=nick))
-    db.commit()
-    load_cache(db)
-
-
-def del_factoid(db, word):
-    """
-    :type db: sqlalchemy.orm.Session
-    :type word: str
-    """
-    db.execute(table.delete().where(table.c.word == word))
-    db.commit()
-    load_cache(db)
-
-
-@hook.command(["r", "remember"], threaded=False, permissions=["addfactoid"])
-def remember(text, nick, db, notice):
-    """remember <word> [+]<data> -- Remembers <data> with <word>. Add + to <data> to append."""
-
-    append = False
-
-    try:
-        word, data = text.split(None, 1)
-    except ValueError:
-        return remember.__doc__
-
-    old_data = factoid_cache.get(word)
-
-    if data.startswith('+') and old_data:
-        append = True
-        # remove + symbol
-        new_data = data[1:]
-        # append new_data to the old_data
-        if len(new_data) > 1 and new_data[1] in (string.punctuation + ' '):
-            data = old_data + new_data
-        else:
-            data = old_data + ' ' + new_data
-
-    add_factoid(db, word, data, nick)
-
-    if old_data:
-        if append:
-            notice("Appending \x02{}\x02 to \x02{}\x02".format(new_data, old_data))
-        else:
-            notice('Remembering \x02{}\x02 for \x02{}\x02. Type ?{} to see it.'.format(data, word, word))
-            notice('Previous data was \x02{}\x02'.format(old_data))
-    else:
-        notice('Remembering \x02{}\x02 for \x02{}\x02. Type ?{} to see it.'.format(data, word, word))
-
-
-@hook.command(["f", "forget"], threaded=True, permissions=["delfactoid"])
-def forget(text, db, notice):
-    """forget <word> -- Forgets a remembered <word>."""
-
-    data = factoid_cache.get(text)
-
-    if data:
-        del_factoid(db, text)
-        notice('"%s" has been forgotten.' % data.replace('`', "'"))
-        return
-    else:
-        notice("I don't know about that.")
-        return
-
-
-@hook.command(threaded=False)
-def info(text, notice):
-    """info <factoid> -- Shows the source of a factoid."""
-
-    text = text.strip()
-
-    if text in factoid_cache:
-        notice(factoid_cache[text])
-    else:
-        notice("Unknown Factoid.")
-
-
-@hook.regex(r'^\^ ?(.+)', threaded=False)
-def factoid(inp, input, db, message, action):
-    """?<word> -- Shows what data is associated with <word>."""
-
-    # split up the input
-    split = inp.group(1).strip().split(" ")
-    factoid_id = split[0]
-
-    if len(split) >= 1:
-        arguments = " ".join(split[1:])
-    else:
-        arguments = ""
-
-    if factoid_id in factoid_cache:
-        data = factoid_cache[factoid_id]
-        # factoid preprocessors
-        if data.startswith("<py>"):
-            code = data[4:].strip()
-            variables = 'input="""{}"""; nick="{}"; chan="{}"; bot_nick="{}";'.format(arguments.replace('"', '\\"'),
-                                                                                      input.nick, input.chan,
-                                                                                      input.conn.nick)
-            result = pyexec.eval_py(variables + code)
-        else:
-            result = data
-
-        # factoid postprocessors
-        result = formatting.multiword_replace(result, shortcodes)
-
-        if result.startswith("<act>"):
-            result = result[5:].strip()
-            action(result)
-        elif result.startswith("<url>"):
-            url = result[5:].strip()
-            try:
-                message(http.get(url))
-            except http.HTTPError:
-                message("Could not fetch URL.")
-        else:
-            message(result)
-
-
-@hook.command(autohelp=False, threaded=False, permissions=["listfactoids"])
-def listfactoids(reply):
-    reply_text = []
-    reply_text_length = 0
-    for word in factoid_cache.keys():
-        added_length = len(word) + 2
-        if reply_text_length + added_length > 400:
-            reply(", ".join(reply_text))
-            reply_text = []
-            reply_text_length = 0
-        else:
-            reply_text.append(word)
-            reply_text_length += added_length
-    return ", ".join(reply_text)
diff --git a/modules/fishbans.py b/modules/fishbans.py
deleted file mode 100644
index 0b42c5e..0000000
--- a/modules/fishbans.py
+++ /dev/null
@@ -1,58 +0,0 @@
-from urllib.parse import quote_plus
-
-from util import hook, http, formatting
-
-api_url = "http://api.fishbans.com/stats/{}/"
-
-
-@hook.command(["bans", "fishbans"], threaded=True)
-def fishbans(text):
-    """fishbans <user> -- Gets information on <user>s minecraft bans from fishbans"""
-    user = text.strip()
-
-    try:
-        request = http.get_json(api_url.format(quote_plus(user)))
-    except (http.HTTPError, http.URLError) as e:
-        return "Could not fetch ban data from the Fishbans API: {}".format(e)
-
-    if not request["success"]:
-        return "Could not fetch ban data for {}.".format(user)
-
-    user_url = "http://fishbans.com/u/{}/".format(user)
-    ban_count = request["stats"]["totalbans"]
-
-    if ban_count == 1:
-        return "The user \x02{}\x02 has \x021\x02 ban - {}".format(user, user_url)
-    elif ban_count > 1:
-        return "The user \x02{}\x02 has \x02{}\x02 bans - {}".format(user, ban_count, user_url)
-    else:
-        return "The user \x02{}\x02 has no bans - {}".format(user, user_url)
-
-
-@hook.command(threaded=True)
-def bancount(text):
-    """bancount <user> -- Gets a count of <user>s minecraft bans from fishbans"""
-    user = text.strip()
-
-    try:
-        request = http.get_json(api_url.format(quote_plus(user)))
-    except (http.HTTPError, http.URLError) as e:
-        return "Could not fetch ban data from the Fishbans API: {}".format(e)
-
-    if not request["success"]:
-        return "Could not fetch ban data for {}.".format(user)
-
-    user_url = "http://fishbans.com/u/{}/".format(user)
-    services = request["stats"]["service"]
-
-    out = []
-    for service, ban_count in list(services.items()):
-        if ban_count != 0:
-            out.append("{}: \x02{}\x02".format(service, ban_count))
-        else:
-            pass
-
-    if not out:
-        return "The user \x02{}\x02 has no bans - {}".format(user, user_url)
-    else:
-        return "Bans for \x02{}\x02: {} - {}".format(user, formatting.get_text_list(out, "and"), user_url)
diff --git a/modules/fmylife.py b/modules/fmylife.py
deleted file mode 100644
index d6628c3..0000000
--- a/modules/fmylife.py
+++ /dev/null
@@ -1,32 +0,0 @@
-from util import hook, http
-
-fml_cache = []
-
-
-def refresh_cache():
-    """ gets a page of random FMLs and puts them into a dictionary """
-    soup = http.get_soup('http://www.fmylife.com/random/')
-
-    for e in soup.find_all('div', {'class': 'post article'}):
-        fml_id = int(e['id'])
-        text = ''.join(e.find('p').find_all(text=True))
-        fml_cache.append((fml_id, text))
-
-
-@hook.onload()
-def initial_refresh():
-    # do an initial refresh of the cache
-    refresh_cache()
-
-
-@hook.command(autohelp=False, threaded=True)
-def fml(reply):
-    """fml -- Gets a random quote from fmyfife.com."""
-
-    # grab the last item in the fml cache and remove it
-    fml_id, text = fml_cache.pop()
-    # reply with the fml we grabbed
-    reply('(#{}) {}'.format(fml_id, text))
-    # refresh fml cache if its getting empty
-    if len(fml_cache) < 3:
-        refresh_cache()
diff --git a/modules/fortune.py b/modules/fortune.py
deleted file mode 100644
index a181f01..0000000
--- a/modules/fortune.py
+++ /dev/null
@@ -1,19 +0,0 @@
-import os
-import random
-
-from util import hook
-
-
-@hook.onload()
-def load_fortunes(bot):
-    path = os.path.join(bot.data_dir, "fortunes.txt")
-    global fortunes
-    with open(path) as f:
-        fortunes = [line.strip() for line in f.readlines()
-                    if not line.startswith("//")]
-
-
-@hook.command(autohelp=False,threaded=False)
-def fortune():
-    """fortune -- Fortune cookies on demand."""
-    return random.choice(fortunes)
diff --git a/modules/geoip.py b/modules/geoip.py
deleted file mode 100644
index 103d285..0000000
--- a/modules/geoip.py
+++ /dev/null
@@ -1,59 +0,0 @@
-import os.path
-import json
-import gzip
-from io import BytesIO
-
-import pygeoip
-
-from util import hook, http
-
-
-@hook.onload()
-def load_regions(bot):
-    global regions, geo
-    # load region database
-    with open(os.path.join(bot.data_dir, "geoip_regions.json"), "rb") as f:
-        regions = json.loads(f.read().decode())
-
-    if os.path.isfile(os.path.join(bot.data_dir, "GeoLiteCity.dat")):
-        # initialise geolocation database
-        geo = pygeoip.GeoIP(os.path.join(bot.data_dir, "GeoLiteCity.dat"))
-    else:
-        print("Downloading GeoIP database")
-        download = http.get("http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz", decode=False)
-        print("Download complete")
-        bytes_io = BytesIO(download)
-        geoip_file = gzip.GzipFile(fileobj=bytes_io, mode='rb')
-
-        output = open(os.path.join(bot.data_dir, "GeoLiteCity.dat"), 'wb')
-        output.write(geoip_file.read())
-        output.close()
-
-        geo = pygeoip.GeoIP(os.path.join(bot.data_dir, "GeoLiteCity.dat"))
-
-
-@hook.command(threaded=True)
-def geoip(text):
-    """geoip <host/ip> -- Gets the location of <host/ip>"""
-
-    try:
-        record = geo.record_by_name(text)
-    except Exception:
-        return "Sorry, I can't locate that in my database."
-
-    data = {}
-
-    if "region_name" in record:
-        # we try catching an exception here because the region DB is missing a few areas
-        # it's a lazy patch, but it should do the job
-        try:
-            data["region"] = ", " + regions[record["country_code"]][record["region_name"]]
-        except:
-            data["region"] = ""
-    else:
-        data["region"] = ""
-
-    data["cc"] = record["country_code"] or "N/A"
-    data["country"] = record["country_name"] or "Unknown"
-    data["city"] = record["city"] or "Unknown"
-    return "\x02Country:\x02 {country} ({cc}), \x02City:\x02 {city}{region}".format(**data)
diff --git a/modules/github.py b/modules/github.py
deleted file mode 100644
index d692ae0..0000000
--- a/modules/github.py
+++ /dev/null
@@ -1,128 +0,0 @@
-import json
-import traceback
-import urllib
-
-from util import hook, http
-
-
-shortcuts = {"cloudbot": "ClouDev/CloudBot"}
-
-# (number, state, user.login, title, truncate(body), gitio.gitio(data.url))
-format_with_summary = "Issue: #{} ({}) by {}: {} | {} {}"
-
-# (number, state, user.login, title, gitio.gitio(data.url))
-format_without_summary = "Issue: #{} ({}) by {}: {} {}"
-
-
-def truncate(msg):
-    nmsg = msg.split()
-    out = None
-    x = 0
-    for i in nmsg:
-        if x <= 7:
-            if out:
-                out = out + " " + nmsg[x]
-            else:
-                out = nmsg[x]
-        x += 1
-    if x <= 7:
-        return out
-    else:
-        return out + "..."
-
-
-def shorten_gitio(url, code=None):
-    # Make sure the url starts with https://
-    if not url.startswith("https://"):
-        if url.startswith("http://"):
-            url = "https://" + url
-        else:
-            url = "https://" + url
-
-    data = 'url=' + url
-    if code:
-        data += '&code=' + code
-        print(code)
-    req = urllib.request.Request(url='http://git.io', data=data.encode())
-
-    # try getting url, let http error raise to next level
-    response = urllib.request.urlopen(req)
-
-    # return location
-    return response.headers["Location"]
-
-
-def try_shorten_gitio(url, code=None):
-    try:
-        return shorten_gitio(url, code)
-    except urllib.error.HTTPError:
-        return url
-
-
-@hook.command(threaded=True)
-def ghissues(text):
-    """ghissues username/repo [number] - Get specified issue summary, or open issue count """
-    args = text.split()
-    if args[0] in shortcuts:
-        repo = shortcuts[args[0]]
-    else:
-        repo = args[0]
-    url = "https://api.github.com/repos/{}/issues".format(repo)
-
-    specific_issue = len(args) > 1
-    if specific_issue:
-        url += "/{}".format(args[1])
-    print("Fetching {}".format(url))
-    try:
-        raw_data = http.get(url)
-    except urllib.error.HTTPError:
-        if specific_issue:
-            return "Error getting issues for '{}/{}', is it a valid issue?".format(args[0], args[1])
-        else:
-            return "Error getting issues for '{}', is it a valid repository?".format(args[0])
-
-    issue_list = json.loads(raw_data)
-
-    if not specific_issue:
-        if len(issue_list) < 1:
-            return "Repository has no open issues"
-        issue = issue_list[0]
-    else:
-        issue = issue_list  # only had one issue
-
-    issue_number = issue["number"]
-    if issue["state"] == "open":
-        state = "\x033\x02OPEN\x02\x0f"
-    else:
-        state = "\x034\x02CLOSED\x02\x0f by {}".format(issue["closed_by"]["login"])
-    user = issue["user"]["login"]
-    title = issue["title"]
-    summary = truncate(issue["body"])
-
-    try:
-        shorturl = try_shorten_gitio(issue["html_url"])
-    except urllib.error.HTTPError:
-        shorturl = try_shorten_gitio(issue["html_url"] + " " + repo.split("/")[1] + issue_number)
-
-    if summary:
-        return format_with_summary.format(issue_number, state, user, title, summary, shorturl)
-    else:
-        return format_without_summary.format(issue_number, state, user, title, shorturl)
-
-
-@hook.command(threaded=True)
-def gitio(text):
-    """gitio <url> [code] -- Shorten Github URLs with git.io. [code] is an optional custom short code."""
-    split = text.split()
-    url = split[0]
-
-    if len(split) > 1:
-        code = split[1]
-    else:
-        code = None
-
-    try:
-        return shorten_gitio(url, code=code)
-    except urllib.error.HTTPError:
-        traceback.print_exc()
-        return "Failed to shorten!"
diff --git a/modules/google.py b/modules/google.py
deleted file mode 100644
index 9b393bf..0000000
--- a/modules/google.py
+++ /dev/null
@@ -1,47 +0,0 @@
-import random
-
-from util import hook, http, formatting
-
-
-def api_get(kind, query):
-    """Use the RESTful Google Search API"""
-    url = 'http://ajax.googleapis.com/ajax/services/search/%s?' \
-          'v=1.0&safe=moderate'
-    return http.get_json(url % kind, q=query)
-
-
-@hook.command(["googleimage", "gis", "image"], threaded=True)
-def googleimage(text):
-    """gis <query> -- Returns first Google Image result for <query>."""
-
-    parsed = api_get('images', text)
-    if not 200 <= parsed['responseStatus'] < 300:
-        raise IOError('error searching for images: {}: {}'.format(parsed['responseStatus'], ''))
-    if not parsed['responseData']['results']:
-        return 'no images found'
-    return random.choice(parsed['responseData']['results'][:10])['unescapedUrl']
-
-
-@hook.command(["google", "g", "search"], threaded=True)
-def google(text):
-    """google <query> -- Returns first google search result for <query>."""
-
-    parsed = api_get('web', text)
-    if not 200 <= parsed['responseStatus'] < 300:
-        raise IOError('error searching for pages: {}: {}'.format(parsed['responseStatus'], ''))
-    if not parsed['responseData']['results']:
-        return 'No results found.'
-
-    result = parsed['responseData']['results'][0]
-
-    title = http.unescape(result['titleNoFormatting'])
-    title = formatting.truncate_str(title, 60)
-    content = http.unescape(result['content'])
-
-    if not content:
-        content = "No description available."
-    else:
-        content = http.html.fromstring(content).text_content()
-        content = formatting.truncate_str(content, 150)
-
-    return '{} -- \x02{}\x02: "{}"'.format(result['unescapedUrl'], title, content)
diff --git a/modules/google_translate.py b/modules/google_translate.py
deleted file mode 100644
index cb42a35..0000000
--- a/modules/google_translate.py
+++ /dev/null
@@ -1,169 +0,0 @@
-"""
-A Google API key is required and retrieved from the bot config file.
-Since December 1, 2011, the Google Translate API is a paid service only.
-"""
-
-import re
-
-import html.entities
-from util import hook, http
-
-
-max_length = 100
-
-
-########### from http://effbot.org/zone/re-sub.htm#unescape-html #############
-
-
-def unescape(text):
-    def fixup(m):
-        text = m.group(0)
-        if text[:2] == "&#":
-            # character reference
-            try:
-                if text[:3] == "&#x":
-                    return chr(int(text[3:-1], 16))
-                else:
-                    return chr(int(text[2:-1]))
-            except ValueError:
-                pass
-        else:
-            # named entity
-            try:
-                text = chr(html.entities.name2codepoint[text[1:-1]])
-            except KeyError:
-                pass
-        return text  # leave as is
-
-    return re.sub("&#?\w+;", fixup, text)
-
-
-##############################################################################
-
-
-def goog_trans(api_key, text, slang, tlang):
-    url = 'https://www.googleapis.com/language/translate/v2'
-
-    if len(text) > max_length:
-        return "This command only supports input of less then 100 characters."
-
-    if slang:
-        parsed = http.get_json(url, key=api_key, q=text, source=slang, target=tlang, format="text")
-    else:
-        parsed = http.get_json(url, key=api_key, q=text, target=tlang, format="text")
-
-        #if not 200 <= parsed['responseStatus'] < 300:
-        #   raise IOError('error with the translation server: %d: %s' % (
-        #           parsed['responseStatus'], parsed['responseDetails']))
-    if not slang:
-        return unescape('(%(detectedSourceLanguage)s) %(translatedText)s' %
-                        (parsed['data']['translations'][0]))
-    return unescape('%(translatedText)s' % parsed['data']['translations'][0])
-
-
-def match_language(fragment):
-    fragment = fragment.lower()
-    for short, _ in lang_pairs:
-        if fragment in short.lower().split():
-            return short.split()[0]
-
-    for short, full in lang_pairs:
-        if fragment in full.lower():
-            return short.split()[0]
-
-    return None
-
-
-@hook.command(threaded=True)
-def translate(text, bot):
-    """translate [source language [target language]] <sentence> -- translates
-    <sentence> from source language (default autodetect) to target
-    language (default English) using Google Translate"""
-
-    api_key = bot.config.get("api_keys", {}).get("googletranslate", None)
-    if not api_key:
-        return "This command requires a paid API key."
-
-    args = text.split(' ', 2)
-
-    try:
-        if len(args) >= 2:
-            sl = match_language(args[0])
-            if not sl:
-                return goog_trans(api_key, text, '', 'en')
-            if len(args) == 2:
-                return goog_trans(api_key, args[1], sl, 'en')
-            if len(args) >= 3:
-                tl = match_language(args[1])
-                if not tl:
-                    if sl == 'en':
-                        return 'unable to determine desired target language'
-                    return goog_trans(api_key, args[1] + ' ' + args[2], sl, 'en')
-                return goog_trans(api_key, args[2], sl, tl)
-        return goog_trans(api_key, text, '', 'en')
-    except IOError as e:
-        return e
-
-
-lang_pairs = [
-    ("no", "Norwegian"),
-    ("it", "Italian"),
-    ("ht", "Haitian Creole"),
-    ("af", "Afrikaans"),
-    ("sq", "Albanian"),
-    ("ar", "Arabic"),
-    ("hy", "Armenian"),
-    ("az", "Azerbaijani"),
-    ("eu", "Basque"),
-    ("be", "Belarusian"),
-    ("bg", "Bulgarian"),
-    ("ca", "Catalan"),
-    ("zh-CN zh", "Chinese"),
-    ("hr", "Croatian"),
-    ("cs", "Czech"),
-    ("da", "Danish"),
-    ("nl", "Dutch"),
-    ("en", "English"),
-    ("et", "Estonian"),
-    ("tl", "Filipino"),
-    ("fi", "Finnish"),
-    ("fr", "French"),
-    ("gl", "Galician"),
-    ("ka", "Georgian"),
-    ("de", "German"),
-    ("el", "Greek"),
-    ("ht", "Haitian Creole"),
-    ("iw", "Hebrew"),
-    ("hi", "Hindi"),
-    ("hu", "Hungarian"),
-    ("is", "Icelandic"),
-    ("id", "Indonesian"),
-    ("ga", "Irish"),
-    ("it", "Italian"),
-    ("ja jp jpn", "Japanese"),
-    ("ko", "Korean"),
-    ("lv", "Latvian"),
-    ("lt", "Lithuanian"),
-    ("mk", "Macedonian"),
-    ("ms", "Malay"),
-    ("mt", "Maltese"),
-    ("no", "Norwegian"),
-    ("fa", "Persian"),
-    ("pl", "Polish"),
-    ("pt", "Portuguese"),
-    ("ro", "Romanian"),
-    ("ru", "Russian"),
-    ("sr", "Serbian"),
-    ("sk", "Slovak"),
-    ("sl", "Slovenian"),
-    ("es", "Spanish"),
-    ("sw", "Swahili"),
-    ("sv", "Swedish"),
-    ("th", "Thai"),
-    ("tr", "Turkish"),
-    ("uk", "Ukrainian"),
-    ("ur", "Urdu"),
-    ("vi", "Vietnamese"),
-    ("cy", "Welsh"),
-    ("yi", "Yiddish")
-]
diff --git a/modules/googleurlparse.py b/modules/googleurlparse.py
deleted file mode 100644
index 7f9dfb4..0000000
--- a/modules/googleurlparse.py
+++ /dev/null
@@ -1,23 +0,0 @@
-from util import hook
-from urllib.parse import unquote
-
-
-@hook.command(autohelp=False, threaded=True)
-def googleurl(text, db, nick):
-    """googleurl [nickname] - Converts Google urls (google.com/url) to normal urls
-       where possible, in the specified nickname's last message. If nickname isn't provided,
-       action will be performed on user's last message"""
-    if not text:
-        text = nick
-    last_message = db.execute("select name, quote from seen_user where name"
-                              " like ? and chan = ?", (text.lower(), input.chan.lower())).fetchone()
-    if last_message:
-        msg = last_message[1]
-        out = ", ".join([(unquote(a[4:]) if a[:4] == "url=" else "") for a in msg.split("&")]) \
-            .replace(", ,", "").strip()
-        return out if out else "No matches in your last message."
-    else:
-        if text == nick:
-            return "You haven't said anything in this channel yet!"
-        else:
-            return "That user hasn't said anything in this channel yet!"
diff --git a/modules/history.py b/modules/history.py
deleted file mode 100644
index 81ca449..0000000
--- a/modules/history.py
+++ /dev/null
@@ -1,92 +0,0 @@
-from collections import deque
-import time
-import re
-
-from util import hook, timesince
-
-
-db_ready = []
-
-
-def db_init(db, conn_name):
-    """check to see that our db has the the seen table (connection name is for caching the result per connection)"""
-    global db_ready
-    if db_ready.count(conn_name) < 1:
-        db.execute("create table if not exists seen_user(name, time, quote, chan, host, "
-                   "primary key(name, chan))")
-        db.commit()
-        db_ready.append(conn_name)
-
-
-def track_seen(input, message_time, db, conn):
-    """ Tracks messages for the .seen command """
-    db_init(db, conn)
-    # keep private messages private
-    if input.chan[:1] == "#" and not re.findall('^s/.*/.*/$', input.msg.lower()):
-        db.execute("insert or replace into seen_user(name, time, quote, chan, host)"
-                   "values(:name,:time,:quote,:chan,:host)", {'name': input.nick.lower(),
-                                                              'time': time.time(),
-                                                              'quote': input.msg,
-                                                              'chan': input.chan,
-                                                              'host': input.mask})
-        db.commit()
-
-
-def track_history(input, message_time, conn):
-    try:
-        history = conn.history[input.chan]
-    except KeyError:
-        conn.history[input.chan] = deque(maxlen=100)
-        history = conn.history[input.chan]
-
-    data = (input.nick, message_time, input.msg)
-    history.append(data)
-
-
-@hook.event('PRIVMSG', threaded=True, singlethread=True)
-def chat_tracker(input, db, conn):
-    message_time = time.time()
-    track_seen(input, message_time, db, conn)
-    track_history(input, message_time, conn)
-
-
-@hook.command(autohelp=False, threaded=False)
-def resethistory(input, conn):
-    """resethistory - Resets chat history for the current channel"""
-    try:
-        conn.history[input.chan].clear()
-        return "Reset chat history for current channel."
-    except KeyError:
-        # wat
-        return "There is no history for this channel."
-
-
-@hook.command(threaded=True)
-def seen(text, nick, chan, db, input, conn):
-    """seen <nick> <channel> -- Tell when a nickname was last in active in one of this bot's channels."""
-
-    if input.conn.nick.lower() == text.lower():
-        return "You need to get your eyes checked."
-
-    if text.lower() == nick.lower():
-        return "Have you looked in a mirror lately?"
-
-    if not re.match("^[A-Za-z0-9_|.\-\]\[]*$", text.lower()):
-        return "I can't look up that name, its impossible to use!"
-
-    db_init(db, conn.name)
-
-    last_seen = db.execute("select name, time, quote from seen_user where name"
-                           " like :name and chan = :chan", {'name': text, 'chan': chan}).fetchone()
-
-    if last_seen:
-        reltime = timesince.timesince(last_seen[1])
-        if last_seen[0] != text.lower():  # for glob matching
-            text = last_seen[0]
-        if last_seen[2][0:1] == "\x01":
-            return '{} was last seen {} ago: * {} {}'.format(text, reltime, text,
-                                                             last_seen[2][8:-1])
-        else:
-            return '{} was last seen {} ago saying: {}'.format(text, reltime, last_seen[2])
-    else:
-        return "I've never seen {} talking in this channel.".format(text)
diff --git a/modules/horoscope.py b/modules/horoscope.py
deleted file mode 100644
index 6eebd19..0000000
--- a/modules/horoscope.py
+++ /dev/null
@@ -1,50 +0,0 @@
-# Plugin by Infinity - <https://github.com/infinitylabs/UguuBot>
-
-from util import hook, http, formatting
-
-
-@hook.onload()
-def init(db):
-    db.execute("create table if not exists horoscope(nick primary key, sign)")
-    db.commit()
-
-
-@hook.command(autohelp=False, threaded=True)
-def horoscope(text, db, notice, nick):
-    """horoscope <sign> -- Get your horoscope."""
-
-    # check if the user asked us not to save his details
-    dontsave = text.endswith(" dontsave")
-    if dontsave:
-        sign = text[:-9].strip().lower()
-    else:
-        sign = text
-
-    db.execute("create table if not exists horoscope(nick primary key, sign)")
-
-    if not sign:
-        sign = db.execute("select sign from horoscope where "
-                          "nick=lower(:nick)", {'nick': nick}).fetchone()
-        if not sign:
-            notice("horoscope <sign> -- Get your horoscope")
-            return
-        sign = sign[0]
-
-    url = "http://my.horoscope.com/astrology/free-daily-horoscope-{}.html".format(sign)
-    soup = http.get_soup(url)
-
-    title = soup.find_all('h1', {'class': 'h1b'})[1]
-    horoscope_text = soup.find('div', {'class': 'fontdef1'})
-    result = "\x02{}\x02 {}".format(title, horoscope_text)
-    result = formatting.strip_html(result)
-    #result = unicode(result, "utf8").replace('flight ','')
-
-    if not title:
-        return "Could not get the horoscope for {}.".format(text)
-
-    if text and not dontsave:
-        db.execute("insert or replace into horoscope(nick, sign) values (:nick, :sign)",
-                   {'nick': nick.lower(), 'sign': sign})
-        db.commit()
-
-    return result
diff --git a/modules/hulu.py b/modules/hulu.py
deleted file mode 100644
index ee7197d..0000000
--- a/modules/hulu.py
+++ /dev/null
@@ -1,30 +0,0 @@
-import re
-
-from urllib.parse import urlencode
-from util import hook, http, timeformat
-
-
-hulu_re = (r'(.*://)(www.hulu.com|hulu.com)(.*)', re.I)
-
-
-@hook.regex(*hulu_re, threaded=True)
-def hulu_url(match):
-    data = http.get_json("http://www.hulu.com/api/oembed.json?url=http://www.hulu.com" + match.group(3))
-    showname = data['title'].split("(")[-1].split(")")[0]
-    title = data['title'].split(" (")[0]
-    return "{}: {} - {}".format(showname, title, timeformat.format_time(int(data['duration'])))
-
-
-@hook.command('hulu', threaded=True)
-def hulu_search(text):
-    """hulu <search> - Search Hulu"""
-    result = http.get_soup(
-        "http://m.hulu.com/search?dp_identifier=hulu&{}&items_per_page=1&page=1".format(urlencode({'query': text})))
-    data = result.find('results').find('videos').find('video')
-    showname = data.find('show').find('name').text
-    title = data.find('title').text
-    duration = timeformat.format_time(int(float(data.find('duration').text)))
-    description = data.find('description').text
-    rating = data.find('content-rating').text
-    return "{}: {} - {} - {} ({}) {}".format(showname, title, description, duration, rating,
-                                             "http://www.hulu.com/watch/" + str(data.find('id').text))
diff --git a/modules/ignore.py b/modules/ignore.py
deleted file mode 100644
index ded2bf5..0000000
--- a/modules/ignore.py
+++ /dev/null
@@ -1,71 +0,0 @@
-from fnmatch import fnmatch
-
-from util import hook
-
-
-#@hook.sieve
-def ignore_sieve(bot, input, plugin):
-    """ blocks input from ignored channels/hosts """
-    ignorelist = bot.config["modules"]["ignore"]["ignored"]
-    mask = input.mask.lower()
-
-    # don't block input to event hooks
-    if type == "event":
-        return input
-
-    if ignorelist:
-        for pattern in ignorelist:
-            if pattern.startswith("#") and pattern in ignorelist:
-                if input.command == "PRIVMSG" and input.lastparam[1:] == "unignore":
-                    return input
-                else:
-                    return None
-            elif fnmatch(mask, pattern):
-                if input.command == "PRIVMSG" and input.lastparam[1:] == "unignore":
-                    return input
-                else:
-                    return None
-
-    return input
-
-
-@hook.command(threaded=False, autohelp=False)
-def ignored(notice, bot):
-    """ignored -- Lists ignored channels/users."""
-    ignorelist = bot.config["modules"]["ignore"]["ignored"]
-    if ignorelist:
-        notice("Ignored channels/users are: {}".format(", ".join(ignorelist)))
-    else:
-        notice("No masks are currently ignored.")
-    return
-
-
-@hook.command(threaded=True, permissions=["ignore"])
-def ignore(text, notice, bot):
-    """ignore <channel|nick|host> -- Makes the bot ignore <channel|user>."""
-    target = text.lower()
-    ignorelist = bot.config["modules"]["ignore"]["ignored"]
-    if target in ignorelist:
-        notice("{} is already ignored.".format(target))
-    else:
-        notice("{} has been ignored.".format(target))
-        ignorelist.append(target)
-        ignorelist.sort()
-        bot.config.save_config()
-    return
-
-
-@hook.command(threaded=True, permissions=["ignore"])
-def unignore(text, notice, bot):
-    """unignore <channel|user> -- Makes the bot listen to
-    <channel|user>."""
-    target = text.lower()
-    ignorelist = bot.config["modules"]["ignore"]["ignored"]
-    if target in ignorelist:
-        notice("{} has been unignored.".format(target))
-        ignorelist.remove(target)
-        ignorelist.sort()
-        bot.config.save_config()
-    else:
-        notice("{} is not ignored.".format(target))
-    return
diff --git a/modules/imdb.py b/modules/imdb.py
deleted file mode 100644
index c8810d6..0000000
--- a/modules/imdb.py
+++ /dev/null
@@ -1,59 +0,0 @@
-# IMDb lookup plugin by Ghetto Wizard (2011) and blha303 (2013)
-
-import re
-
-from util import hook, http, formatting
-
-
-id_re = re.compile("tt\d+")
-imdb_re = (r'(.*:)//(imdb.com|www.imdb.com)(:[0-9]+)?(.*)', re.I)
-
-
-@hook.command(threaded=True)
-def imdb(text):
-    """imdb <movie> -- Gets information about <movie> from IMDb."""
-
-    strip = text.strip()
-
-    if id_re.match(strip):
-        content = http.get_json("http://www.omdbapi.com/", i=strip)
-    else:
-        content = http.get_json("http://www.omdbapi.com/", t=strip)
-
-    if content.get('Error', None) == 'Movie not found!':
-        return 'Movie not found!'
-    elif content['Response'] == 'True':
-        content['URL'] = 'http://www.imdb.com/title/{}'.format(content['imdbID'])
-
-        out = '\x02%(Title)s\x02 (%(Year)s) (%(Genre)s): %(Plot)s'
-        if content['Runtime'] != 'N/A':
-            out += ' \x02%(Runtime)s\x02.'
-        if content['imdbRating'] != 'N/A' and content['imdbVotes'] != 'N/A':
-            out += ' \x02%(imdbRating)s/10\x02 with \x02%(imdbVotes)s\x02' \
-                   ' votes.'
-        out += ' %(URL)s'
-        return out % content
-    else:
-        return 'Unknown error.'
-
-
-@hook.regex(*imdb_re, threaded=True)
-def imdb_url(match):
-    imdb_id = match.group(4).split('/')[-1]
-    if imdb_id == "":
-        imdb_id = match.group(4).split('/')[-2]
-    content = http.get_json("http://www.omdbapi.com/", i=imdb_id)
-    if content.get('Error', None) == 'Movie not found!':
-        return 'Movie not found!'
-    elif content['Response'] == 'True':
-        content['URL'] = 'http://www.imdb.com/title/%(imdbID)s' % content
-        content['Plot'] = formatting.truncate_str(content['Plot'], 50)
-        out = '\x02%(Title)s\x02 (%(Year)s) (%(Genre)s): %(Plot)s'
-        if content['Runtime'] != 'N/A':
-            out += ' \x02%(Runtime)s\x02.'
-        if content['imdbRating'] != 'N/A' and content['imdbVotes'] != 'N/A':
-            out += ' \x02%(imdbRating)s/10\x02 with \x02%(imdbVotes)s\x02' \
-                   ' votes.'
-        return out % content
-    else:
-        return 'Unknown error.'
diff --git a/modules/imgur.py b/modules/imgur.py
deleted file mode 100644
index 7b95cfb..0000000
--- a/modules/imgur.py
+++ /dev/null
@@ -1,82 +0,0 @@
-import re
-import random
-
-from util import hook, http, web
-
-
-base_url = "http://reddit.com/r/{}/.json"
-imgur_re = re.compile(r'http://(?:i\.)?imgur\.com/(a/)?(\w+\b(?!/))\.?\w?')
-
-album_api = "https://api.imgur.com/3/album/{}/images.json"
-
-
-def is_valid(data):
-    if data["domain"] in ["i.imgur.com", "imgur.com"]:
-        return True
-    else:
-        return False
-
-
-@hook.command(autohelp=False, threaded=True)
-def imgur(inp):
-    """imgur [subreddit] -- Gets the first page of imgur images from [subreddit] and returns a link to them.
-     If [subreddit] is undefined, return any imgur images"""
-    if inp:
-        # see if the input ends with "nsfw"
-        show_nsfw = inp.endswith(" nsfw")
-
-        # remove "nsfw" from the input string after checking for it
-        if show_nsfw:
-            inp = inp[:-5].strip().lower()
-
-        url = base_url.format(inp.strip())
-    else:
-        url = "http://www.reddit.com/domain/imgur.com/.json"
-        show_nsfw = False
-
-    try:
-        data = http.get_json(url, user_agent=http.ua_chrome)
-    except Exception as e:
-        return "Error: " + str(e)
-
-    data = data["data"]["children"]
-    random.shuffle(data)
-
-    # filter list to only have imgur links
-    filtered_posts = [i["data"] for i in data if is_valid(i["data"])]
-
-    if not filtered_posts:
-        return "No images found."
-
-    items = []
-
-    headers = {
-        "Authorization": "Client-ID b5d127e6941b07a"
-    }
-
-    # loop over the list of posts
-    for post in filtered_posts:
-        if post["over_18"] and not show_nsfw:
-            continue
-
-        match = imgur_re.search(post["url"])
-        if match.group(1) == 'a/':
-            # post is an album
-            url = album_api.format(match.group(2))
-            images = http.get_json(url, headers=headers)["data"]
-
-            # loop over the images in the album and add to the list
-            for image in images:
-                items.append(image["id"])
-
-        elif match.group(2) is not None:
-            # post is an image
-            items.append(match.group(2))
-
-    if not items:
-        return "No images found (use .imgur <subreddit> nsfw to show explicit content)"
-
-    if show_nsfw:
-        return "{} \x02NSFW\x02".format(web.isgd("http://imgur.com/" + ','.join(items)))
-    else:
-        return web.isgd("http://imgur.com/" + ','.join(items))
diff --git a/modules/kernel.py b/modules/kernel.py
deleted file mode 100644
index 5944372..0000000
--- a/modules/kernel.py
+++ /dev/null
@@ -1,14 +0,0 @@
-import re
-
-from util import hook, http
-
-
-@hook.command(autohelp=False, threaded=True)
-def kernel(reply):
-    contents = http.get("https://www.kernel.org/finger_banner")
-    contents = re.sub(r'The latest(\s*)', '', contents)
-    contents = re.sub(r'version of the Linux kernel is:(\s*)', '- ', contents)
-    lines = contents.split("\n")
-
-    message = "Linux kernel versions: {}".format(", ".join(line for line in lines[:-1]))
-    reply(message)
diff --git a/modules/kill.py b/modules/kill.py
deleted file mode 100644
index d687436..0000000
--- a/modules/kill.py
+++ /dev/null
@@ -1,33 +0,0 @@
-import json
-
-from util import hook, textgen
-
-
-def get_generator(_json, variables):
-    data = json.loads(_json)
-    return textgen.TextGenerator(data["templates"],
-                                 data["parts"], variables=variables)
-
-
-@hook.command(threaded=False)
-def kill(inp, action=None, nick=None, conn=None, notice=None):
-    """kill <user> -- Makes the bot kill <user>."""
-    target = inp.strip()
-
-    if " " in target:
-        notice("Invalid username!")
-        return
-
-    # if the user is trying to make the bot kill itself, kill them
-    if target.lower() == conn.nick.lower() or target.lower() == "itself":
-        target = nick
-
-    variables = {
-        "user": target
-    }
-
-    with open("./data/kills.json") as f:
-        generator = get_generator(f.read(), variables)
-
-    # act out the message
-    action(generator.generate_string())
diff --git a/modules/lastfm.py b/modules/lastfm.py
deleted file mode 100644
index 51d6dc2..0000000
--- a/modules/lastfm.py
+++ /dev/null
@@ -1,81 +0,0 @@
-from datetime import datetime
-
-from util import hook, http, timesince
-
-
-api_url = "http://ws.audioscrobbler.com/2.0/?format=json"
-
-
-@hook.command(["lastfm", "l"], threaded=True, autohelp=False)
-def lastfm(inp, nick, db, bot, notice):
-    """lastfm [user] [dontsave] -- Displays the now playing (or last played) track of LastFM user [user]."""
-    api_key = bot.config.get("api_keys", {}).get("lastfm")
-    if not api_key:
-        return "error: no api key set"
-
-    # check if the user asked us not to save his details
-    dontsave = inp.endswith(" dontsave")
-    if dontsave:
-        user = inp[:-9].strip().lower()
-    else:
-        user = inp
-
-    db.execute("create table if not exists lastfm(nick primary key, acc)")
-
-    if not user:
-        user = db.execute("select acc from lastfm where nick=lower(:nick)",
-                          {'nick': nick}).fetchone()
-        if not user:
-            notice(lastfm.__doc__)
-            return
-        user = user[0]
-
-    response = http.get_json(api_url, method="user.getrecenttracks",
-                             api_key=api_key, user=user, limit=1)
-
-    if 'error' in response:
-        return "Error: {}.".format(response["message"])
-
-    if not "track" in response["recenttracks"] or len(response["recenttracks"]["track"]) == 0:
-        return 'No recent tracks for user "{}" found.'.format(user)
-
-    tracks = response["recenttracks"]["track"]
-
-    if type(tracks) == list:
-        # if the user is listening to something, the tracks entry is a list
-        # the first item is the current track
-        track = tracks[0]
-        status = 'is listening to'
-        ending = '.'
-    elif type(tracks) == dict:
-        # otherwise, they aren't listening to anything right now, and
-        # the tracks entry is a dict representing the most recent track
-        track = tracks
-        status = 'last listened to'
-        # lets see how long ago they listened to it
-        time_listened = datetime.fromtimestamp(int(track["date"]["uts"]))
-        time_since = timesince.timesince(time_listened)
-        ending = ' ({} ago)'.format(time_since)
-
-    else:
-        return "error: could not parse track listing"
-
-    title = track["name"]
-    album = track["album"]["#text"]
-    artist = track["artist"]["#text"]
-
-    out = '{} {} "{}"'.format(user, status, title)
-    if artist:
-        out += " by \x02{}\x0f".format(artist)
-    if album:
-        out += " from the album \x02{}\x0f".format(album)
-
-    # append ending based on what type it was
-    out += ending
-
-    if inp and not dontsave:
-        db.execute("insert or replace into lastfm(nick, acc) values "
-                   "(:nick, :account)", {'nick': nick.lower(), 'account': user})
-        db.commit()
-
-    return out
diff --git a/modules/lmgtfy.py b/modules/lmgtfy.py
deleted file mode 100644
index e09358a..0000000
--- a/modules/lmgtfy.py
+++ /dev/null
@@ -1,13 +0,0 @@
-from util import hook, web, http
-
-
-@hook.command(["lmgtfy", "gfy"], threaded=True)
-def lmgtfy(inp):
-    """lmgtfy [phrase] - Posts a google link for the specified phrase"""
-
-    link = "http://lmgtfy.com/?q={}".format(http.quote_plus(inp))
-
-    try:
-        return web.isgd(link)
-    except (web.ShortenError, http.HTTPError):
-        return link
diff --git a/modules/lyrics.py b/modules/lyrics.py
deleted file mode 100644
index 0a1aeb5..0000000
--- a/modules/lyrics.py
+++ /dev/null
@@ -1,43 +0,0 @@
-from util import hook, http, web
-
-url = "http://search.azlyrics.com/search.php?q="
-
-
-@hook.command(threaded=True)
-def lyrics(inp):
-    """lyrics <search> - Search AZLyrics.com for song lyrics"""
-    if "pastelyrics" in inp:
-        dopaste = True
-        inp = inp.replace("pastelyrics", "").strip()
-    else:
-        dopaste = False
-    soup = http.get_soup(url + inp.replace(" ", "+"))
-    if "Try to compose less restrictive search query" in soup.find('div', {'id': 'inn'}).text:
-        return "No results. Check spelling."
-    div = None
-    for i in soup.findAll('div', {'class': 'sen'}):
-        if "/lyrics/" in i.find('a')['href']:
-            div = i
-            break
-    if div:
-        title = div.find('a').text
-        link = div.find('a')['href']
-        if dopaste:
-            newsoup = http.get_soup(link)
-            try:
-                lyrics = newsoup.find('div', {'style': 'margin-left:10px;margin-right:10px;'}).text.strip()
-                pasteurl = " " + web.haste(lyrics)
-            except Exception as e:
-                pasteurl = " (\x02Unable to paste lyrics\x02 [{}])".format(str(e))
-        else:
-            pasteurl = ""
-        artist = div.find('b').text.title()
-        lyricsum = div.find('div').text
-        if "\r\n" in lyricsum.strip():
-            lyricsum = " / ".join(lyricsum.strip().split("\r\n")[0:4])  # truncate, format
-        else:
-            lyricsum = " / ".join(lyricsum.strip().split("\n")[0:4])  # truncate, format
-        return "\x02{}\x02 by \x02{}\x02 {}{} - {}".format(title, artist, web.try_isgd(link), pasteurl,
-                                                           lyricsum[:-3])
-    else:
-        return "No song results. " + url + inp.replace(" ", "+")
diff --git a/modules/metacritic.py b/modules/metacritic.py
deleted file mode 100644
index 261c141..0000000
--- a/modules/metacritic.py
+++ /dev/null
@@ -1,103 +0,0 @@
-# metacritic.com scraper
-
-import re
-
-from urllib.error import HTTPError
-from util import hook, http
-
-
-@hook.command(["metacritic", "mc"], threaded=True)
-def metacritic(inp):
-    """mc [all|movie|tv|album|x360|ps3|pc|gba|ds|3ds|wii|vita|wiiu|xone|ps4] <title>
-    Gets rating for <title> from metacritic on the specified medium."""
-
-    args = inp.strip()
-
-    game_platforms = ('x360', 'ps3', 'pc', 'gba', 'ds', '3ds', 'wii',
-                      'vita', 'wiiu', 'xone', 'ps4')
-
-    all_platforms = game_platforms + ('all', 'movie', 'tv', 'album')
-
-    try:
-        plat, title = args.split(' ', 1)
-        if plat not in all_platforms:
-            # raise the ValueError so that the except block catches it
-            # in this case, or in the case of the .split above raising the
-            # ValueError, we want the same thing to happen
-            raise ValueError
-    except ValueError:
-        plat = 'all'
-        title = args
-
-    cat = 'game' if plat in game_platforms else plat
-
-    title_safe = http.quote_plus(title)
-
-    url = 'http://www.metacritic.com/search/{}/{}/results'.format(cat, title_safe)
-
-    try:
-        doc = http.get_html(url)
-    except HTTPError:
-        return 'error fetching results'
-
-    # get the proper result element we want to pull data from
-    result = None
-
-    if not doc.find_class('query_results'):
-        return 'No results found.'
-
-    # if they specified an invalid search term, the input box will be empty
-    if doc.get_element_by_id('search_term').value == '':
-        return 'Invalid search term.'
-
-    if plat not in game_platforms:
-        # for [all] results, or non-game platforms, get the first result
-        result = doc.find_class('result first_result')[0]
-
-        # find the platform, if it exists
-        result_type = result.find_class('result_type')
-        if result_type:
-
-            # if the result_type div has a platform div, get that one
-            platform_div = result_type[0].find_class('platform')
-            if platform_div:
-                plat = platform_div[0].text_content().strip()
-            else:
-                # otherwise, use the result_type text_content
-                plat = result_type[0].text_content().strip()
-
-    else:
-        # for games, we want to pull the first result with the correct
-        # platform
-        results = doc.find_class('result')
-        for res in results:
-            result_plat = res.find_class('platform')[0].text_content().strip()
-            if result_plat == plat.upper():
-                result = res
-                break
-
-    if not result:
-        return 'No results found.'
-
-    # get the name, release date, and score from the result
-    product_title = result.find_class('product_title')[0]
-    name = product_title.text_content()
-    link = 'http://metacritic.com' + product_title.find('a').attrib['href']
-
-    try:
-        release = result.find_class('release_date')[0]. \
-            find_class('data')[0].text_content()
-
-        # strip extra spaces out of the release date
-        release = re.sub(r'\s{2,}', ' ', release)
-    except IndexError:
-        release = None
-
-    try:
-        score = result.find_class('metascore_w')[0].text_content()
-    except IndexError:
-        score = None
-
-    return '[{}] {} - \x02{}/100\x02, {} - {}'.format(plat.upper(), name, score or 'no score',
-                                                      'release: \x02%s\x02' % release if release else 'unreleased',
-                                                      link)
diff --git a/modules/minecraft_bukget.py b/modules/minecraft_bukget.py
deleted file mode 100644
index f336fb4..0000000
--- a/modules/minecraft_bukget.py
+++ /dev/null
@@ -1,157 +0,0 @@
-import time
-import random
-
-from util import hook, http, web, formatting
-
-
-## CONSTANTS
-
-base_url = "http://api.bukget.org/3/"
-
-search_url = base_url + "search/plugin_name/like/{}"
-random_url = base_url + "plugins/bukkit/?start={}&size=1"
-details_url = base_url + "plugins/bukkit/{}"
-
-
-@hook.onload()
-def load_categories():
-    global categories, count_total, count_categories
-    categories = http.get_json("http://api.bukget.org/3/categories")
-
-    count_total = sum([cat["count"] for cat in categories])
-    count_categories = {cat["name"].lower(): int(cat["count"]) for cat in categories}  # dict comps!
-
-
-class BukgetError(Exception):
-    def __init__(self, code, text):
-        self.code = code
-        self.text = text
-
-    def __str__(self):
-        return self.text
-
-
-## DATA FUNCTIONS
-
-def plugin_search(term):
-    """ searches for a plugin with the bukget API and returns the slug """
-    term = term.lower().strip()
-
-    search_term = http.quote_plus(term)
-
-    try:
-        results = http.get_json(search_url.format(search_term))
-    except (http.HTTPError, http.URLError) as e:
-        raise BukgetError(500, "Error Fetching Search Page: {}".format(e))
-
-    if not results:
-        raise BukgetError(404, "No Results Found")
-
-    for result in results:
-        if result["slug"] == term:
-            return result["slug"]
-
-    return results[0]["slug"]
-
-
-def plugin_random():
-    """ gets a random plugin from the bukget API and returns the slug """
-    results = None
-
-    while not results:
-        plugin_number = random.randint(1, count_total)
-        print("trying {}".format(plugin_number))
-        try:
-            results = http.get_json(random_url.format(plugin_number))
-        except (http.HTTPError, http.URLError) as e:
-            raise BukgetError(500, "Error Fetching Search Page: {}".format(e))
-
-    return results[0]["slug"]
-
-
-def plugin_details(slug):
-    """ takes a plugin slug and returns details from the bukget API """
-    slug = slug.lower().strip()
-
-    try:
-        details = http.get_json(details_url.format(slug))
-    except (http.HTTPError, http.URLError) as e:
-        raise BukgetError(500, "Error Fetching Details: {}".format(e))
-    return details
-
-
-## OTHER FUNCTIONS
-
-def format_output(data):
-    """ takes plugin data and returns two strings representing information about that plugin """
-    name = data["plugin_name"]
-    description = formatting.truncate_str(data['description'], 30)
-    url = data['website']
-    authors = data['authors'][0]
-    authors = authors[0] + "\u200b" + authors[1:]
-    stage = data['stage']
-
-    current_version = data['versions'][0]
-
-    last_update = time.strftime('%d %B %Y %H:%M',
-                                time.gmtime(current_version['date']))
-    version_number = data['versions'][0]['version']
-
-    bukkit_versions = ", ".join(current_version['game_versions'])
-    link = web.try_isgd(current_version['link'])
-
-    if description:
-        line_a = "\x02{}\x02, by \x02{}\x02 - {} - ({}) \x02{}".format(name, authors, description, stage, url)
-    else:
-        line_a = "\x02{}\x02, by \x02{}\x02 ({}) \x02{}".format(name, authors, stage, url)
-
-    line_b = "Last release: \x02v{}\x02 for \x02{}\x02 at {} \x02{}\x02".format(version_number, bukkit_versions,
-                                                                                last_update, link)
-
-    return line_a, line_b
-
-
-## HOOK FUNCTIONS
-
-@hook.command(["bukget", "plugin"], threaded=True)
-def bukget(text, reply, message):
-    """bukget <slug/name> - Look up a plugin on dev.bukkit.org"""
-    # get the plugin slug using search
-    try:
-        slug = plugin_search(text)
-    except BukgetError as e:
-        return e
-
-    # get the plugin info using the slug
-    try:
-        data = plugin_details(slug)
-    except BukgetError as e:
-        return e
-
-    # format the final message and send it to IRC
-    line_a, line_b = format_output(data)
-
-    reply(line_a)
-    message(line_b)
-
-
-@hook.command(threaded=True, autohelp=None)
-def randomplugin(reply, message):
-    """randomplugin - Gets a random plugin from dev.bukkit.org"""
-    # get a random plugin slug
-    try:
-        slug = plugin_random()
-    except BukgetError as e:
-        return e
-
-    # get the plugin info using the slug
-    try:
-        data = plugin_details(slug)
-    except BukgetError as e:
-        return e
-
-    # format the final message and send it to IRC
-    line_a, line_b = format_output(data)
-
-    reply(line_a)
-    message(line_b)
\ No newline at end of file
diff --git a/modules/minecraft_items.py b/modules/minecraft_items.py
deleted file mode 100644
index bcb596b..0000000
--- a/modules/minecraft_items.py
+++ /dev/null
@@ -1,98 +0,0 @@
-""" plugin by _303 (?)
-"""
-
-import re
-
-from util import hook
-
-
-pattern = re.compile(r'^(?P<count>\d+)x (?P<name>.+?): (?P<ingredients>.*)$')
-
-recipelist = []
-
-
-class Recipe(object):
-    __slots__ = 'output', 'count', 'ingredients', 'line'
-
-    def __init__(self, output, count, ingredients, line):
-        self.output = output
-        self.count = count
-        self.ingredients = ingredients
-        self.line = line
-
-    def __str__(self):
-        return self.line
-
-
-with open("./data/recipes.txt") as f:
-    for line in f.readlines():
-        if line.startswith("//"):
-            continue
-        line = line.strip()
-        match = pattern.match(line)
-        if not match:
-            continue
-        recipelist.append(Recipe(line=line,
-                                 output=match.group("name").lower(),
-                                 ingredients=match.group("ingredients"),
-                                 count=match.group("count")))
-
-ids = []
-
-with open("./data/itemids.txt") as f:
-    for line in f.readlines():
-        if line.startswith("//"):
-            continue
-        parts = line.strip().split()
-        itemid = parts[0]
-        name = " ".join(parts[1:])
-        ids.append((itemid, name))
-
-
-@hook.command(["mcitem", "mcid"], threaded=False)
-def mcitem(inp, reply=None):
-    """mcitem <item/id> -- gets the id from an item or vice versa"""
-    inp = inp.lower().strip()
-
-    if inp == "":
-        reply("error: no input.")
-        return
-
-    results = []
-
-    for item_id, item_name in ids:
-        if inp == item_id:
-            results = ["\x02[{}]\x02 {}".format(item_id, item_name)]
-            break
-        elif inp in item_name.lower():
-            results.append("\x02[{}]\x02 {}".format(item_id, item_name))
-
-    if not results:
-        return "No matches found."
-
-    if len(results) > 12:
-        reply("There are too many options, please narrow your search. ({})".format(str(len(results))))
-        return
-
-    out = ", ".join(results)
-
-    return out
-
-
-@hook.command(["mcrecipe", "mccraft"], threaded=False)
-def mcrecipe(inp, reply=None):
-    """mcrecipe <item> -- gets the crafting recipe for an item"""
-    inp = inp.lower().strip()
-
-    results = [recipe.line for recipe in recipelist
-               if inp in recipe.output]
-
-    if not results:
-        return "No matches found."
-
-    if len(results) > 3:
-        reply("There are too many options, please narrow your search. ({})".format(len(results)))
-        return
-
-    for result in results:
-        reply(result)
diff --git a/modules/minecraft_ping.py b/modules/minecraft_ping.py
deleted file mode 100644
index 3c59f81..0000000
--- a/modules/minecraft_ping.py
+++ /dev/null
@@ -1,232 +0,0 @@
-import socket
-import struct
-import json
-import traceback
-
-from util import hook
-
-
-try:
-    import DNS
-
-    has_dns = True
-except ImportError:
-    has_dns = False
-
-mc_colors = [('\xa7f', '\x0300'), ('\xa70', '\x0301'), ('\xa71', '\x0302'), ('\xa72', '\x0303'),
-             ('\xa7c', '\x0304'), ('\xa74', '\x0305'), ('\xa75', '\x0306'), ('\xa76', '\x0307'),
-             ('\xa7e', '\x0308'), ('\xa7a', '\x0309'), ('\xa73', '\x0310'), ('\xa7b', '\x0311'),
-             ('\xa71', '\x0312'), ('\xa7d', '\x0313'), ('\xa78', '\x0314'), ('\xa77', '\x0315'),
-             ('\xa7l', '\x02'), ('\xa79', '\x0310'), ('\xa7o', '\t'), ('\xa7m', '\x13'),
-             ('\xa7r', '\x0f'), ('\xa7n', '\x15')]
-
-
-## EXCEPTIONS
-
-
-class PingError(Exception):
-    def __init__(self, text):
-        self.text = text
-
-    def __str__(self):
-        return self.text
-
-
-class ParseError(Exception):
-    def __init__(self, text):
-        self.text = text
-
-    def __str__(self):
-        return self.text
-
-
-## MISC
-
-
-def unpack_varint(s):
-    d = 0
-    i = 0
-    while True:
-        b = ord(s.recv(1))
-        d |= (b & 0x7F) << 7 * i
-        i += 1
-        if not b & 0x80:
-            return d
-
-
-pack_data = lambda d: struct.pack('>b', len(d)) + d
-pack_port = lambda i: struct.pack('>H', i)
-
-## DATA FUNCTIONS
-
-
-def mcping_modern(host, port):
-    """ pings a server using the modern (1.7+) protocol and returns data """
-    try:
-        # connect to the server
-        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
-
-        try:
-            s.connect((host, port))
-        except socket.gaierror:
-            raise PingError("Invalid hostname")
-        except socket.timeout:
-            raise PingError("Request timed out")
-
-        # send handshake + status request
-        s.send(pack_data(b"\x00\x00" + pack_data(host.encode('utf8')) + pack_port(port) + b"\x01"))
-        s.send(pack_data(b"\x00"))
-
-        # read response
-        unpack_varint(s)  # Packet length
-        unpack_varint(s)  # Packet ID
-        l = unpack_varint(s)  # String length
-
-        if not l > 1:
-            raise PingError("Invalid response")
-
-        d = b""
-        while len(d) < l:
-            d += s.recv(1024)
-
-        # Close our socket
-        s.close()
-    except socket.error:
-        raise PingError("Socket Error")
-
-    # Load json and return
-    data = json.loads(d.decode('utf8'))
-    try:
-        version = data["version"]["name"]
-        try:
-            desc = " ".join(data["description"]["text"].split())
-        except TypeError:
-            desc = " ".join(data["description"].split())
-        max_players = data["players"]["max"]
-        online = data["players"]["online"]
-    except Exception as e:
-        # TODO: except Exception is bad
-        traceback.print_exc(e)
-        raise PingError("Unknown Error: {}".format(e))
-
-    output = {
-        "motd": format_colors(desc),
-        "motd_raw": desc,
-        "version": version,
-        "players": online,
-        "players_max": max_players
-    }
-    return output
-
-
-def mcping_legacy(host, port):
-    """ pings a server using the legacy (1.6 and older) protocol and returns data """
-    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
-
-    try:
-        sock.connect((host, port))
-        sock.send('\xfe\x01')
-        response = sock.recv(1)
-    except socket.gaierror:
-        raise PingError("Invalid hostname")
-    except socket.timeout:
-        raise PingError("Request timed out")
-
-    if response[0] != '\xff':
-        raise PingError("Invalid response")
-
-    length = struct.unpack('!h', sock.recv(2))[0]
-    values = sock.recv(length * 2).decode('utf-16be')
-    data = values.split('\x00')  # try to decode data using new format
-    if len(data) == 1:
-        # failed to decode data, server is using old format
-        data = values.split('\xa7')
-        output = {
-            "motd": format_colors(" ".join(data[0].split())),
-            "motd_raw": data[0],
-            "version": None,
-            "players": data[1],
-            "players_max": data[2]
-        }
-    else:
-        # decoded data, server is using new format
-        output = {
-            "motd": format_colors(" ".join(data[3].split())),
-            "motd_raw": data[3],
-            "version": data[2],
-            "players": data[4],
-            "players_max": data[5]
-        }
-    sock.close()
-    return output
-
-
-## FORMATTING/PARSING FUNCTIONS
-
-def check_srv(domain):
-    """ takes a domain and finds minecraft SRV records """
-    DNS.DiscoverNameServers()
-    srv_req = DNS.Request(qtype='srv')
-    srv_result = srv_req.req('_minecraft._tcp.{}'.format(domain))
-
-    for getsrv in srv_result.answers:
-        if getsrv['typename'] == 'SRV':
-            data = [getsrv['data'][2], getsrv['data'][3]]
-            return data
-
-
-def parse_input(inp):
-    """ takes the input from the mcping command and returns the host and port """
-    inp = inp.strip().split(" ")[0]
-    if ":" in inp:
-        # the port is defined in the input string
-        host, port = inp.split(":", 1)
-        try:
-            port = int(port)
-            if port > 65535 or port < 0:
-                raise ParseError("The port '{}' is invalid.".format(port))
-        except ValueError:
-            raise ParseError("The port '{}' is invalid.".format(port))
-        return host, port
-    if has_dns:
-        # the port is not in the input string, but we have PyDNS so look for a SRV record
-        srv_data = check_srv(inp)
-        if srv_data:
-            return str(srv_data[1]), int(srv_data[0])
-    # return default port
-    return inp, 25565
-
-
-def format_colors(motd):
-    for original, replacement in mc_colors:
-        motd = motd.replace(original, replacement)
-    motd = motd.replace("\xa7k", "")
-    return motd
-
-
-def format_output(data):
-    if data["version"]:
-        return "{motd}\x0f - {version}\x0f - {players}/{players_max}" \
-               " players.".format(**data).replace("\n", "\x0f - ")
-    else:
-        return "{motd}\x0f - {players}/{players_max}" \
-               " players.".format(**data).replace("\n", "\x0f - ")
-
-
-@hook.command(["mcping", "mcp"], threaded=True)
-def mcping(inp):
-    """mcping <server>[:port] - Ping a Minecraft server to check status."""
-    try:
-        host, port = parse_input(inp)
-    except ParseError as e:
-        return "Could not parse input ({})".format(e)
-
-    try:
-        data = mcping_modern(host, port)
-    except PingError:
-        try:
-            data = mcping_legacy(host, port)
-        except PingError as e:
-            return "Could not ping server, is it offline? ({})".format(e)
-
-    return format_output(data)
diff --git a/modules/minecraft_status.py b/modules/minecraft_status.py
deleted file mode 100644
index cb90dbd..0000000
--- a/modules/minecraft_status.py
+++ /dev/null
@@ -1,42 +0,0 @@
-import json
-
-from util import hook, http
-
-
-green_prefix = "\x02\x0f"
-green_suffix = ": \x033\x02\u2714"
-yellow_prefix = "\x02\x0f"
-yellow_suffix = ": \x037\x02\u26A0"
-red_prefix = "\x02\x0f"
-red_suffix = ": \x034\x02\u2716"
-
-
-@hook.command(["mcs", "mcstatus", "mojang"], threaded=True, autohelp=False)
-def mcstatus():
-    """mcstatus -- Checks the status of various Mojang (the creators of Minecraft) servers."""
-
-    try:
-        result = http.get("http://status.mojang.com/check")
-    except (http.URLError, http.HTTPError) as e:
-        return "Unable to get Minecraft server status: {}".format(e)
-
-    data = json.loads(result)
-
-    # use a loop so we don't have to update it if they add more servers
-    servers = []
-    for server_dict in data:
-        for server, status in server_dict.items():
-            if server == "minecraft.net":
-                server = "MC|Website"
-            elif server.endswith(".mojang.com"):
-                server = "MJ|{}".format(server[:-11].capitalize())
-            elif server.endswith(".minecraft.net"):
-                server = "MC|{}".format(server[:-14].capitalize())
-
-            if status == "green":
-                servers.append("{}{}{}".format(green_prefix, server, green_suffix))
-            elif status == "yellow":
-                servers.append("{}{}{}".format(yellow_prefix, server, yellow_suffix))
-            else:
-                servers.append("{}{}{}".format(red_prefix, server, red_suffix))
-    return "  ".join(servers)
diff --git a/modules/minecraft_user.py b/modules/minecraft_user.py
deleted file mode 100644
index 0c8d495..0000000
--- a/modules/minecraft_user.py
+++ /dev/null
@@ -1,101 +0,0 @@
-import json
-
-from util import hook, http
-
-
-NAME_URL = "https://account.minecraft.net/buy/frame/checkName/{}"
-PAID_URL = "http://www.minecraft.net/haspaid.jsp"
-
-
-class McuError(Exception):
-    pass
-
-
-def get_status(name):
-    """ takes a name and returns status """
-    try:
-        name_encoded = http.quote_plus(name)
-        response = http.get(NAME_URL.format(name_encoded))
-    except (http.URLError, http.HTTPError) as e:
-        raise McuError("Could not get name status: {}".format(e))
-
-    if "OK" in response:
-        return "free"
-    elif "TAKEN" in response:
-        return "taken"
-    elif "invalid characters" in response:
-        return "invalid"
-
-
-def get_profile(name):
-    profile = {}
-
-    # form the profile request
-    request = {
-        "name": name,
-        "agent": "minecraft"
-    }
-
-    # submit the profile request
-    try:
-        headers = {"Content-Type": "application/json"}
-        r = http.get_json(
-            'https://api.mojang.com/profiles/page/1',
-            post_data=json.dumps(request).encode('utf-8'),
-            headers=headers
-        )
-    except (http.URLError, http.HTTPError) as e:
-        raise McuError("Could not get profile status: {}".format(e))
-
-    user = r["profiles"][0]
-    profile["name"] = user["name"]
-    profile["id"] = user["id"]
-
-    profile["legacy"] = user.get("legacy", False)
-
-    try:
-        response = http.get(PAID_URL, user=name)
-    except (http.URLError, http.HTTPError) as e:
-        raise McuError("Could not get payment status: {}".format(e))
-
-    if "true" in response:
-        profile["paid"] = True
-    else:
-        profile["paid"] = False
-
-    return profile
-
-
-@hook.command(["mcuser", "mcpaid", "haspaid"], threaded=True)
-def mcuser(inp):
-    """mcpaid <username> -- Gets information about the Minecraft user <account>."""
-    user = inp.strip()
-
-    try:
-        # get status of name (does it exist?)
-        name_status = get_status(user)
-    except McuError as e:
-        return e
-
-    if name_status == "taken":
-        try:
-            # get information about user
-            profile = get_profile(user)
-        except McuError as e:
-            return "Error: {}".format(e)
-
-        profile["lt"] = ", legacy" if profile["legacy"] else ""
-
-        if profile["paid"]:
-            return "The account \x02{name}\x02 ({id}{lt}) exists. It is a \x02paid\x02" \
-                   " account.".format(**profile)
-        else:
-            return "The account \x02{name}\x02 ({id}{lt}) exists. It \x034\x02is NOT\x02\x0f a paid" \
-                   " account.".format(**profile)
-    elif name_status == "free":
-        return "The account \x02{}\x02 does not exist.".format(user)
-    elif name_status == "invalid":
-        return "The name \x02{}\x02 contains invalid characters.".format(user)
-    else:
-        # if you see this, panic
-        return "Unknown Error."
\ No newline at end of file
diff --git a/modules/minecraft_wiki.py b/modules/minecraft_wiki.py
deleted file mode 100644
index e5419a7..0000000
--- a/modules/minecraft_wiki.py
+++ /dev/null
@@ -1,51 +0,0 @@
-import re
-
-from util import hook, http, formatting
-
-
-api_url = "http://minecraft.gamepedia.com/api.php?action=opensearch"
-mc_url = "http://minecraft.gamepedia.com/"
-
-
-@hook.command(threaded=True)
-def mcwiki(text):
-    """mcwiki <phrase> -- Gets the first paragraph of
-    the Minecraft Wiki article on <phrase>."""
-
-    try:
-        j = http.get_json(api_url, search=text)
-    except (http.HTTPError, http.URLError) as e:
-        return "Error fetching search results: {}".format(e)
-    except ValueError as e:
-        return "Error reading search results: {}".format(e)
-
-    if not j[1]:
-        return "No results found."
-
-    # we remove items with a '/' in the name, because
-    # gamepedia uses sub-pages for different languages
-    # for some stupid reason
-    items = [item for item in j[1] if not "/" in item]
-
-    if items:
-        article_name = items[0].replace(' ', '_').encode('utf8')
-    else:
-        # there are no items without /, just return a / one
-        article_name = j[1][0].replace(' ', '_').encode('utf8')
-
-    url = mc_url + http.quote(article_name, '')
-
-    try:
-        page = http.get_html(url)
-    except (http.HTTPError, http.URLError) as e:
-        return "Error fetching wiki page: {}".format(e)
-
-    for p in page.xpath('//div[@class="mw-content-ltr"]/p'):
-        if p.text_content():
-            summary = " ".join(p.text_content().splitlines())
-            summary = re.sub("\[\d+\]", "", summary)
-            summary = formatting.truncate_str(summary, 200)
-            return "{} :: {}".format(summary, url)
-
-    # this shouldn't happen
-    return "Unknown Error."
diff --git a/modules/mlia.py b/modules/mlia.py
deleted file mode 100644
index 9f3226f..0000000
--- a/modules/mlia.py
+++ /dev/null
@@ -1,34 +0,0 @@
-# Plugin by Infinity - <https://github.com/infinitylabs/UguuBot>
-
-import random
-
-from util import hook, http
-
-
-mlia_cache = []
-
-
-def refresh_cache():
-    """gets a page of random MLIAs and puts them into a dictionary """
-    url = 'http://mylifeisaverage.com/{}'.format(random.randint(1, 11000))
-    soup = http.get_soup(url)
-
-    for story in soup.find_all('div', {'class': 'story '}):
-        mlia_id = story.find('span', {'class': 'left'}).a.text
-        mlia_text = story.find('div', {'class': 'sc'}).text.strip()
-        mlia_cache.append((mlia_id, mlia_text))
-
-# do an initial refresh of the cache
-refresh_cache()
-
-
-@hook.command(threaded=True, autohelp=False)
-def mlia(reply):
-    """mlia -- Gets a random quote from MyLifeIsAverage.com."""
-    # grab the last item in the mlia cache and remove it
-    mlia_id, text = mlia_cache.pop()
-    # reply with the mlia we grabbed
-    reply('({}) {}'.format(mlia_id, text))
-    # refresh mlia cache if its getting empty
-    if len(mlia_cache) < 3:
-        refresh_cache()
diff --git a/modules/namegen.py b/modules/namegen.py
deleted file mode 100644
index e182c7f..0000000
--- a/modules/namegen.py
+++ /dev/null
@@ -1,58 +0,0 @@
-import json
-import os
-
-from util import hook, formatting, textgen
-
-
-def get_generator(_json):
-    data = json.loads(_json)
-    return textgen.TextGenerator(data["templates"],
-                                 data["parts"], default_templates=data["default_templates"])
-
-
-@hook.command(threaded=True, autohelp=False)
-def namegen(input, bot):
-    """namegen [generator] -- Generates some names using the chosen generator.
-    :type bot: core.bot.CloudBot
-    'namegen list' will display a list of all generators."""
-
-    # clean up the input
-    inp = input.text.strip().lower()
-
-    # get a list of available name generators
-    files = os.listdir(os.path.join(bot.data_dir, "name_files"))
-    all_modules = []
-    for i in files:
-        if os.path.splitext(i)[1] == ".json":
-            all_modules.append(os.path.splitext(i)[0])
-    all_modules.sort()
-
-    # command to return a list of all available generators
-    if inp == "list":
-        message = "Available generators: "
-        message += formatting.get_text_list(all_modules, 'and')
-        input.notice(message)
-        return
-
-    if inp:
-        selected_module = inp.split()[0]
-    else:
-        # make some generic fantasy names
-        selected_module = "fantasy"
-
-    # check if the selected module is valid
-    if not selected_module in all_modules:
-        return "Invalid name generator :("
-
-    # load the name generator
-    with open(os.path.join(bot.data_dir, "name_files", "{}.json".format(selected_module))) as f:
-        try:
-            generator = get_generator(f.read())
-        except ValueError as error:
-            return "Unable to read name file: {}".format(error)
-
-    # time to generate some names
-    name_list = generator.generate_strings(10)
-
-    # and finally return the final message :D
-    return "Some names to ponder: {}.".format(formatting.get_text_list(name_list, 'and'))
diff --git a/modules/newegg.py b/modules/newegg.py
deleted file mode 100644
index 33d72af..0000000
--- a/modules/newegg.py
+++ /dev/null
@@ -1,95 +0,0 @@
-import json
-import re
-
-from util import hook, http, formatting, web
-
-
-## CONSTANTS
-
-ITEM_URL = "http://www.newegg.com/Product/Product.aspx?Item={}"
-
-API_PRODUCT = "http://www.ows.newegg.com/Products.egg/{}/ProductDetails"
-API_SEARCH = "http://www.ows.newegg.com/Search.egg/Advanced"
-
-NEWEGG_RE = (r"(?:(?:www.newegg.com|newegg.com)/Product/Product\.aspx\?Item=)([-_a-zA-Z0-9]+)", re.I)
-
-
-## OTHER FUNCTIONS
-
-def format_item(item, show_url=True):
-    """ takes a newegg API item object and returns a description """
-    title = formatting.truncate_str(item["Title"], 50)
-
-    # format the rating nicely if it exists
-    if not item["ReviewSummary"]["TotalReviews"] == "[]":
-        rating = "Rated {}/5 ({} ratings)".format(item["ReviewSummary"]["Rating"],
-                                                  item["ReviewSummary"]["TotalReviews"][1:-1])
-    else:
-        rating = "No Ratings"
-
-    if not item["FinalPrice"] == item["OriginalPrice"]:
-        price = "{FinalPrice}, was {OriginalPrice}".format(**item)
-    else:
-        price = item["FinalPrice"]
-
-    tags = []
-
-    if item["Instock"]:
-        tags.append("\x02Stock Available\x02")
-    else:
-        tags.append("\x02Out Of Stock\x02")
-
-    if item["FreeShippingFlag"]:
-        tags.append("\x02Free Shipping\x02")
-
-    if item["IsFeaturedItem"]:
-        tags.append("\x02Featured\x02")
-
-    if item["IsShellShockerItem"]:
-        tags.append("\x02SHELL SHOCKER\u00AE\x02")
-
-    # join all the tags together in a comma separated string ("tag1, tag2, tag3")
-    tag_text = ", ".join(tags)
-
-    if show_url:
-        # create the item URL and shorten it
-        url = web.try_isgd(ITEM_URL.format(item["NeweggItemNumber"]))
-        return "\x02{}\x02 ({}) - {} - {} - {}".format(title, price, rating,
-                                                       tag_text, url)
-    else:
-        return "\x02{}\x02 ({}) - {} - {}".format(title, price, rating,
-                                                  tag_text)
-
-
-## HOOK FUNCTIONS
-
-@hook.regex(*NEWEGG_RE, threaded=True)
-def newegg_url(match):
-    item_id = match.group(1)
-    item = http.get_json(API_PRODUCT.format(item_id))
-    return format_item(item, show_url=False)
-
-
-@hook.command(threaded=True)
-def newegg(inp):
-    """newegg <item name> -- Searches newegg.com for <item name>"""
-
-    # form the search request
-    request = {
-        "Keyword": inp,
-        "Sort": "FEATURED"
-    }
-
-    # submit the search request
-    r = http.get_json(
-        'http://www.ows.newegg.com/Search.egg/Advanced',
-        post_data=json.dumps(request).encode('utf-8')
-    )
-
-    # get the first result
-    if r["ProductListItems"]:
-        return format_item(r["ProductListItems"][0])
-    else:
-        return "No results found."
-
-
diff --git a/modules/newgrounds.py b/modules/newgrounds.py
deleted file mode 100644
index e0d96c1..0000000
--- a/modules/newgrounds.py
+++ /dev/null
@@ -1,60 +0,0 @@
-import re
-
-from util import hook, http
-
-
-newgrounds_re = (r'(.*:)//(www.newgrounds.com|newgrounds.com)(:[0-9]+)?(.*)', re.I)
-valid = set('0123456789')
-
-
-def test(s):
-    return set(s) <= valid
-
-
-@hook.regex(*newgrounds_re, threaded=True)
-def newgrounds_url(match):
-    location = match.group(4).split("/")[-1]
-    if not test(location):
-        print("Not a valid Newgrounds portal ID. Example: http://www.newgrounds.com/portal/view/593993")
-        return None
-    soup = http.get_soup("http://www.newgrounds.com/portal/view/" + location)
-
-    title = "\x02{}\x02".format(soup.find('title').text)
-
-    # get author
-    try:
-        author_info = soup.find('ul', {'class': 'authorlinks'}).find('img')['alt']
-        author = " - \x02{}\x02".format(author_info)
-    except:
-        author = ""
-
-    # get rating
-    try:
-        rating_info = soup.find('dd', {'class': 'star-variable'})['title'].split("Stars &ndash;")[0].strip()
-        rating = " - rated \x02{}\x02/\x025.0\x02".format(rating_info)
-    except:
-        rating = ""
-
-    # get amount of ratings
-    try:
-        ratings_info = soup.find('dd', {'class': 'star-variable'})['title'].split("Stars"
-                                                                                  " &ndsh;")[1].replace("Votes",
-                                                                                                        "").strip()
-        numofratings = " ({})".format(ratings_info)
-    except:
-        numofratings = ""
-
-    # get amount of views
-    try:
-        views_info = soup.find('dl', {'class': 'contentdata'}).findAll('dd')[1].find('strong').text
-        views = " - \x02{}\x02 views".format(views_info)
-    except:
-        views = ""
-
-    # get upload data
-    try:
-        date = "on \x02{}\x02".format(soup.find('dl', {'class': 'sidestats'}).find('dd').text)
-    except:
-        date = ""
-
-    return title + rating + numofratings + views + author + date
diff --git a/modules/notes.py b/modules/notes.py
deleted file mode 100644
index 9364b89..0000000
--- a/modules/notes.py
+++ /dev/null
@@ -1,189 +0,0 @@
-import re
-
-from util import hook
-
-db_ready = False
-
-
-def clean_sql(sql):
-    return re.sub(r'\s+', " ", sql).strip()
-
-
-def db_init(db):
-    global db_ready
-    if db_ready:
-        return
-
-    exists = db.execute("""
-      select exists (
-        select * from sqlite_master where type = "table" and name = "todos"
-      )
-    """).fetchone()[0] == 1
-
-    if not exists:
-        db.execute(clean_sql("""
-           create virtual table todos using fts4(
-                user,
-                text,
-                added,
-                tokenize=porter
-           )"""))
-
-    db.commit()
-
-    db_ready = True
-
-
-def db_getall(db, nick, limit=-1):
-    return db.execute("""
-        select added, text
-            from todos
-            where lower(user) = lower(?)
-            order by added desc
-            limit ?
-
-        """, (nick, limit))
-
-
-def db_get(db, nick, note_id):
-    return db.execute("""
-        select added, text from todos
-        where lower(user) = lower(?)
-        order by added desc
-        limit 1
-        offset ?
-    """, (nick, note_id)).fetchone()
-
-
-def db_del(db, nick, limit='all'):
-    row = db.execute("""
-        delete from todos
-        where rowid in (
-          select rowid from todos
-          where lower(user) = lower(?)
-          order by added desc
-          limit ?
-          offset ?)
-     """, (nick,
-           -1 if limit == 'all' else 1,
-           0 if limit == 'all' else limit))
-    db.commit()
-    return row
-
-
-def db_add(db, nick, text):
-    db.execute("""
-        insert into todos (user, text, added)
-        values (?, ?, CURRENT_TIMESTAMP)
-    """, (nick, text))
-    db.commit()
-
-
-def db_search(db, nick, query):
-    return db.execute("""
-        select added, text
-        from todos
-        where todos match ?
-        and lower(user) = lower(?)
-        order by added desc
-    """, (query, nick))
-
-
-@hook.command(["note", "notes"])
-def note(inp, nick, db, notice):
-    """note(s) <add|del|list|search> args -- Manipulates your list of notes."""
-
-    db_init(db)
-
-    parts = inp.split()
-    cmd = parts[0].lower()
-
-    args = parts[1:]
-
-    # code to allow users to access each others factoids and a copy of help
-    # ".note (add|del|list|search) [@user] args -- Manipulates your list of todos."
-    #if len(args) and args[0].startswith("@"):
-    #    nick = args[0][1:]
-    #    args = args[1:]
-
-    if cmd == 'add':
-        if not len(args):
-            return "no text"
-
-        text = " ".join(args)
-
-        db_add(db, nick, text)
-
-        notice("Note added!")
-        return
-    elif cmd == 'get':
-        if len(args):
-            try:
-                index = int(args[0])
-            except ValueError:
-                notice("Invalid number format.")
-                return
-        else:
-            index = 0
-
-        row = db_get(db, nick, index)
-
-        if not row:
-            notice("No such entry.")
-            return
-        notice("[{}]: {}: {}".format(index, row[0], row[1]))
-    elif cmd == 'del' or cmd == 'delete' or cmd == 'remove':
-        if not len(args):
-            return "error"
-
-        if args[0] == 'all':
-            index = 'all'
-        else:
-            try:
-                index = int(args[0])
-            except ValueError:
-                notice("Invalid number.")
-                return
-
-        rows = db_del(db, nick, index)
-
-        notice("Deleted {} entries".format(rows.rowcount))
-    elif cmd == 'list':
-        limit = -1
-
-        if len(args):
-            try:
-                limit = int(args[0])
-                limit = max(-1, limit)
-            except ValueError:
-                notice("Invalid number.")
-                return
-
-        rows = db_getall(db, nick, limit)
-
-        found = False
-
-        for (index, row) in enumerate(rows):
-            notice("[{}]: {}: {}".format(index, row[0], row[1]))
-            found = True
-
-        if not found:
-            notice("{} has no entries.".format(nick))
-    elif cmd == 'search':
-        if not len(args):
-            notice("No search query given!")
-            return
-        query = " ".join(args)
-        rows = db_search(db, nick, query)
-
-        found = False
-
-        for (index, row) in enumerate(rows):
-            notice("[{}]: {}: {}".format(index, row[0], row[1]))
-            found = True
-
-        if not found:
-            notice("{} has no matching entries for: {}".format(nick, query))
-
-    else:
-        notice("Unknown command: {}".format(cmd))
diff --git a/modules/op.py b/modules/op.py
deleted file mode 100644
index df1f887..0000000
--- a/modules/op.py
+++ /dev/null
@@ -1,179 +0,0 @@
-from util import hook
-
-
-def mode_cmd(mode, text, inp, chan, conn, notice):
-    """ generic mode setting function """
-    split = inp.split(" ")
-    if split[0].startswith("#"):
-        channel = split[0]
-        target = split[1]
-        notice("Attempting to {} {} in {}...".format(text, target, channel))
-        conn.send("MODE {} {} {}".format(channel, mode, target))
-    else:
-        channel = chan
-        target = split[0]
-        notice("Attempting to {} {} in {}...".format(text, target, channel))
-        conn.send("MODE {} {} {}".format(channel, mode, target))
-
-
-def mode_cmd_no_target(mode, text, inp, chan, conn, notice):
-    """ generic mode setting function without a target"""
-    split = inp.split(" ")
-    if split[0].startswith("#"):
-        channel = split[0]
-        notice("Attempting to {} {}...".format(text, channel))
-        conn.send("MODE {} {}".format(channel, mode))
-    else:
-        channel = chan
-        notice("Attempting to {} {}...".format(text, channel))
-        conn.send("MODE {} {}".format(channel, mode))
-
-
-@hook.command(permissions=["op_ban", "op"])
-def ban(inp, conn=None, chan=None, notice=None):
-    """ban [channel] <user> -- Makes the bot ban <user> in [channel].
-    If [channel] is blank the bot will ban <user> in
-    the channel the command was used in."""
-    mode_cmd("+b", "ban", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_ban", "op"])
-def unban(inp, conn=None, chan=None, notice=None):
-    """unban [channel] <user> -- Makes the bot unban <user> in [channel].
-    If [channel] is blank the bot will unban <user> in
-    the channel the command was used in."""
-    mode_cmd("-b", "unban", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_quiet", "op"])
-def quiet(inp, conn=None, chan=None, notice=None):
-    """quiet [channel] <user> -- Makes the bot quiet <user> in [channel].
-    If [channel] is blank the bot will quiet <user> in
-    the channel the command was used in."""
-    mode_cmd("+q", "quiet", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_quiet", "op"])
-def unquiet(inp, conn=None, chan=None, notice=None):
-    """unquiet [channel] <user> -- Makes the bot unquiet <user> in [channel].
-    If [channel] is blank the bot will unquiet <user> in
-    the channel the command was used in."""
-    mode_cmd("-q", "unquiet", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_voice", "op"])
-def voice(inp, conn=None, chan=None, notice=None):
-    """voice [channel] <user> -- Makes the bot voice <user> in [channel].
-    If [channel] is blank the bot will voice <user> in
-    the channel the command was used in."""
-    mode_cmd("+v", "voice", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_voice", "op"])
-def devoice(inp, conn=None, chan=None, notice=None):
-    """devoice [channel] <user> -- Makes the bot devoice <user> in [channel].
-    If [channel] is blank the bot will devoice <user> in
-    the channel the command was used in."""
-    mode_cmd("-v", "devoice", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_op", "op"])
-def op(inp, conn=None, chan=None, notice=None):
-    """op [channel] <user> -- Makes the bot op <user> in [channel].
-    If [channel] is blank the bot will op <user> in
-    the channel the command was used in."""
-    mode_cmd("+o", "op", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_op", "op"])
-def deop(inp, conn=None, chan=None, notice=None):
-    """deop [channel] <user> -- Makes the bot deop <user> in [channel].
-    If [channel] is blank the bot will deop <user> in
-    the channel the command was used in."""
-    mode_cmd("-o", "deop", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_topic", "op"])
-def topic(inp, conn=None, chan=None):
-    """topic [channel] <topic> -- Change the topic of a channel."""
-    split = inp.split(" ")
-    if split[0].startswith("#"):
-        message = " ".join(split[1:])
-        chan = split[0]
-    else:
-        message = " ".join(split)
-    conn.send("TOPIC {} :{}".format(chan, message))
-
-
-@hook.command(permissions=["op_kick", "op"])
-def kick(inp, chan=None, conn=None, notice=None):
-    """kick [channel] <user> [reason] -- Makes the bot kick <user> in [channel]
-    If [channel] is blank the bot will kick the <user> in
-    the channel the command was used in."""
-    split = inp.split(" ")
-
-    if split[0].startswith("#"):
-        channel = split[0]
-        target = split[1]
-        if len(split) > 2:
-            reason = " ".join(split[2:])
-            out = "KICK {} {}: {}".format(channel, target, reason)
-        else:
-            out = "KICK {} {}".format(channel, target)
-    else:
-        channel = chan
-        target = split[0]
-        if len(split) > 1:
-            reason = " ".join(split[1:])
-            out = "KICK {} {} :{}".format(channel, target, reason)
-        else:
-            out = "KICK {} {}".format(channel, target)
-
-    notice("Attempting to kick {} from {}...".format(target, channel))
-    conn.send(out)
-
-
-@hook.command(permissions=["op_rem", "op"])
-def remove(inp, chan=None, conn=None):
-    """remove [channel] [user] -- Force a user to part from a channel."""
-    split = inp.split(" ")
-    if split[0].startswith("#"):
-        message = " ".join(split[1:])
-        chan = split[0]
-        out = "REMOVE {} :{}".format(chan, message)
-    else:
-        message = " ".join(split)
-        out = "REMOVE {} :{}".format(chan, message)
-    conn.send(out)
-
-
-@hook.command(permissions=["op_mute", "op"], autohelp=False)
-def mute(inp, conn=None, chan=None, notice=None):
-    """mute [channel] -- Makes the bot mute a channel..
-    If [channel] is blank the bot will mute
-    the channel the command was used in."""
-    mode_cmd_no_target("+m", "mute", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_mute", "op"], autohelp=False)
-def unmute(inp, conn=None, chan=None, notice=None):
-    """mute [channel] -- Makes the bot mute a channel..
-    If [channel] is blank the bot will mute
-    the channel the command was used in."""
-    mode_cmd_no_target("-m", "unmute", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_lock", "op"], autohelp=False)
-def lock(inp, conn=None, chan=None, notice=None):
-    """lock [channel] -- Makes the bot lock a channel.
-    If [channel] is blank the bot will mute
-    the channel the command was used in."""
-    mode_cmd_no_target("+i", "lock", inp, chan, conn, notice)
-
-
-@hook.command(permissions=["op_lock", "op"], autohelp=False)
-def unlock(inp, conn=None, chan=None, notice=None):
-    """unlock [channel] -- Makes the bot unlock a channel..
-    If [channel] is blank the bot will mute
-    the channel the command was used in."""
-    mode_cmd_no_target("-i", "unlock", inp, chan, conn, notice)
diff --git a/modules/osrc.py b/modules/osrc.py
deleted file mode 100644
index 3dcb0b5..0000000
--- a/modules/osrc.py
+++ /dev/null
@@ -1,27 +0,0 @@
-from util import hook, http, web
-
-
-user_url = "http://osrc.dfm.io/{}"
-
-
-@hook.command
-def osrc(inp):
-    """osrc <github user> -- Gets an Open Source Report Card for <github user>"""
-
-    user_nick = inp.strip()
-    url = user_url.format(user_nick)
-
-    try:
-        soup = http.get_soup(url)
-    except (http.HTTPError, http.URLError):
-        return "Couldn't find any stats for this user."
-
-    report = soup.find("div", {"id": "description"}).find("p").get_text()
-
-    # Split and join to remove all the excess whitespace, slice the
-    # string to remove the trailing full stop.
-    report = " ".join(report.split())[:-1]
-
-    short_url = web.try_isgd(url)
-
-    return "{} - {}".format(report, short_url)
diff --git a/modules/pagecheck.py b/modules/pagecheck.py
deleted file mode 100644
index 3b6946c..0000000
--- a/modules/pagecheck.py
+++ /dev/null
@@ -1,48 +0,0 @@
-import urllib.parse
-
-from util import hook, http, urlnorm
-
-
-@hook.command
-def down(inp):
-    """down <url> -- Checks if the site at <url> is up or down.
-    :type inp: str
-    """
-
-    if not inp.startswith("http://"):
-        inp = 'http://' + inp
-
-    inp = 'http://' + urllib.parse.urlparse(inp).netloc
-
-    try:
-        http.get(inp, get_method='HEAD')
-        return '{} seems to be up'.format(inp)
-    except http.URLError:
-        return '{} seems to be down'.format(inp)
-
-
-@hook.command
-def isup(inp):
-    """isup -- uses isup.me to see if a site is up or not
-    :type inp: str
-    """
-
-    # slightly overcomplicated, esoteric URL parsing
-    scheme, auth, path, query, fragment = urllib.parse.urlsplit(inp.strip())
-
-    domain = auth or path
-    url = urlnorm.normalize(domain, assume_scheme="http")
-
-    try:
-        soup = http.get_soup('http://isup.me/' + domain)
-    except http.HTTPError:
-        return "Failed to get status."
-
-    content = soup.find('div').text.strip()
-
-    if "not just you" in content:
-        return "It's not just you. {} looks \x02\x034down\x02\x0f from here!".format(url)
-    elif "is up" in content:
-        return "It's just you. {} is \x02\x033up\x02\x0f.".format(url)
-    else:
-        return "Huh? That doesn't look like a site on the interweb."
diff --git a/modules/password.py b/modules/password.py
deleted file mode 100644
index 5e79d92..0000000
--- a/modules/password.py
+++ /dev/null
@@ -1,75 +0,0 @@
-import string
-
-try:
-    from Crypto.Random import random
-except ImportError:
-    # Just use the regular random module, not the strong one
-    import random
-
-from util import hook
-
-with open("data/password_words.txt") as f:
-    common_words = [line.strip() for line in f.readlines()]
-
-
-@hook.command(autohelp=False)
-def password(text, notice):
-    """password <length> [types] -- Generates a password of <length> (default 10).
-    [types] can include 'alpha', 'no caps', 'numeric', 'symbols' or any combination of the inp, eg. 'numbers symbols'"""
-    okay = []
-
-    # find the length needed for the password
-    numb = text.split(" ")
-
-    try:
-        length = int(numb[0])
-    except ValueError:
-        length = 10
-
-    # add alpha characters
-    if "alpha" in text or "letter" in text:
-        okay = okay + list(string.ascii_lowercase)
-        #adds capital characters if not told not to
-        if "no caps" not in text:
-            okay = okay + list(string.ascii_uppercase)
-
-    # add numbers
-    if "numeric" in text or "number" in text:
-        okay = okay + [str(x) for x in range(0, 10)]
-
-    # add symbols
-    if "symbol" in text:
-        sym = ['!', '@', '#', '$', '%', '^', '&', '*', '(', ')', '-', '=', '_', '+', '[', ']', '{', '}', '\\', '|', ';',
-               ':', "'", '.', '>', ',', '<', '/', '?', '`', '~', '"']
-        okay += okay + sym
-
-    # defaults to lowercase alpha password if the okay list is empty
-    if not okay:
-        okay = okay + list(string.ascii_lowercase)
-
-    pw = ""
-
-    # generates password
-    for x in range(length):
-        pw = pw + random.choice(okay)
-
-    notice(pw)
-
-
-@hook.command(["rpass", "rpassword", "readablepassword"], autohelp=False)
-def readable_password(text, notice):
-    """rpass [length]  -- Generates an easy to remember password with [length] (default 4) commonly used words."""
-    if text:
-        try:
-            length = int(text)
-        except ValueError:
-            notice("Invalid input '{}'".format(text))
-            return
-    else:
-        length = 4
-    words = []
-    # generate password
-    for x in range(length):
-        words.append(random.choice(common_words))
-
-    notice("Your password is '{}'. Feel free to remove the spaces when using it.".format(" ".join(words)))
diff --git a/modules/ping.py b/modules/ping.py
deleted file mode 100644
index 1ccfce1..0000000
--- a/modules/ping.py
+++ /dev/null
@@ -1,44 +0,0 @@
-# ping plugin by neersighted
-import subprocess
-import re
-import os
-
-from util import hook
-
-ping_regex = re.compile(r"(\d+.\d+)/(\d+.\d+)/(\d+.\d+)/(\d+.\d+)")
-
-
-@hook.command
-def ping(inp, reply=None):
-    """ping <host> [count] -- Pings <host> [count] times."""
-
-    if os.name == "nt":
-        return "Sorry, this command is not supported on Windows systems."
-        # TODO: Rewrite this entire command to work on Windows, somehow
-
-    args = inp.split(' ')
-    host = args[0]
-
-    # check for a second argument and set the ping count
-    if len(args) > 1:
-        count = int(args[1])
-        if count > 20:
-            count = 20
-    else:
-        count = 5
-
-    count = str(count)
-
-    # I suck at regex, but this is causing issues, and I'm just going to remove it
-    # I assume it's no longer needed with the way we run the process
-    # host = re.sub(r'([^\s\w\.])+', '', host)
-
-    reply("Attempting to ping {} {} times...".format(host, count))
-
-    pingcmd = subprocess.check_output(["ping", "-c", count, host]).decode("utf-8")
-    if "request timed out" in pingcmd or "unknown host" in pingcmd:
-        return "error: could not ping host"
-    else:
-        m = re.search(ping_regex, pingcmd)
-        return "min: %sms, max: %sms, average: %sms, range: %sms, count: %s" \
-               % (m.group(1), m.group(3), m.group(2), m.group(4), count)
diff --git a/modules/plpaste.py b/modules/plpaste.py
deleted file mode 100644
index a5bdadb..0000000
--- a/modules/plpaste.py
+++ /dev/null
@@ -1,20 +0,0 @@
-from os import listdir
-
-from util import hook, web
-
-
-@hook.command(permissions=["adminonly"])
-def plpaste(text, bot):
-    """
-    :type text: str
-    :type bot: core.bot.CloudBot
-    """
-    if text in bot.plugin_manager.commands:
-        file_path = bot.plugin_manager.commands[text].module.file_path
-        with open(file_path) as f:
-            return web.haste(f.read(), ext='py')
-    elif text + ".py" in listdir('modules/'):
-        with open('modules/{}.py'.format(text)) as f:
-            return web.haste(f.read(), ext='py')
-    else:
-        return "Could not find specified plugin."
diff --git a/modules/potato.py b/modules/potato.py
deleted file mode 100644
index 9987e18..0000000
--- a/modules/potato.py
+++ /dev/null
@@ -1,56 +0,0 @@
-# coding=utf-8
-import re
-import random
-
-from util import hook
-
-
-potatoes = ['AC Belmont', 'AC Blue Pride', 'AC Brador', 'AC Chaleur', 'AC Domino', 'AC Dubuc', 'AC Glacier Chip',
-            'AC Maple Gold', 'AC Novachip', 'AC Peregrine Red', 'AC Ptarmigan', 'AC Red Island', 'AC Saguenor',
-            'AC Stampede Russet', 'AC Sunbury', 'Abeille', 'Abnaki', 'Acadia', 'Acadia Russet', 'Accent',
-            'Adirondack Blue', 'Adirondack Red', 'Adora', 'Agria', 'All Blue', 'All Red', 'Alpha', 'Alta Russet',
-            'Alturas Russet', 'Amandine', 'Amisk', 'Andover', 'Anoka', 'Anson', 'Aquilon', 'Arran Consul', 'Asterix',
-            'Atlantic', 'Austrian Crescent', 'Avalanche', 'Banana', 'Bannock Russet', 'Batoche', 'BeRus',
-            'Belle De Fonteney', 'Belleisle', 'Bintje', 'Blossom', 'Blue Christie', 'Blue Mac', 'Brigus',
-            'Brise du Nord', 'Butte', 'Butterfinger', 'Caesar', 'CalWhite', 'CalRed', 'Caribe', 'Carlingford',
-            'Carlton', 'Carola', 'Cascade', 'Castile', 'Centennial Russet', 'Century Russet', 'Charlotte', 'Cherie',
-            'Cherokee', 'Cherry Red', 'Chieftain', 'Chipeta', 'Coastal Russet', 'Colorado Rose', 'Concurrent',
-            'Conestoga', 'Cowhorn', 'Crestone Russet', 'Crispin', 'Cupids', 'Daisy Gold', 'Dakota Pearl', 'Defender',
-            'Delikat', 'Denali', 'Desiree', 'Divina', 'Dundrod', 'Durango Red', 'Early Rose', 'Elba', 'Envol',
-            'Epicure', 'Eramosa', 'Estima', 'Eva', 'Fabula', 'Fambo', 'Fremont Russet', 'French Fingerling',
-            'Frontier Russet', 'Fundy', 'Garnet Chile', 'Gem Russet', 'GemStar Russet', 'Gemchip', 'German Butterball',
-            'Gigant', 'Goldrush', 'Granola', 'Green Mountain', 'Haida', 'Hertha', 'Hilite Russet', 'Huckleberry',
-            'Hunter', 'Huron', 'IdaRose', 'Innovator', 'Irish Cobbler', 'Island Sunshine', 'Ivory Crisp',
-            'Jacqueline Lee', 'Jemseg', 'Kanona', 'Katahdin', 'Kennebec', "Kerr's Pink", 'Keswick', 'Keuka Gold',
-            'Keystone Russet', 'King Edward VII', 'Kipfel', 'Klamath Russet', 'Krantz', 'LaRatte', 'Lady Rosetta',
-            'Latona', 'Lemhi Russet', 'Liberator', 'Lili', 'MaineChip', 'Marfona', 'Maris Bard', 'Maris Piper',
-            'Matilda', 'Mazama', 'McIntyre', 'Michigan Purple', 'Millenium Russet', 'Mirton Pearl', 'Modoc', 'Mondial',
-            'Monona', 'Morene', 'Morning Gold', 'Mouraska', 'Navan', 'Nicola', 'Nipigon', 'Niska', 'Nooksack',
-            'NorValley', 'Norchip', 'Nordonna', 'Norgold Russet', 'Norking Russet', 'Norland', 'Norwis', 'Obelix',
-            'Ozette', 'Peanut', 'Penta', 'Peribonka', 'Peruvian Purple', 'Pike', 'Pink Pearl', 'Prospect', 'Pungo',
-            'Purple Majesty', 'Purple Viking', 'Ranger Russet', 'Reba', 'Red Cloud', 'Red Gold', 'Red La Soda',
-            'Red Pontiac', 'Red Ruby', 'Red Thumb', 'Redsen', 'Rocket', 'Rose Finn Apple', 'Rose Gold', 'Roselys',
-            'Rote Erstling', 'Ruby Crescent', 'Russet Burbank', 'Russet Legend', 'Russet Norkotah', 'Russet Nugget',
-            'Russian Banana', 'Saginaw Gold', 'Sangre', 'Sant', 'Satina', 'Saxon', 'Sebago', 'Shepody', 'Sierra',
-            'Silverton Russet', 'Simcoe', 'Snowden', 'Spunta', "St. John's", 'Summit Russet', 'Sunrise', 'Superior',
-            'Symfonia', 'Tolaas', 'Trent', 'True Blue', 'Ulla', 'Umatilla Russet', 'Valisa', 'Van Gogh', 'Viking',
-            'Wallowa Russet', 'Warba', 'Western Russet', 'White Rose', 'Willamette', 'Winema', 'Yellow Finn',
-            'Yukon Gold']
-
-
-@hook.command
-def potato(inp, action=None):
-    """potato <user> - Makes <user> a tasty little potato."""
-    inp = inp.strip()
-
-    if not re.match("^[A-Za-z0-9_|.-\]\[]*$", inp.lower()):
-        return "I cant make a tasty potato for that user!"
-
-    potato_type = random.choice(potatoes)
-    size = random.choice(['small', 'little', 'mid-sized', 'medium-sized', 'large', 'gigantic'])
-    flavor = random.choice(['tasty', 'delectable', 'delicious', 'yummy', 'toothsome', 'scrumptious', 'luscious'])
-    method = random.choice(['bakes', 'fries', 'boils', 'roasts'])
-    side_dish = random.choice(['side salad', 'dollop of sour cream', 'piece of chicken', 'bowl of shredded bacon'])
-
-    action("{} a {} {} {} potato for {} and serves it with a small {}!".format(method, flavor, size, potato_type, inp,
-                                                                               side_dish))
diff --git a/modules/prefixes.py b/modules/prefixes.py
deleted file mode 100644
index ce575fd..0000000
--- a/modules/prefixes.py
+++ /dev/null
@@ -1,83 +0,0 @@
-import re
-
-from sqlalchemy import Table, Column, String, UniqueConstraint
-
-from core import main
-
-from util import hook, botvars
-
-table = Table(
-    "prefixes",
-    botvars.metadata,
-    Column("connection", String),
-    Column("channel", String),
-    Column("prefix", String),
-    UniqueConstraint("connection", "channel", "prefix")
-)
-
-
-@hook.onload()
-def load_command_re(db):
-    """
-    :type db: sqlalchemy.orm.Session
-    """
-    global chan_re
-    channel_prefixes = {}
-    for row in db.execute(table.select()):
-        connection = row["connection"]
-        channel = row["channel"]
-        prefix = row["prefix"]
-        key = (connection, channel)
-        if key in channel_prefixes:
-            channel_prefixes[key].append(re.escape(prefix))
-        else:
-            channel_prefixes[key] = [re.escape(prefix)]
-
-    chan_re = {}
-    for key, prefixes in channel_prefixes.items():
-        command_re = r"([{}])(\w+)(?:$|\s+)(.*)".format("".join(prefixes))
-        chan_re[key] = re.compile(command_re)
-
-
-@hook.command(permissions=["botcontrol"])
-def addprefix(text, conn, chan, db):
-    """delprefix <prefix> - Adds a command prefix <prefix> to the current channel
-    :type text: str
-    :type chan: str
-    :type db: sqlalchemy.orm.Session
-    """
-    print("Adding prefix {} to {}".format(text, chan))
-    db.execute(table.insert().values(connection=conn.name, channel=chan, prefix=text))
-    db.commit()
-    load_command_re(db)
-    return "Added command prefix {} to {}".format(text, chan)
-
-
-@hook.command(permissions=["botcontrol"])
-def delprefix(text, chan, db):
-    """delprefix <prefix> - Removes command prefix <prefix> from the current channel
-    :type text: str
-    :type chan: str
-    :type db: sqlalchemy.orm.Session
-    """
-    print("Removing prefix {} from {}".format(text, chan))
-    db.execute(table.delete().where(table.c.channel == chan).where(table.c.prefix == text))
-    db.commit()
-    load_command_re(db)
-    return "Removed command prefix {} from {}".format(text, chan)
-
-
-@hook.event("PRIVMSG", threaded=False)
-def run_extra_prefix(input, bot, conn, chan, lastparam):
-    key = (conn.name, chan)
-    if key in chan_re:
-        match = chan_re[key].match(lastparam)
-        if match:
-            command = match.group(2).lower()
-            if command in bot.plugin_manager.commands:
-                plugin = bot.plugin_manager.commands[command]
-                # this input is a one-use input, so we can just modify it and send it to the plugin
-                input.trigger = command
-                input.text = match.group(3).strip()
-                input.inp = input.text  # re-set inp as well, for compatibilty
-                yield from main.dispatch(bot, input, plugin)
diff --git a/modules/python.py b/modules/python.py
deleted file mode 100644
index 5cdc524..0000000
--- a/modules/python.py
+++ /dev/null
@@ -1,9 +0,0 @@
-from util import hook
-from util.pyexec import eval_py
-
-
-@hook.command
-def python(inp):
-    """python <prog> -- Executes <prog> as Python code."""
-
-    return eval_py(inp)
diff --git a/modules/qrcode.py b/modules/qrcode.py
deleted file mode 100644
index 9d481e0..0000000
--- a/modules/qrcode.py
+++ /dev/null
@@ -1,18 +0,0 @@
-# Plugin by https://github.com/Mu5tank05
-from util import hook, web, http
-
-
-@hook.command('qr')
-@hook.command
-def qrcode(inp):
-    """qrcode [link] returns a link for a QR code."""
-
-    args = {
-        "cht": "qr",  # chart type (QR)
-        "chs": "200x200",  # dimensions
-        "chl": inp  # data
-    }
-
-    link = http.prepare_url("http://chart.googleapis.com/chart", args)
-
-    return web.try_isgd(link)
diff --git a/modules/quote.py b/modules/quote.py
deleted file mode 100644
index 6beefc5..0000000
--- a/modules/quote.py
+++ /dev/null
@@ -1,149 +0,0 @@
-import random
-import re
-import time
-
-from util import hook
-
-
-def format_quote(q, num, n_quotes):
-    """Returns a formatted string of a quote"""
-    ctime, nick, msg = q
-    return "[{}/{}] <{}> {}".format(num, n_quotes,
-                                    nick, msg)
-
-
-def create_table_if_not_exists(db):
-    """Creates an empty quote table if one does not already exist"""
-    db.execute("create table if not exists quote"
-               "(chan, nick, add_nick, msg, time real, deleted default 0, "
-               "primary key (chan, nick, msg))")
-    db.commit()
-
-
-def add_quote(db, chan, nick, add_nick, msg):
-    """Adds a quote to a nick, returns message string"""
-    try:
-        db.execute('''INSERT OR FAIL INTO quote
-                      (chan, nick, add_nick, msg, time)
-                      VALUES(?,?,?,?,?)''',
-                   (chan, nick, add_nick, msg, time.time()))
-        db.commit()
-    except db.IntegrityError:
-        return "Message already stored, doing nothing."
-    return "Quote added."
-
-
-def del_quote(db, chan, nick, add_nick, msg):
-    """Deletes a quote from a nick"""
-    db.execute('''UPDATE quote SET deleted = 1 WHERE
-                  chan=? AND lower(nick)=lower(?) AND msg=msg''')
-    db.commit()
-
-
-def get_quote_num(num, count, name):
-    """Returns the quote number to fetch from the DB"""
-    if num:  # Make sure num is a number if it isn't false
-        num = int(num)
-    if count == 0:  # Error on no quotes
-        raise Exception("No quotes found for {}.".format(name))
-    if num and num < 0:  # Count back if possible
-        num = count + num + 1 if num + count > -1 else count + 1
-    if num and num > count:  # If there are not enough quotes, raise an error
-        raise Exception("I only have {} quote{} for {}.".format(count, ('s', '')[count == 1], name))
-    if num and num == 0:  # If the number is zero, set it to one
-        num = 1
-    if not num:  # If a number is not given, select a random one
-        num = random.randint(1, count)
-    return num
-
-
-def get_quote_by_nick(db, nick, num=False):
-    """Returns a formatted quote from a nick, random or selected by number"""
-    count = db.execute('''SELECT COUNT(*) FROM quote WHERE deleted != 1
-                          AND lower(nick) = lower(?)''', [nick]).fetchall()[0][0]
-
-    try:
-        num = get_quote_num(num, count, nick)
-    except Exception as error_message:
-        return error_message
-
-    quote = db.execute('''SELECT time, nick, msg
-                          FROM quote
-                          WHERE deleted != 1
-                          AND lower(nick) = lower(?)
-                          ORDER BY time
-                          LIMIT ?, 1''', (nick, (num - 1))).fetchall()[0]
-    return format_quote(quote, num, count)
-
-
-def get_quote_by_nick_chan(db, chan, nick, num=False):
-    """Returns a formatted quote from a nick in a channel, random or selected by number"""
-    count = db.execute('''SELECT COUNT(*)
-                          FROM quote
-                          WHERE deleted != 1
-                          AND chan = ?
-                          AND lower(nick) = lower(?)''', (chan, nick)).fetchall()[0][0]
-
-    try:
-        num = get_quote_num(num, count, nick)
-    except Exception as error_message:
-        return error_message
-
-    quote = db.execute('''SELECT time, nick, msg
-                          FROM quote
-                          WHERE deleted != 1
-                          AND chan = ?
-                          AND lower(nick) = lower(?)
-                          ORDER BY time
-                          LIMIT ?, 1''', (chan, nick, (num - 1))).fetchall()[0]
-    return format_quote(quote, num, count)
-
-
-def get_quote_by_chan(db, chan, num=False):
-    """Returns a formatted quote from a channel, random or selected by number"""
-    count = db.execute('''SELECT COUNT(*)
-                          FROM quote
-                          WHERE deleted != 1
-                          AND chan = ?''', (chan,)).fetchall()[0][0]
-
-    try:
-        num = get_quote_num(num, count, chan)
-    except Exception as error_message:
-        return error_message
-
-    quote = db.execute('''SELECT time, nick, msg
-                          FROM quote
-                          WHERE deleted != 1
-                          AND chan = ?
-                          ORDER BY time
-                          LIMIT ?, 1''', (chan, (num - 1))).fetchall()[0]
-    return format_quote(quote, num, count)
-
-
-@hook.command('q')
-@hook.command
-def quote(inp, nick='', chan='', db=None, notice=None):
-    """quote [#chan] [nick] [#n]/.quote add <nick> <msg>
-    Gets random or [#n]th quote by <nick> or from <#chan>/adds quote."""
-    create_table_if_not_exists(db)
-
-    add = re.match(r"add[^\w@]+(\S+?)>?\s+(.*)", inp, re.I)
-    retrieve = re.match(r"(\S+)(?:\s+#?(-?\d+))?$", inp)
-    retrieve_chan = re.match(r"(#\S+)\s+(\S+)(?:\s+#?(-?\d+))?$", inp)
-
-    if add:
-        quoted_nick, msg = add.groups()
-        notice(add_quote(db, chan, quoted_nick, nick, msg))
-        return
-    elif retrieve:
-        select, num = retrieve.groups()
-        by_chan = True if select.startswith('#') else False
-        if by_chan:
-            return get_quote_by_chan(db, select, num)
-        else:
-            return get_quote_by_nick(db, select, num)
-    elif retrieve_chan:
-        chan, nick, num = retrieve_chan.groups()
-        return get_quote_by_nick_chan(db, chan, nick, num)
-
-    notice(quote.__doc__)
diff --git a/modules/rdio.py b/modules/rdio.py
deleted file mode 100644
index d56bbf0..0000000
--- a/modules/rdio.py
+++ /dev/null
@@ -1,131 +0,0 @@
-import urllib
-import json
-import re
-
-oauth = None  # import oauth2 as oauth
-
-from util import hook
-
-
-def getdata(inp, types, api_key, api_secret):
-    consumer = oauth.Consumer(api_key, api_secret)
-    client = oauth.Client(consumer)
-    response = client.request('http://api.rdio.com/1/', 'POST',
-                              urllib.parse.urlencode({'method': 'search', 'query': inp, 'types': types, 'count': '1'}))
-    data = json.loads(response[1])
-    return data
-
-
-@hook.command
-def rdio(inp, bot=None):
-    """ rdio <search term> - alternatives: .rdiot (track), .rdioar (artist), .rdioal (album) """
-    api_key = bot.config.get("api_keys", {}).get("rdio_key")
-    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
-    if not api_key:
-        return "error: no api key set"
-    data = getdata(inp, "Track,Album,Artist", api_key, api_secret)
-    try:
-        info = data['result']['results'][0]
-    except IndexError:
-        return "No results."
-    if 'name' in info:
-        if 'artist' in info and 'album' in info:  # Track
-            name = info['name']
-            artist = info['artist']
-            album = info['album']
-            url = info['shortUrl']
-            return "\x02{}\x02 by \x02{}\x02 - {} {}".format(name, artist, album, url)
-        elif 'artist' in info and not 'album' in info:  # Album
-            name = info['name']
-            artist = info['artist']
-            url = info['shortUrl']
-            return "\x02{}\x02 by \x02{}\x02 - {}".format(name, artist, url)
-        else:  # Artist
-            name = info['name']
-            url = info['shortUrl']
-            return "\x02{}\x02 - {}".format(name, url)
-
-
-@hook.command
-def rdiot(inp, bot=None):
-    """ rdiot <search term> - Search for tracks on rdio """
-    api_key = bot.config.get("api_keys", {}).get("rdio_key")
-    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
-    if not api_key:
-        return "error: no api key set"
-    data = getdata(inp, "Track", api_key, api_secret)
-    try:
-        info = data['result']['results'][0]
-    except IndexError:
-        return "No results."
-    name = info['name']
-    artist = info['artist']
-    album = info['album']
-    url = info['shortUrl']
-    return "\x02{}\x02 by \x02{}\x02 - {} - {}".format(name, artist, album, url)
-
-
-@hook.command
-def rdioar(inp, bot=None):
-    """ rdioar <search term> - Search for artists on rdio """
-    api_key = bot.config.get("api_keys", {}).get("rdio_key")
-    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
-    if not api_key:
-        return "error: no api key set"
-    data = getdata(inp, "Artist", api_key, api_secret)
-    try:
-        info = data['result']['results'][0]
-    except IndexError:
-        return "No results."
-    name = info['name']
-    url = info['shortUrl']
-    return "\x02{}\x02 - {}".format(name, url)
-
-
-@hook.command
-def rdioal(inp, bot=None):
-    """ rdioal <search term> - Search for albums on rdio """
-    api_key = bot.config.get("api_keys", {}).get("rdio_key")
-    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
-    if not api_key:
-        return "error: no api key set"
-    data = getdata(inp, "Album", api_key, api_secret)
-    try:
-        info = data['result']['results'][0]
-    except IndexError:
-        return "No results."
-    name = info['name']
-    artist = info['artist']
-    url = info['shortUrl']
-    return "\x02{}\x02 by \x02{}\x02 - {}".format(name, artist, url)
-
-
-rdio_re = (r'(.*:)//(rd.io|www.rdio.com|rdio.com)(:[0-9]+)?(.*)', re.I)
-
-
-@hook.regex(*rdio_re)
-def rdio_url(match, bot=None):
-    api_key = bot.config.get("api_keys", {}).get("rdio_key")
-    api_secret = bot.config.get("api_keys", {}).get("rdio_secret")
-    if not api_key:
-        return None
-    url = match.group(1) + "//" + match.group(2) + match.group(4)
-    consumer = oauth.Consumer(api_key, api_secret)
-    client = oauth.Client(consumer)
-    response = client.request('http://api.rdio.com/1/', 'POST',
-                              urllib.parse.urlencode({'method': 'getObjectFromUrl', 'url': url}))
-    data = json.loads(response[1])
-    info = data['result']
-    if 'name' in info:
-        if 'artist' in info and 'album' in info:  # Track
-            name = info['name']
-            artist = info['artist']
-            album = info['album']
-            return "Rdio track: \x02{}\x02 by \x02{}\x02 - {}".format(name, artist, album)
-        elif 'artist' in info and not 'album' in info:  # Album
-            name = info['name']
-            artist = info['artist']
-            return "Rdio album: \x02{}\x02 by \x02{}\x02".format(name, artist)
-        else:  # Artist
-            name = info['name']
-            return "Rdio artist: \x02{}\x02".format(name)
diff --git a/modules/recipe.py b/modules/recipe.py
deleted file mode 100644
index 5f7b742..0000000
--- a/modules/recipe.py
+++ /dev/null
@@ -1,111 +0,0 @@
-import random
-
-from util import hook, http, web
-
-metadata_url = "http://omnidator.appspot.com/microdata/json/?url={}"
-
-base_url = "http://www.cookstr.com"
-search_url = base_url + "/searches"
-random_url = search_url + "/surprise"
-
-# set this to true to censor this plugin!
-censor = True
-phrases = [
-    "EAT SOME FUCKING \x02{}\x02",
-    "YOU WON'T NOT MAKE SOME FUCKING \x02{}\x02",
-    "HOW ABOUT SOME FUCKING \x02{}?\x02",
-    "WHY DON'T YOU EAT SOME FUCKING \x02{}?\x02",
-    "MAKE SOME FUCKING \x02{}\x02",
-    "INDUCE FOOD COMA WITH SOME FUCKING \x02{}\x02"
-    "CLASSILY PARTAKE IN SOME FUCKING \x02{}\x02",
-    "COOK UP SOME FUCKING \x02{}\x02",
-    "CURE YOUR MOUTH'S POST TRAUMATIC STRESS DISORDER WITH SOME FUCKING \x02{}\x02",
-    "PROCURE SOME CHILD LABOR TO COOK UP SOME FUCKING \x02{}\x02",
-    "YOUR INDECISION IS FAR LESS APPETIZING THAN SOME FUCKING \x02{}\x02"
-]
-
-clean_key = lambda i: i.split("#")[1]
-
-
-class ParseError(Exception):
-    pass
-
-
-def get_data(url):
-    """ Uses the omnidator API to parse the metadata from the provided URL """
-    try:
-        omni = http.get_json(metadata_url.format(url))
-    except (http.HTTPError, http.URLError) as e:
-        raise ParseError(e)
-    schemas = omni["@"]
-    for d in schemas:
-        if d["a"] == "<http://schema.org/Recipe>":
-            data = {clean_key(key): value for (key, value) in d.items()
-                    if key.startswith("http://schema.org/Recipe")}
-            return data
-    raise ParseError("No recipe data found")
-
-
-@hook.command(autohelp=False)
-def recipe(text):
-    """recipe [term] - Gets a recipe for [term], or ets a random recipe if [term] is not provided"""
-    if text:
-        # get the recipe URL by searching
-        try:
-            search = http.get_soup(search_url, query=text.strip())
-        except (http.HTTPError, http.URLError) as e:
-            return "Could not get recipe: {}".format(e)
-
-        # find the list of results
-        result_list = search.find('div', {'class': 'found_results'})
-
-        if result_list:
-            results = result_list.find_all('div', {'class': 'recipe_result'})
-        else:
-            return "No results"
-
-        # pick a random front page result
-        result = random.choice(results)
-
-        # extract the URL from the result
-        url = base_url + result.find('div', {'class': 'image-wrapper'}).find('a')['href']
-
-    else:
-        # get a random recipe URL
-        try:
-            page = http.open(random_url)
-        except (http.HTTPError, http.URLError) as e:
-            return "Could not get recipe: {}".format(e)
-        url = page.geturl()
-
-    # use get_data() to get the recipe info from the URL
-    try:
-        data = get_data(url)
-    except ParseError as e:
-        return "Could not parse recipe: {}".format(e)
-
-    name = data["name"].strip()
-    return "Try eating \x02{}!\x02 - {}".format(name, web.try_isgd(url))
-
-
-@hook.command(autohelp=False)
-def dinner():
-    """dinner - WTF IS FOR DINNER"""
-    try:
-        page = http.open(random_url)
-    except (http.HTTPError, http.URLError) as e:
-        return "Could not get recipe: {}".format(e)
-    url = page.geturl()
-
-    try:
-        data = get_data(url)
-    except ParseError as e:
-        return "Could not parse recipe: {}".format(e)
-
-    name = data["name"].strip().upper()
-    text = random.choice(phrases).format(name)
-
-    if censor:
-        text = text.replace("FUCK", "F**K")
-
-    return "{} - {}".format(text, web.try_isgd(url))
diff --git a/modules/reddit.py b/modules/reddit.py
deleted file mode 100644
index e5dc49c..0000000
--- a/modules/reddit.py
+++ /dev/null
@@ -1,79 +0,0 @@
-from datetime import datetime
-import re
-import random
-
-from util import hook, http, formatting, timesince
-
-
-reddit_re = (r'.*(((www\.)?reddit\.com/r|redd\.it)[^ ]+)', re.I)
-
-base_url = "http://reddit.com/r/{}/.json"
-short_url = "http://redd.it/{}"
-
-
-@hook.regex(*reddit_re)
-def reddit_url(match):
-    thread = http.get_html(match.group(0))
-
-    title = thread.xpath('//title/text()')[0]
-    upvotes = thread.xpath("//span[@class='upvotes']/span[@class='number']/text()")[0]
-    downvotes = thread.xpath("//span[@class='downvotes']/span[@class='number']/text()")[0]
-    author = thread.xpath("//div[@id='siteTable']//a[contains(@class,'author')]/text()")[0]
-    timeago = thread.xpath("//div[@id='siteTable']//p[@class='tagline']/time/text()")[0]
-    comments = thread.xpath("//div[@id='siteTable']//a[@class='comments']/text()")[0]
-
-    return '\x02{}\x02 - posted by \x02{}\x02 {} ago - {} upvotes, {} downvotes - {}'.format(
-        title, author, timeago, upvotes, downvotes, comments)
-
-
-@hook.command(autohelp=False)
-def reddit(inp):
-    """reddit <subreddit> [n] -- Gets a random post from <subreddit>, or gets the [n]th post in the subreddit."""
-    id_num = None
-
-    if inp:
-        # clean and split the input
-        parts = inp.lower().strip().split()
-
-        # find the requested post number (if any)
-        if len(parts) > 1:
-            url = base_url.format(parts[0].strip())
-            try:
-                id_num = int(parts[1]) - 1
-            except ValueError:
-                return "Invalid post number."
-        else:
-            url = base_url.format(parts[0].strip())
-    else:
-        url = "http://reddit.com/.json"
-
-    try:
-        data = http.get_json(url, user_agent=http.ua_chrome)
-    except Exception as e:
-        return "Error: " + str(e)
-    data = data["data"]["children"]
-
-    # get the requested/random post
-    if id_num is not None:
-        try:
-            item = data[id_num]["data"]
-        except IndexError:
-            length = len(data)
-            return "Invalid post number. Number must be between 1 and {}.".format(length)
-    else:
-        item = random.choice(data)["data"]
-
-    item["title"] = formatting.truncate_str(item["title"], 50)
-    item["link"] = short_url.format(item["id"])
-
-    raw_time = datetime.fromtimestamp(int(item["created_utc"]))
-    item["timesince"] = timesince.timesince(raw_time)
-
-    if item["over_18"]:
-        item["warning"] = " \x02NSFW\x02"
-    else:
-        item["warning"] = ""
-
-    return "\x02{title} : {subreddit}\x02 - posted by \x02{author}\x02" \
-           " {timesince} ago - {ups} upvotes, {downs} downvotes -" \
-           " {link}{warning}".format(**item)
diff --git a/modules/regex_chans.py b/modules/regex_chans.py
deleted file mode 100644
index 0ef8f82..0000000
--- a/modules/regex_chans.py
+++ /dev/null
@@ -1,142 +0,0 @@
-from sqlalchemy import Table, Column, UniqueConstraint, String
-
-from util import hook, botvars
-
-table = Table(
-    "regex_chans",
-    botvars.metadata,
-    Column("connection", String),
-    Column("channel", String),
-    Column("status", String),
-    UniqueConstraint("connection", "channel")
-)
-
-# Default value.
-# If True, all channels without a setting will have regex enabled
-# If False, all channels without a setting will have regex disabled
-default_enabled = False
-
-
-@hook.onload()
-def load_cache(db):
-    """
-    :type db: sqlalchemy.orm.Session
-    """
-    global status_cache
-    status_cache = {}
-    for row in db.execute(table.select()):
-        conn = row["connection"]
-        chan = row["channel"]
-        status = row["status"]
-        status_cache[(conn, chan)] = status
-
-
-def set_status(db, conn, chan, status):
-    """
-    :type db: sqlalchemy.orm.Session
-    :type conn: str
-    :type chan: str
-    :type status: str
-    """
-    if (conn, chan) in status_cache:
-        # if we have a set value, update
-        db.execute(
-            table.update().values(status=status).where(table.c.connection == conn).where(table.c.channel == chan))
-    else:
-        # otherwise, insert
-        db.execute(table.insert().values(connection=conn, channel=chan, status=status))
-    db.commit()
-
-
-def delete_status(db, conn, chan):
-    db.execute(table.delete().where(table.c.connection == conn).where(table.c.channel == chan))
-    db.commit()
-
-
-@hook.sieve()
-def sieve_regex(bot, input, plugin):
-    if plugin.type == "regex" and input.chan.startswith("#") and plugin.module.title != "factoids":
-        status = status_cache.get((input.conn.name, input.chan))
-        if status != "ENABLED" and (status == "DISABLED" or not default_enabled):
-            bot.logger.info("[{}] Denying {} from {}"
-                            .format(input.conn.readable_name, plugin.function_name, input.chan))
-            return None
-        bot.logger.info("[{}] Allowing {} to {}".format(input.conn.readable_name, plugin.function_name, input.chan))
-
-    return input
-
-
-@hook.command(autohelp=False, permissions=["botcontrol"])
-def enableregex(text, db, conn, chan, nick, message, notice):
-    text = text.strip().lower()
-    if not text:
-        channel = chan
-    elif text.startswith("#"):
-        channel = text
-    else:
-        channel = "#{}".format(text)
-
-    message("Enabling regex matching (youtube, etc) (issued by {})".format(nick), target=channel)
-    notice("Enabling regex matching (youtube, etc) in channel {}".format(channel))
-    set_status(db, conn.name, channel, "ENABLED")
-    load_cache(db)
-
-
-@hook.command(autohelp=False, permissions=["botcontrol"])
-def disableregex(text, db, conn, chan, nick, message, notice):
-    text = text.strip().lower()
-    if not text:
-        channel = chan
-    elif text.startswith("#"):
-        channel = text
-    else:
-        channel = "#{}".format(text)
-
-    message("Disabling regex matching (youtube, etc) (issued by {})".format(nick), target=channel)
-    notice("Disabling regex matching (youtube, etc) in channel {}".format(channel))
-    set_status(db, conn.name, channel, "DISABLED")
-    load_cache(db)
-
-
-@hook.command(autohelp=False, permissions=["botcontrol"])
-def resetregex(text, db, conn, chan, nick, message, notice):
-    text = text.strip().lower()
-    if not text:
-        channel = chan
-    elif text.startswith("#"):
-        channel = text
-    else:
-        channel = "#{}".format(text)
-
-    message("Resetting regex matching setting (youtube, etc) (issued by {})".format(nick), target=channel)
-    notice("Resetting regex matching setting (youtube, etc) in channel {}".format(channel))
-    delete_status(db, conn.name, channel)
-    load_cache(db)
-
-
-@hook.command(autohelp=False, permissions=["botcontrol"])
-def regexstatus(text, conn, chan):
-    text = text.strip().lower()
-    if not text:
-        channel = chan
-    elif text.startswith("#"):
-        channel = text
-    else:
-        channel = "#{}".format(text)
-    status = status_cache.get((conn.name, chan))
-    if status is None:
-        if default_enabled:
-            status = "ENABLED"
-        else:
-            status = "DISABLED"
-    return "Regex status for {}: {}".format(channel, status)
-
-
-@hook.command(autohelp=False, permissions=["botcontrol"])
-def listregex(conn):
-    values = []
-    for (conn_name, chan), status in status_cache.values():
-        if conn_name != conn.name:
-            continue
-        values.append("{}: {}".format(chan, status))
-    return ", ".join(values)
diff --git a/modules/rottentomatoes.py b/modules/rottentomatoes.py
deleted file mode 100644
index 34e6f6e..0000000
--- a/modules/rottentomatoes.py
+++ /dev/null
@@ -1,39 +0,0 @@
-from util import http, hook
-
-api_root = 'http://api.rottentomatoes.com/api/public/v1.0/'
-movie_search_url = api_root + 'movies.json'
-movie_reviews_url = api_root + 'movies/%s/reviews.json'
-
-
-@hook.command('rt')
-def rottentomatoes(inp, bot=None):
-    """rt <title> -- gets ratings for <title> from Rotten Tomatoes"""
-
-    api_key = bot.config.get("api_keys", {}).get("rottentomatoes", None)
-    if not api_key:
-        return "error: no api key set"
-
-    title = inp.strip()
-
-    results = http.get_json(movie_search_url, q=title, apikey=api_key)
-    if results['total'] == 0:
-        return 'No results.'
-
-    movie = results['movies'][0]
-    title = movie['title']
-    movie_id = movie['id']
-    critics_score = movie['ratings']['critics_score']
-    audience_score = movie['ratings']['audience_score']
-    url = movie['links']['alternate']
-
-    if critics_score == -1:
-        return
-
-    reviews = http.get_json(movie_reviews_url % movie_id, apikey=api_key, review_type='all')
-    review_count = reviews['total']
-
-    fresh = critics_score * review_count / 100
-    rotten = review_count - fresh
-
-    return "{} - Critics Rating: \x02{}%\x02 ({} liked, {} disliked) " \
-           "Audience Rating: \x02{}%\x02 - {}".format(title, critics_score, fresh, rotten, audience_score, url)
diff --git a/modules/rss.py b/modules/rss.py
deleted file mode 100644
index a87e460..0000000
--- a/modules/rss.py
+++ /dev/null
@@ -1,40 +0,0 @@
-from util import hook, http, web, formatting
-
-
-@hook.command("feed")
-@hook.command
-def rss(text, message):
-    """rss <feed> -- Gets the first three items from the RSS feed <feed>."""
-    limit = 3
-
-    # preset news feeds
-    strip = text.lower().strip()
-    if strip == "bukkit":
-        feed = "http://dl.bukkit.org/downloads/craftbukkit/feeds/latest-rb.rss"
-        limit = 1
-    elif strip == "xkcd":
-        feed = "http://xkcd.com/rss.xml"
-    elif strip == "ars":
-        feed = "http://feeds.arstechnica.com/arstechnica/index"
-    else:
-        feed = text
-
-    query = "SELECT title, link FROM rss WHERE url=@feed LIMIT @limit"
-    result = web.query(query, {"feed": feed, "limit": limit})
-
-    if not result.rows:
-        return "Could not find/read RSS feed."
-
-    for row in result.rows:
-        title = formatting.truncate_str(row["title"], 100)
-        try:
-            link = web.isgd(row["link"])
-        except (web.ShortenError, http.HTTPError, http.URLError):
-            link = row["link"]
-        message("{} - {}".format(title, link))
-
-
-@hook.command(autohelp=False)
-def rb(message):
-    """rb -- Shows the latest Craftbukkit recommended build"""
-    rss("bukkit", message)
diff --git a/modules/scene.py b/modules/scene.py
deleted file mode 100644
index b4d94e4..0000000
--- a/modules/scene.py
+++ /dev/null
@@ -1,39 +0,0 @@
-import datetime
-
-from util import hook, http, timesince
-
-
-@hook.command("scene")
-@hook.command
-def pre(inp):
-    """pre <query> -- searches scene releases using orlydb.com"""
-
-    try:
-        h = http.get_html("http://orlydb.com/", q=inp)
-    except http.HTTPError as e:
-        return 'Unable to fetch results: {}'.format(e)
-
-    results = h.xpath("//div[@id='releases']/div/span[@class='release']/..")
-
-    if not results:
-        return "No results found."
-
-    result = results[0]
-
-    date = result.xpath("span[@class='timestamp']/text()")[0]
-    section = result.xpath("span[@class='section']//text()")[0]
-    name = result.xpath("span[@class='release']/text()")[0]
-
-    # parse date/time
-    date = datetime.datetime.strptime(date, "%Y-%m-%d %H:%M:%S")
-    date_string = date.strftime("%d %b %Y")
-    since = timesince.timesince(date)
-
-    size = result.xpath("span[@class='inforight']//text()")
-    if size:
-        size = ' - ' + size[0].split()[0]
-    else:
-        size = ''
-
-    return '{} - {}{} - {} ({} ago)'.format(section, name, size, date_string, since)
-
diff --git a/modules/shorten.py b/modules/shorten.py
deleted file mode 100644
index 39d993b..0000000
--- a/modules/shorten.py
+++ /dev/null
@@ -1,11 +0,0 @@
-from util import hook, http, web
-
-
-@hook.command
-def shorten(inp):
-    """shorten <url> - Makes an is.gd shortlink to the url provided."""
-
-    try:
-        return web.isgd(inp)
-    except (web.ShortenError, http.HTTPError) as error:
-        return error
diff --git a/modules/slap.py b/modules/slap.py
deleted file mode 100644
index 4147781..0000000
--- a/modules/slap.py
+++ /dev/null
@@ -1,33 +0,0 @@
-import json
-
-from util import hook, textgen
-
-
-def get_generator(_json, variables):
-    data = json.loads(_json)
-    return textgen.TextGenerator(data["templates"],
-                                 data["parts"], variables=variables)
-
-
-@hook.command
-def slap(inp, action=None, nick=None, conn=None, notice=None):
-    """slap <user> -- Makes the bot slap <user>."""
-    target = inp.strip()
-
-    if " " in target:
-        notice("Invalid username!")
-        return
-
-    # if the user is trying to make the bot slap itself, slap them
-    if target.lower() == conn.nick.lower() or target.lower() == "itself":
-        target = nick
-
-    variables = {
-        "user": target
-    }
-
-    with open("./data/slaps.json") as f:
-        generator = get_generator(f.read(), variables)
-
-    # act out the message
-    action(generator.generate_string())
diff --git a/modules/slogan.py b/modules/slogan.py
deleted file mode 100644
index 8bbd87e..0000000
--- a/modules/slogan.py
+++ /dev/null
@@ -1,17 +0,0 @@
-import random
-
-from util import hook, formatting
-
-with open("./data/slogans.txt") as f:
-    slogans = [line.strip() for line in f.readlines()
-               if not line.startswith("//")]
-
-
-@hook.command
-def slogan(text):
-    """slogan <word> -- Makes a slogan for <word>."""
-    out = random.choice(slogans)
-    if text.lower() and out.startswith("<text>"):
-        text = formatting.capitalize_first(text)
-
-    return out.replace('<text>', text)
diff --git a/modules/snopes.py b/modules/snopes.py
deleted file mode 100644
index c97628e..0000000
--- a/modules/snopes.py
+++ /dev/null
@@ -1,34 +0,0 @@
-import re
-
-from util import hook, http
-
-
-search_url = "http://search.atomz.com/search/?sp_a=00062d45-sp00000000"
-
-
-@hook.command
-def snopes(inp):
-    """snopes <topic> -- Searches snopes for an urban legend about <topic>."""
-
-    search_page = http.get_html(search_url, sp_q=inp, sp_c="1")
-    result_urls = search_page.xpath("//a[@target='_self']/@href")
-
-    if not result_urls:
-        return "no matching pages found"
-
-    snopes_page = http.get_html(result_urls[0])
-    snopes_text = snopes_page.text_content()
-
-    claim = re.search(r"Claim: .*", snopes_text).group(0).strip()
-    status = re.search(r"Status: .*", snopes_text)
-
-    if status is not None:
-        status = status.group(0).strip()
-    else:  # new-style statuses
-        status = "Status: {}.".format(re.search(r"FALSE|TRUE|MIXTURE|UNDETERMINED",
-                                                snopes_text).group(0).title())
-
-    claim = re.sub(r"[\s\xa0]+", " ", claim)  # compress whitespace
-    status = re.sub(r"[\s\xa0]+", " ", status)
-
-    return "{} {} {}".format(claim, status, result_urls[0])
diff --git a/modules/soundcloud.py b/modules/soundcloud.py
deleted file mode 100644
index d6f73e8..0000000
--- a/modules/soundcloud.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import re
-from urllib.parse import urlencode
-
-from util import hook, http, web, formatting
-
-sc_re = (r'(.*:)//(www.)?(soundcloud.com)(.*)', re.I)
-api_url = "http://api.soundcloud.com"
-sndsc_re = (r'(.*:)//(www.)?(snd.sc)(.*)', re.I)
-
-
-def soundcloud(url, api_key):
-    data = http.get_json(api_url + '/resolve.json?' + urlencode({'url': url, 'client_id': api_key}))
-
-    if data['description']:
-        desc = ": {} ".format(formatting.truncate_str(data['description'], 50))
-    else:
-        desc = ""
-    if data['genre']:
-        genre = "- Genre: \x02{}\x02 ".format(data['genre'])
-    else:
-        genre = ""
-
-    url = web.try_isgd(data['permalink_url'])
-
-    return "SoundCloud track: \x02{}\x02 by \x02{}\x02 {}{}- {} plays, {} downloads, {} comments - {}".format(
-        data['title'], data['user']['username'], desc, genre, data['playback_count'], data['download_count'],
-        data['comment_count'], url)
-
-
-@hook.regex(*sc_re)
-def soundcloud_url(match, bot=None):
-    api_key = bot.config.get("api_keys", {}).get("soundcloud")
-    if not api_key:
-        print("Error: no api key set")
-        return None
-    url = match.group(1).split(' ')[-1] + "//" + (match.group(2) if match.group(2) else "") + match.group(3) + \
-          match.group(4).split(' ')[0]
-    return soundcloud(url, api_key)
-
-
-@hook.regex(*sndsc_re)
-def sndsc_url(match, bot=None):
-    api_key = bot.config.get("api_keys", {}).get("soundcloud")
-    if not api_key:
-        print("Error: no api key set")
-        return None
-    url = match.group(1).split(' ')[-1] + "//" + (match.group(2) if match.group(2) else "") + match.group(3) + \
-          match.group(4).split(' ')[0]
-    return soundcloud(http.open(url).url, api_key)
diff --git a/modules/spellcheck.py b/modules/spellcheck.py
deleted file mode 100644
index 1630a0d..0000000
--- a/modules/spellcheck.py
+++ /dev/null
@@ -1,47 +0,0 @@
-from enchant.checker import SpellChecker
-import enchant
-
-from util import hook
-
-
-locale = "en_US"
-
-
-@hook.command
-def spell(inp):
-    """spell <word/sentence> -- Check spelling of a word or sentence."""
-
-    if not enchant.dict_exists(locale):
-        return "Could not find dictionary: {}".format(locale)
-
-    if len(inp.split(" ")) > 1:
-        # input is a sentence
-        checker = SpellChecker(locale)
-        checker.set_text(inp)
-
-        offset = 0
-        for err in checker:
-            # find the location of the incorrect word
-            start = err.wordpos + offset
-            finish = start + len(err.word)
-            # get some suggestions for it
-            suggestions = err.suggest()
-            s_string = '/'.join(suggestions[:3])
-            s_string = "\x02{}\x02".format(s_string)
-            # calculate the offset for the next word
-            offset = (offset + len(s_string)) - len(err.word)
-            # replace the word with the suggestions
-            inp = inp[:start] + s_string + inp[finish:]
-        return inp
-    else:
-        # input is a word
-        dictionary = enchant.Dict(locale)
-        is_correct = dictionary.check(inp)
-        suggestions = dictionary.suggest(inp)
-        s_string = ', '.join(suggestions[:10])
-        if is_correct:
-            return '"{}" appears to be \x02valid\x02! ' \
-                   '(suggestions: {})'.format(inp, s_string)
-        else:
-            return '"{}" appears to be \x02invalid\x02! ' \
-                   '(suggestions: {})'.format(inp, s_string)
diff --git a/modules/spotify.py b/modules/spotify.py
deleted file mode 100644
index e562a01..0000000
--- a/modules/spotify.py
+++ /dev/null
@@ -1,110 +0,0 @@
-import re
-from urllib.parse import urlencode
-
-from util import hook, http, web
-
-gateway = 'http://open.spotify.com/{}/{}'  # http spotify gw address
-spuri = 'spotify:{}:{}'
-
-spotify_re = (r'(spotify:(track|album|artist|user):([a-zA-Z0-9]+))', re.I)
-http_re = (r'(open\.spotify\.com\/(track|album|artist|user)\/'
-           '([a-zA-Z0-9]+))', re.I)
-
-
-def sptfy(inp, sptfy=False):
-    if sptfy:
-        shortenurl = "http://sptfy.com/index.php"
-        data = urlencode({'longUrl': inp, 'shortUrlDomain': 1, 'submitted': 1, "shortUrlFolder": 6, "customUrl": "",
-                          "shortUrlPassword": "", "shortUrlExpiryDate": "", "shortUrlUses": 0, "shortUrlType": 0})
-        try:
-            soup = http.get_soup(shortenurl, post_data=data, cookies=True)
-        except:
-            return inp
-        try:
-            link = soup.find('div', {'class': 'resultLink'}).text.strip()
-            return link
-        except:
-            message = "Unable to shorten URL: {}".format(soup.find('div', {
-                'class': 'messagebox_text'}).find('p').text.split("<br/>")[0])
-            return message
-    else:
-        return web.try_isgd(inp)
-
-
-@hook.command('sptrack')
-@hook.command
-def spotify(inp):
-    """spotify <song> -- Search Spotify for <song>"""
-    try:
-        data = http.get_json("http://ws.spotify.com/search/1/track.json", q=inp.strip())
-    except Exception as e:
-        return "Could not get track information: {}".format(e)
-
-    try:
-        type, id = data["tracks"][0]["href"].split(":")[1:]
-    except IndexError:
-        return "Could not find track."
-    url = sptfy(gateway.format(type, id))
-
-    return "\x02{}\x02 by \x02{}\x02 - {}".format(data["tracks"][0]["name"],
-                                                  data["tracks"][0]["artists"][0]["name"], url)
-
-
-@hook.command
-def spalbum(inp):
-    """spalbum <album> -- Search Spotify for <album>"""
-    try:
-        data = http.get_json("http://ws.spotify.com/search/1/album.json", q=inp.strip())
-    except Exception as e:
-        return "Could not get album information: {}".format(e)
-
-    try:
-        type, id = data["albums"][0]["href"].split(":")[1:]
-    except IndexError:
-        return "Could not find album."
-    url = sptfy(gateway.format(type, id))
-
-    return "\x02{}\x02 by \x02{}\x02 - {}".format(data["albums"][0]["name"],
-                                                  data["albums"][0]["artists"][0]["name"], url)
-
-
-@hook.command
-def spartist(inp):
-    """spartist <artist> -- Search Spotify for <artist>"""
-    try:
-        data = http.get_json("http://ws.spotify.com/search/1/artist.json", q=inp.strip())
-    except Exception as e:
-        return "Could not get artist information: {}".format(e)
-
-    try:
-        type, id = data["artists"][0]["href"].split(":")[1:]
-    except IndexError:
-        return "Could not find artist."
-    url = sptfy(gateway.format(type, id))
-
-    return "\x02{}\x02 - {}".format(data["artists"][0]["name"], url)
-
-
-@hook.regex(*http_re)
-@hook.regex(*spotify_re)
-def spotify_url(match):
-    type = match.group(2)
-    spotify_id = match.group(3)
-    url = spuri.format(type, spotify_id)
-    # no error catching here, if the API is down fail silently
-    data = http.get_json("http://ws.spotify.com/lookup/1/.json", uri=url)
-    if type == "track":
-        name = data["track"]["name"]
-        artist = data["track"]["artists"][0]["name"]
-        album = data["track"]["album"]["name"]
-
-        return "Spotify Track: \x02{}\x02 by \x02{}\x02 from the album \x02{}\x02 - {}".format(name, artist,
-                                                                                               album, sptfy(
-                gateway.format(type, spotify_id)))
-    elif type == "artist":
-        return "Spotify Artist: \x02{}\x02 - {}".format(data["artist"]["name"],
-                                                        sptfy(gateway.format(type, spotify_id)))
-    elif type == "album":
-        return "Spotify Album: \x02{}\x02 - \x02{}\x02 - {}".format(data["album"]["artist"],
-                                                                    data["album"]["name"],
-                                                                    sptfy(gateway.format(type, spotify_id)))
diff --git a/modules/steal.py b/modules/steal.py
deleted file mode 100644
index 21d61bc..0000000
--- a/modules/steal.py
+++ /dev/null
@@ -1,77 +0,0 @@
-from random import randint
-
-from sqlalchemy import Table, Column, String
-from sqlalchemy.exc import IntegrityError
-
-from util import hook, botvars
-
-table = Table(
-    'stolen',
-    botvars.metadata,
-    Column('word', String, primary_key=True)
-)
-
-
-def get_random(db):
-    """
-    :type db: sqlalchemy.orm.session.Session
-    """
-    count = db.execute(table.select().count()).fetchone()[0]
-    offset = randint(0, int(count - 1))
-    row = db.execute(table.select().limit(1).offset(offset)).fetchone()
-    if row:
-        return row[0]
-    else:
-        return None
-
-
-def list_steals(db):
-    """
-    :type db: sqlalchemy.orm.session.Session
-    """
-    row = db.execute(table.select()).fetchall()
-    return row
-
-
-def add_word(db, stolen):
-    """
-    :type db: sqlalchemy.orm.session.Session
-    """
-    try:
-        db.execute(table.insert().values(word=stolen))
-        db.commit()
-    except IntegrityError:
-        pass  # for lack of a better thing to do
-
-
-@hook.command(["steal", "stealit"], autohelp=False)
-def stealit(inp, db, nick, action):
-    """steal [username [object]] - Steals an object from a user, or a random previously stolen object."""
-    args = inp.strip().split()
-    if not args:
-        steal_from = nick
-        to_steal = get_random(db)
-        action("steals {}'s {}".format(steal_from, to_steal))
-    elif len(args) < 2:
-        steal_from = args[0]
-        to_steal = get_random(db)
-        action("steals {}'s {}".format(steal_from, to_steal))
-    else:
-        steal_from = args[0]
-        to_steal = " ".join(args[1:])
-        action("steals {}'s {}".format(steal_from, to_steal))
-        add_word(db, to_steal)
-
-
-@hook.command(autohelp=False, permissions=["adminonly"])
-def liststolen(db, reply):
-    text = False
-    for word in list_steals(db):
-        if not text:
-            text = word[0]
-        else:
-            text += ", {}".format(word[0])
-        if len(text) > 400:
-            reply(text.rsplit(', ', 1)[0])
-            text = word[0]
-    return text
diff --git a/modules/steam.py b/modules/steam.py
deleted file mode 100644
index 02a29f8..0000000
--- a/modules/steam.py
+++ /dev/null
@@ -1,72 +0,0 @@
-import re
-
-from bs4 import BeautifulSoup, NavigableString, Tag
-
-from util import hook, http, web
-from util.formatting import truncate_str
-
-steam_re = (r'(.*:)//(store.steampowered.com)(:[0-9]+)?(.*)', re.I)
-
-
-def get_steam_info(url):
-    page = http.get(url)
-    soup = BeautifulSoup(page, 'lxml', from_encoding="utf-8")
-
-    data = {"name": soup.find('div', {'class': 'apphub_AppName'}).text,
-            "desc": truncate_str(soup.find('meta', {'name': 'description'})['content'].strip(), 80)}
-
-    # get the element details_block
-    details = soup.find('div', {'class': 'details_block'})
-
-    # loop over every <b></b> tag in details_block
-    for b in details.findAll('b'):
-        # get the contents of the <b></b> tag, which is our title
-        title = b.text.lower().replace(":", "")
-        if title == "languages":
-            # we have all we need!
-            break
-
-        # find the next element directly after the <b></b> tag
-        next_element = b.nextSibling
-        if next_element:
-            # if the element is some text
-            if isinstance(next_element, NavigableString):
-                text = next_element.string.strip()
-                if text:
-                    # we found valid text, save it and continue the loop
-                    data[title] = text
-                    continue
-                else:
-                    # the text is blank - sometimes this means there are
-                    # useless spaces or tabs between the <b> and <a> tags.
-                    # so we find the next <a> tag and carry on to the next
-                    # bit of code below
-                    next_element = next_element.find_next('a', href=True)
-
-            # if the element is an <a></a> tag
-            if isinstance(next_element, Tag) and next_element.name == 'a':
-                text = next_element.string.strip()
-                if text:
-                    # we found valid text (in the <a></a> tag),
-                    # save it and continue the loop
-                    data[title] = text
-                    continue
-
-    data["price"] = soup.find('div', {'class': 'game_purchase_price price'}).text.strip()
-
-    return "\x02{name}\x02: {desc}, \x02Genre\x02: {genre}, \x02Release Date\x02: {release date}," \
-           " \x02Price\x02: {price}".format(**data)
-
-
-@hook.regex(*steam_re)
-def steam_url(match):
-    return get_steam_info("http://store.steampowered.com" + match.group(4))
-
-
-@hook.command
-def steam(inp):
-    """steam [search] - Search for specified game/trailer/DLC"""
-    page = http.get("http://store.steampowered.com/search/?term=" + inp)
-    soup = BeautifulSoup(page, 'lxml', from_encoding="utf-8")
-    result = soup.find('a', {'class': 'search_result_row'})
-    return get_steam_info(result['href']) + " - " + web.isgd(result['href'])
diff --git a/modules/steam_calc.py b/modules/steam_calc.py
deleted file mode 100644
index acf70f2..0000000
--- a/modules/steam_calc.py
+++ /dev/null
@@ -1,120 +0,0 @@
-import csv
-import io
-
-from util import hook, http
-
-
-gauge_url = "http://www.mysteamgauge.com/search?username={}"
-
-api_url = "http://mysteamgauge.com/user/{}.csv"
-steam_api_url = "http://steamcommunity.com/id/{}/?xml=1"
-
-
-def refresh_data(name):
-    http.get(gauge_url.format(name), timeout=25, get_method='HEAD')
-
-
-def get_data(name):
-    return http.get(api_url.format(name))
-
-
-def is_number(s):
-    try:
-        float(s)
-        return True
-    except ValueError:
-        return False
-
-
-def unicode_dictreader(utf8_data, **kwargs):
-    csv_reader = csv.DictReader(utf8_data, **kwargs)
-    for row in csv_reader:
-        yield dict([(key.lower(), str(value, 'utf-8')) for key, value in row.items()])
-
-
-@hook.command('sc')
-@hook.command
-def steamcalc(inp, reply=None):
-    """steamcalc <username> [currency] - Gets value of steam account and
-       total hours played. Uses steamcommunity.com/id/<nickname>. """
-
-    # check if the user asked us to force reload
-    force_reload = inp.endswith(" forcereload")
-    if force_reload:
-        name = inp[:-12].strip().lower()
-    else:
-        name = inp.strip()
-
-    if force_reload:
-        try:
-            reply("Collecting data, this may take a while.")
-            refresh_data(name)
-            request = get_data(name)
-            do_refresh = False
-        except (http.HTTPError, http.URLError):
-            return "Could not get data for this user."
-    else:
-        try:
-            request = get_data(name)
-            do_refresh = True
-        except (http.HTTPError, http.URLError):
-            try:
-                reply("Collecting data, this may take a while.")
-                refresh_data(name)
-                request = get_data(name)
-                do_refresh = False
-            except (http.HTTPError, http.URLError):
-                return "Could not get data for this user."
-
-    csv_data = io.StringIO(request)  # we use StringIO because CSV can't read a string
-    reader = unicode_dictreader(csv_data)
-
-    # put the games in a list
-    games = []
-    for row in reader:
-        games.append(row)
-
-    data = {}
-
-    # basic information
-    steam_profile = http.get_xml(steam_api_url.format(name))
-    try:
-        data["name"] = steam_profile.find('steamID').text
-        online_state = steam_profile.find('stateMessage').text
-    except AttributeError:
-        return "Could not get data for this user."
-
-    online_state = online_state.replace("<br/>", ": ")  # will make this pretty later
-    data["state"] = text.strip_html(online_state)
-
-    # work out the average metascore for all games
-    ms = [float(game["metascore"]) for game in games if is_number(game["metascore"])]
-    metascore = float(sum(ms)) / len(ms) if len(ms) > 0 else float('nan')
-    data["average_metascore"] = "{0:.1f}".format(metascore)
-
-    # work out the totals
-    data["games"] = len(games)
-
-    total_value = sum([float(game["value"]) for game in games if is_number(game["value"])])
-    data["value"] = str(int(round(total_value)))
-
-    # work out the total size
-    total_size = 0.0
-
-    for game in games:
-        if not is_number(game["size"]):
-            continue
-
-        if game["unit"] == "GB":
-            total_size += float(game["size"])
-        else:
-            total_size += float(game["size"]) / 1024
-
-    data["size"] = "{0:.1f}".format(total_size)
-
-    reply("{name} ({state}) has {games} games with a total value of ${value}"
-          " and a total size of {size}GB! The average metascore for these"
-          " games is {average_metascore}.".format(**data))
-
-    if do_refresh:
-        refresh_data(name)
diff --git a/modules/stock.py b/modules/stock.py
deleted file mode 100644
index f61fc5c..0000000
--- a/modules/stock.py
+++ /dev/null
@@ -1,30 +0,0 @@
-from util import hook, web
-
-
-@hook.command
-def stock(inp):
-    """stock <symbol> -- gets stock information"""
-    sym = inp.strip().lower()
-
-    query = "SELECT * FROM yahoo.finance.quote WHERE symbol=@symbol LIMIT 1"
-    quote = web.query(query, {"symbol": sym}).one()
-
-    # if we don't get a company name back, the symbol doesn't match a company
-    if quote['Change'] is None:
-        return "Unknown ticker symbol: {}".format(sym)
-
-    change = float(quote['Change'])
-    price = float(quote['LastTradePriceOnly'])
-
-    if change < 0:
-        quote['color'] = "5"
-    else:
-        quote['color'] = "3"
-
-    quote['PercentChange'] = 100 * change / (price - change)
-    print(quote)
-
-    return "\x02{Name}\x02 (\x02{symbol}\x02) - {LastTradePriceOnly} " \
-           "\x03{color}{Change} ({PercentChange:.2f}%)\x03 " \
-           "Day Range: {DaysRange} " \
-           "MCAP: {MarketCapitalization}".format(**quote)
diff --git a/modules/suggest.py b/modules/suggest.py
deleted file mode 100644
index 9a9d21e..0000000
--- a/modules/suggest.py
+++ /dev/null
@@ -1,28 +0,0 @@
-import json
-
-from bs4 import BeautifulSoup
-
-from util import hook, http, formatting
-
-
-@hook.command
-def suggest(text):
-    """suggest <phrase> -- Gets suggested phrases for a google search"""
-
-    page = http.get('http://google.com/complete/search',
-                    output='json', client='hp', q=text)
-    page_json = page.split('(', 1)[1][:-1]
-
-    suggestions = json.loads(page_json)[1]
-    suggestions = [suggestion[0] for suggestion in suggestions]
-
-    if not suggestions:
-        return 'no suggestions found'
-
-    out = ", ".join(suggestions)
-
-    # defuckify text (might not be needed now, but I'll keep it)
-    soup = BeautifulSoup(out)
-    out = soup.get_text()
-
-    return formatting.truncate_str(out, 200)
diff --git a/modules/tell.py b/modules/tell.py
deleted file mode 100644
index 306f03b..0000000
--- a/modules/tell.py
+++ /dev/null
@@ -1,142 +0,0 @@
-import re
-from datetime import datetime
-
-from sqlalchemy import Table, Column, String, Boolean, DateTime
-from sqlalchemy.sql import select
-
-from util import hook, timesince, botvars
-
-table = Table(
-    'tells',
-    botvars.metadata,
-    Column('connection', String),
-    Column('sender', String),
-    Column('target', String),
-    Column('message', String),
-    Column('is_read', Boolean),
-    Column('time_sent', DateTime),
-    Column('time_read', DateTime)
-)
-
-
-def get_unread(db, server, target):
-    query = select([table.c.sender, table.c.message, table.c.time_sent]) \
-        .where(table.c.connection == server) \
-        .where(table.c.target == target.lower()) \
-        .where(table.c.is_read == 0) \
-        .order_by(table.c.time_sent)
-    return db.execute(query).fetchall()
-
-
-def count_unread(db, server, target):
-    query = select([table]) \
-        .where(table.c.connection == server) \
-        .where(table.c.target == target.lower()) \
-        .where(table.c.is_read == 0) \
-        .count()
-    return db.execute(query).fetchone()[0]
-
-
-def read_all_tells(db, server, target):
-    query = table.update() \
-        .where(table.c.connection == server) \
-        .where(table.c.target == target.lower()) \
-        .where(table.c.is_read == 0) \
-        .values(is_read=1)
-    db.execute(query)
-    db.commit()
-
-
-def read_tell(db, server, target, message):
-    query = table.update() \
-        .where(table.c.connection == server) \
-        .where(table.c.target == target.lower()) \
-        .where(table.c.message == message) \
-        .values(is_read=1)
-    db.execute(query)
-    db.commit()
-
-
-def add_tell(db, server, sender, target, message):
-    query = table.insert().values(
-        connection=server,
-        sender=sender,
-        target=target,
-        message=message,
-        is_read=False,
-        time_sent=datetime.today()
-    )
-    db.execute(query)
-    db.commit()
-
-
-@hook.event('PRIVMSG', singlethread=True)
-def tellinput(input, notice, db, nick, conn):
-    if 'showtells' in input.msg.lower():
-        return
-
-    tells = get_unread(db, conn.server, nick)
-
-    if tells:
-        user_from, message, time_sent = tells[0]
-        reltime = timesince.timesince(time_sent)
-
-        reply = "{} sent you a message {} ago: {}".format(user_from, reltime, message)
-        if len(tells) > 1:
-            reply += " (+{} more, {}showtells to view)".format(len(tells) - 1, conn.config["command_prefix"])
-
-        read_tell(db, conn.server, nick, message)
-        notice(reply)
-
-
-@hook.command(autohelp=False)
-def showtells(nick, notice, db, conn):
-    """showtells -- View all pending tell messages (sent in a notice)."""
-
-    tells = get_unread(db, conn.server, nick)
-
-    if not tells:
-        notice("You have no pending messages.")
-        return
-
-    for tell in tells:
-        sender, message, time_sent = tell
-        past = timesince.timesince(time_sent)
-        notice("{} sent you a message {} ago: {}".format(sender, past, message))
-
-    read_all_tells(db, conn.server, nick)
-
-
-@hook.command("tell")
-def tell_cmd(inp, nick, db, notice, conn):
-    """tell <nick> <message> -- Relay <message> to <nick> when <nick> is around."""
-    query = inp.split(' ', 1)
-
-    if len(query) != 2:
-        notice(conn.config("command_prefix") + tell_cmd.__doc__)
-        return
-
-    target = query[0].lower()
-    message = query[1].strip()
-    sender = nick
-
-    if target == sender.lower():
-        notice("Have you looked in a mirror lately?")
-        return
-
-    if target.lower() == conn.nick.lower():
-        # we can't send messages to ourselves
-        notice("Invalid nick '{}'.".format(target))
-        return
-
-    if not re.match("^[A-Za-z0-9_|.\-\]\[]*$", target.lower()):
-        notice("Invalid nick '{}'.".format(target))
-        return
-
-    if count_unread(db, conn.server, target) >= 10:
-        notice("Sorry, {} has too many messages queued already.".format(target))
-        return
-
-    add_tell(db, conn.server, sender, target, message)
-
-    notice("Your message has been sent!")
diff --git a/modules/time_plugin.py b/modules/time_plugin.py
deleted file mode 100644
index 9247952..0000000
--- a/modules/time_plugin.py
+++ /dev/null
@@ -1,62 +0,0 @@
-import time
-
-from util import hook, http
-from util.formatting import capitalize_first
-
-
-api_url = 'http://api.wolframalpha.com/v2/query?format=plaintext'
-
-
-@hook.command("time")
-def time_command(inp, bot=None):
-    """time <area> -- Gets the time in <area>"""
-
-    query = "current time in {}".format(inp)
-
-    api_key = bot.config.get("api_keys", {}).get("wolframalpha", None)
-    if not api_key:
-        return "error: no wolfram alpha api key set"
-
-    request = http.get_xml(api_url, input=query, appid=api_key)
-    current_time = " ".join(request.xpath("//pod[@title='Result']/subpod/plaintext/text()"))
-    current_time = current_time.replace("  |  ", ", ")
-
-    if current_time:
-        # nice place name for UNIX time
-        if inp.lower() == "unix":
-            place = "Unix Epoch"
-        else:
-            place = capitalize_first(" ".join(request.xpath("//pod[@"
-                                                            "title='Input interpretation']/subpod/plaintext/text()"))[
-                                     16:])
-        return "{} - \x02{}\x02".format(current_time, place)
-    else:
-        return "Could not get the time for '{}'.".format(inp)
-
-
-@hook.command(autohelp=False)
-def beats(inp):
-    """beats -- Gets the current time in .beats (Swatch Internet Time). """
-
-    if inp.lower() == "wut":
-        return "Instead of hours and minutes, the mean solar day is divided " \
-               "up into 1000 parts called \".beats\". Each .beat lasts 1 minute and" \
-               " 26.4 seconds. Times are notated as a 3-digit number out of 1000 af" \
-               "ter midnight. So, @248 would indicate a time 248 .beats after midni" \
-               "ght representing 248/1000 of a day, just over 5 hours and 57 minute" \
-               "s. There are no timezones."
-    elif inp.lower() == "guide":
-        return "1 day = 1000 .beats, 1 hour = 41.666 .beats, 1 min = 0.6944 .beats, 1 second = 0.01157 .beats"
-
-    t = time.gmtime()
-    h, m, s = t.tm_hour, t.tm_min, t.tm_sec
-
-    utc = 3600 * h + 60 * m + s
-    bmt = utc + 3600  # Biel Mean Time (BMT)
-
-    beat = bmt / 86.4
-
-    if beat > 1000:
-        beat -= 1000
-
-    return "Swatch Internet Time: @%06.2f" % beat
diff --git a/modules/title.py b/modules/title.py
deleted file mode 100644
index a31dc42..0000000
--- a/modules/title.py
+++ /dev/null
@@ -1,23 +0,0 @@
-from bs4 import BeautifulSoup
-
-from util import hook, http, urlnorm
-
-
-@hook.command
-def title(inp):
-    """title <url> -- gets the title of a web page"""
-    url = urlnorm.normalize(inp, assume_scheme="http")
-
-    try:
-        page = http.open(url)
-        real_url = page.geturl()
-        soup = BeautifulSoup(page.read())
-    except (http.HTTPError, http.URLError):
-        return "Could not fetch page."
-
-    page_title = soup.find('title').contents[0]
-
-    if not page_title:
-        return "Could not find title."
-
-    return "{} [{}]".format(page_title, real_url)
diff --git a/modules/tvdb.py b/modules/tvdb.py
deleted file mode 100644
index 46b25db..0000000
--- a/modules/tvdb.py
+++ /dev/null
@@ -1,154 +0,0 @@
-import datetime
-
-from util import hook, http
-
-
-base_url = "http://thetvdb.com/api/"
-api_key = "469B73127CA0C411"
-
-
-def get_episodes_for_series(series_name, api_key):
-    res = {"error": None, "ended": False, "episodes": None, "name": None}
-    # http://thetvdb.com/wiki/index.php/API:GetSeries
-    try:
-        query = http.get_xml(base_url + 'GetSeries.php', seriesname=series_name)
-    except http.URLError:
-        res["error"] = "error contacting thetvdb.com"
-        return res
-
-    series_id = query.xpath('//seriesid/text()')
-
-    if not series_id:
-        res["error"] = "Unknown TV series. (using www.thetvdb.com)"
-        return res
-
-    series_id = series_id[0]
-
-    try:
-        series = http.get_xml(base_url + '%s/series/%s/all/en.xml' % (api_key, series_id))
-    except http.URLError:
-        res["error"] = "Error contacting thetvdb.com."
-        return res
-
-    series_name = series.xpath('//SeriesName/text()')[0]
-
-    if series.xpath('//Status/text()')[0] == 'Ended':
-        res["ended"] = True
-
-    res["episodes"] = series.xpath('//Episode')
-    res["name"] = series_name
-    return res
-
-
-def get_episode_info(episode, api_key):
-    first_aired = episode.findtext("FirstAired")
-
-    try:
-        air_date = datetime.date(*list(map(int, first_aired.split('-'))))
-    except (ValueError, TypeError):
-        return None
-
-    episode_num = "S%02dE%02d" % (int(episode.findtext("SeasonNumber")),
-                                  int(episode.findtext("EpisodeNumber")))
-
-    episode_name = episode.findtext("EpisodeName")
-    # in the event of an unannounced episode title, users either leave the
-    # field out (None) or fill it with TBA
-    if episode_name == "TBA":
-        episode_name = None
-
-    episode_desc = '{}'.format(episode_num)
-    if episode_name:
-        episode_desc += ' - {}'.format(episode_name)
-    return first_aired, air_date, episode_desc
-
-
-@hook.command
-@hook.command('tv')
-def tv_next(inp, bot=None):
-    """tv <series> -- Get the next episode of <series>."""
-
-    api_key = bot.config.get("api_keys", {}).get("tvdb", None)
-    if api_key is None:
-        return "error: no api key set"
-    episodes = get_episodes_for_series(inp, api_key)
-
-    if episodes["error"]:
-        return episodes["error"]
-
-    series_name = episodes["name"]
-    ended = episodes["ended"]
-    episodes = episodes["episodes"]
-
-    if ended:
-        return "{} has ended.".format(series_name)
-
-    next_eps = []
-    today = datetime.date.today()
-
-    for episode in reversed(episodes):
-        ep_info = get_episode_info(episode, api_key)
-
-        if ep_info is None:
-            continue
-
-        (first_aired, air_date, episode_desc) = ep_info
-
-        if air_date > today:
-            next_eps = ['{} ({})'.format(first_aired, episode_desc)]
-        elif air_date == today:
-            next_eps = ['Today ({})'.format(episode_desc)] + next_eps
-        else:
-            # we're iterating in reverse order with newest episodes last
-            # so, as soon as we're past today, break out of loop
-            break
-
-    if not next_eps:
-        return "There are no new episodes scheduled for {}.".format(series_name)
-
-    if len(next_eps) == 1:
-        return "The next episode of {} airs {}".format(series_name, next_eps[0])
-    else:
-        next_eps = ', '.join(next_eps)
-        return "The next episodes of {}: {}".format(series_name, next_eps)
-
-
-@hook.command
-@hook.command('tv_prev')
-def tv_last(inp, bot=None):
-    """tv_last <series> -- Gets the most recently aired episode of <series>."""
-
-    api_key = bot.config.get("api_keys", {}).get("tvdb", None)
-    if api_key is None:
-        return "error: no api key set"
-    episodes = get_episodes_for_series(inp, api_key)
-
-    if episodes["error"]:
-        return episodes["error"]
-
-    series_name = episodes["name"]
-    ended = episodes["ended"]
-    episodes = episodes["episodes"]
-
-    prev_ep = None
-    today = datetime.date.today()
-
-    for episode in reversed(episodes):
-        ep_info = get_episode_info(episode, api_key)
-
-        if ep_info is None:
-            continue
-
-        (first_aired, air_date, episode_desc) = ep_info
-
-        if air_date < today:
-            #iterating in reverse order, so the first episode encountered
-            #before today was the most recently aired
-            prev_ep = '{} ({})'.format(first_aired, episode_desc)
-            break
-
-    if not prev_ep:
-        return "There are no previously aired episodes for {}.".format(series_name)
-    if ended:
-        return '{} ended. The last episode aired {}.'.format(series_name, prev_ep)
-    return "The last episode of {} aired {}.".format(series_name, prev_ep)
diff --git a/modules/twitch.py b/modules/twitch.py
deleted file mode 100644
index 2405f64..0000000
--- a/modules/twitch.py
+++ /dev/null
@@ -1,115 +0,0 @@
-import re
-
-from html.parser import HTMLParser
-from util import hook, http
-
-
-twitch_re = (r'(.*:)//(twitch.tv|www.twitch.tv)(:[0-9]+)?(.*)', re.I)
-multitwitch_re = (r'(.*:)//(www.multitwitch.tv|multitwitch.tv)/(.*)', re.I)
-
-
-def test(s):
-    valid = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_/')
-    return set(s) <= valid
-
-
-def truncate(msg):
-    nmsg = msg.split(" ")
-    out = None
-    x = 0
-    for i in nmsg:
-        if x <= 7:
-            if out:
-                out = out + " " + nmsg[x]
-            else:
-                out = nmsg[x]
-        x += 1
-    if x <= 7:
-        return out
-    else:
-        return out + "..."
-
-
-@hook.regex(*multitwitch_re)
-def multitwitch_url(match):
-    usernames = match.group(3).split("/")
-    out = ""
-    for i in usernames:
-        if not test(i):
-            print("Not a valid username")
-            return None
-        if out == "":
-            out = twitch_lookup(i)
-        else:
-            out = out + " \x02|\x02 " + twitch_lookup(i)
-    return out
-
-
-@hook.regex(*twitch_re)
-def twitch_url(match):
-    bit = match.group(4).split("#")[0]
-    location = "/".join(bit.split("/")[1:])
-    if not test(location):
-        print("Not a valid username")
-        return None
-    return twitch_lookup(location)
-
-
-@hook.command('twitchviewers')
-@hook.command
-def twviewers(inp):
-    inp = inp.split("/")[-1]
-    if test(inp):
-        location = inp
-    else:
-        return "Not a valid channel name."
-    return twitch_lookup(location).split("(")[-1].split(")")[0].replace("Online now! ", "")
-
-
-def twitch_lookup(location):
-    locsplit = location.split("/")
-    if len(locsplit) > 1 and len(locsplit) == 3:
-        channel = locsplit[0]
-        type = locsplit[1]  # should be b or c
-        id = locsplit[2]
-    else:
-        channel = locsplit[0]
-        type = None
-        id = None
-    h = HTMLParser()
-    fmt = "{}: {} playing {} ({})"  # Title: nickname playing Game (x views)
-    if type and id:
-        if type == "b":  # I haven't found an API to retrieve broadcast info
-            soup = http.get_soup("http://twitch.tv/" + location)
-            title = soup.find('span', {'class': 'real_title js-title'}).text
-            playing = soup.find('a', {'class': 'game js-game'}).text
-            views = soup.find('span', {'id': 'views-count'}).text + " view"
-            views = views + "s" if not views[0:2] == "1 " else views
-            return h.unescape(fmt.format(title, channel, playing, views))
-        elif type == "c":
-            data = http.get_json("https://api.twitch.tv/kraken/videos/" + type + id)
-            title = data['title']
-            playing = data['game']
-            views = str(data['views']) + " view"
-            views = views + "s" if not views[0:2] == "1 " else views
-            return h.unescape(fmt.format(title, channel, playing, views))
-    else:
-        data = http.get_json("http://api.justin.tv/api/stream/list.json?channel=" + channel)
-        if data and len(data) >= 1:
-            data = data[0]
-            title = data['title']
-            playing = data['meta_game']
-            viewers = "\x033\x02Online now!\x02\x0f " + str(data["channel_count"]) + " viewer"
-            print(viewers)
-            viewers = viewers + "s" if not " 1 view" in viewers else viewers
-            print(viewers)
-            return h.unescape(fmt.format(title, channel, playing, viewers))
-        else:
-            try:
-                data = http.get_json("https://api.twitch.tv/kraken/channels/" + channel)
-            except:
-                return
-            title = data['status']
-            playing = data['game']
-            viewers = "\x034\x02Offline\x02\x0f"
-            return h.unescape(fmt.format(title, channel, playing, viewers))
diff --git a/modules/twitter.py b/modules/twitter.py
deleted file mode 100644
index 60a3c1e..0000000
--- a/modules/twitter.py
+++ /dev/null
@@ -1,178 +0,0 @@
-import re
-import random
-from datetime import datetime
-
-import tweepy
-
-from util import hook, timesince
-
-
-TWITTER_RE = (r"(?:(?:www.twitter.com|twitter.com)/(?:[-_a-zA-Z0-9]+)/status/)([0-9]+)", re.I)
-
-
-def get_api(bot):
-    consumer_key = bot.config.get("api_keys", {}).get("twitter_consumer_key")
-    consumer_secret = bot.config.get("api_keys", {}).get("twitter_consumer_secret")
-
-    oauth_token = bot.config.get("api_keys", {}).get("twitter_access_token")
-    oauth_secret = bot.config.get("api_keys", {}).get("twitter_access_secret")
-
-    if not consumer_key:
-        return False
-
-    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
-    auth.set_access_token(oauth_token, oauth_secret)
-
-    return tweepy.API(auth)
-
-
-@hook.regex(*TWITTER_RE)
-def twitter_url(match, bot=None):
-    # Find the tweet ID from the URL
-    tweet_id = match.group(1)
-
-    # Get the tweet using the tweepy API
-    api = get_api(bot)
-    if not api:
-        return
-    try:
-        tweet = api.get_status(tweet_id)
-        user = tweet.user
-    except tweepy.error.TweepError:
-        return
-
-    # Format the return the text of the tweet
-    text = " ".join(tweet.text.split())
-
-    if user.verified:
-        prefix = "\u2713"
-    else:
-        prefix = ""
-
-    time = timesince.timesince(tweet.created_at, datetime.utcnow())
-
-    return "{}@\x02{}\x02 ({}): {} ({} ago)".format(prefix, user.screen_name, user.name, text, time)
-
-
-@hook.command("tw")
-@hook.command("twatter")
-@hook.command
-def twitter(inp, bot=None):
-    """twitter <user> [n] -- Gets last/[n]th tweet from <user>"""
-
-    api = get_api(bot)
-    if not api:
-        return "Error: No Twitter API details."
-
-    if re.match(r'^\d+$', inp):
-        # user is getting a tweet by id
-
-        try:
-            # get tweet by id
-            tweet = api.get_status(inp)
-        except tweepy.error.TweepError as e:
-            if e[0][0]['code'] == 34:
-                return "Could not find tweet."
-            else:
-                return "Error {}: {}".format(e[0][0]['code'], e[0][0]['message'])
-
-        user = tweet.user
-
-    elif re.match(r'^\w{1,15}$', inp) or re.match(r'^\w{1,15}\s+\d+$', inp):
-        # user is getting a tweet by name
-
-        if inp.find(' ') == -1:
-            username = inp
-            tweet_number = 0
-        else:
-            username, tweet_number = inp.split()
-            tweet_number = int(tweet_number) - 1
-
-        if tweet_number > 300:
-            return "This command can only find the last \x02300\x02 tweets."
-
-        try:
-            # try to get user by username
-            user = api.get_user(username)
-        except tweepy.error.TweepError as e:
-            if e[0][0]['code'] == 34:
-                return "Could not find user."
-            else:
-                return "Error {}: {}".format(e[0][0]['code'], e[0][0]['message'])
-
-        # get the users tweets
-        user_timeline = api.user_timeline(id=user.id, count=tweet_number + 1)
-
-        # if the timeline is empty, return an error
-        if not user_timeline:
-            return "The user \x02{}\x02 has no tweets.".format(user.screen_name)
-
-        # grab the newest tweet from the users timeline
-        try:
-            tweet = user_timeline[tweet_number]
-        except IndexError:
-            tweet_count = len(user_timeline)
-            return "The user \x02{}\x02 only has \x02{}\x02 tweets.".format(user.screen_name, tweet_count)
-
-    elif re.match(r'^#\w+$', inp):
-        # user is searching by hashtag
-        search = api.search(inp)
-
-        if not search:
-            return "No tweets found."
-
-        tweet = random.choice(search)
-        user = tweet.user
-    else:
-        # ???
-        return "Invalid Input"
-
-    # Format the return the text of the tweet
-    text = " ".join(tweet.text.split())
-
-    if user.verified:
-        prefix = "\u2713"
-    else:
-        prefix = ""
-
-    time = timesince.timesince(tweet.created_at, datetime.utcnow())
-
-    return "{}@\x02{}\x02 ({}): {} ({} ago)".format(prefix, user.screen_name, user.name, text, time)
-
-
-@hook.command("twinfo")
-@hook.command
-def twuser(inp, bot=None):
-    """twuser <user> -- Get info on the Twitter user <user>"""
-
-    api = get_api(bot)
-    if not api:
-        return "Error: No Twitter API details."
-
-    try:
-        # try to get user by username
-        user = api.get_user(inp)
-    except tweepy.error.TweepError as e:
-        if e[0][0]['code'] == 34:
-            return "Could not find user."
-        else:
-            return "Unknown error"
-
-    if user.verified:
-        prefix = "\u2713"
-    else:
-        prefix = ""
-
-    if user.location:
-        loc_str = " is located in \x02{}\x02 and".format(user.location)
-    else:
-        loc_str = ""
-
-    if user.description:
-        desc_str = " The users description is \"{}\"".format(user.description)
-    else:
-        desc_str = ""
-
-    return "{}@\x02{}\x02 ({}){} has \x02{:,}\x02 tweets and \x02{:,}\x02 followers.{}" \
-           "".format(prefix, user.screen_name, user.name, loc_str, user.statuses_count, user.followers_count,
-                     desc_str)
diff --git a/modules/update.py b/modules/update.py
deleted file mode 100644
index c867505..0000000
--- a/modules/update.py
+++ /dev/null
@@ -1,43 +0,0 @@
-from git import Repo
-
-from util import hook, web
-
-
-@hook.command
-def update():
-    repo = Repo()
-    git = repo.git
-    try:
-        pull = git.pull()
-    except Exception as e:
-        return e
-    if "\n" in pull:
-        return web.haste(pull)
-    else:
-        return pull
-
-
-@hook.command
-def version():
-    repo = Repo()
-
-    # get origin and fetch it
-    origin = repo.remotes.origin
-    info = origin.fetch()
-
-    # get objects
-    head = repo.head
-    origin_head = info[0]
-    current_commit = head.commit
-    remote_commit = origin_head.commit
-
-    if current_commit == remote_commit:
-        in_sync = True
-    else:
-        in_sync = False
-
-    # output
-    return "Local \x02{}\x02 is at commit \x02{}\x02, remote \x02{}\x02 is at commit \x02{}\x02." \
-           " You {} running the latest version.".format(head, current_commit.name_rev[:7],
-                                                        origin_head, remote_commit.name_rev[:7],
-                                                        "are" if in_sync else "are not")
diff --git a/modules/urban.py b/modules/urban.py
deleted file mode 100644
index 1d3691c..0000000
--- a/modules/urban.py
+++ /dev/null
@@ -1,64 +0,0 @@
-import random
-
-from util import hook, http, formatting
-
-base_url = 'http://api.urbandictionary.com/v0'
-define_url = base_url + "/define"
-random_url = base_url + "/random"
-
-
-@hook.command(["urban", "u"], autohelp=False)
-def urban(text):
-    """urban <phrase> [id] -- Looks up <phrase> on urbandictionary.com."""
-
-    if text:
-        # clean and split the input
-        text = text.lower().strip()
-        parts = text.split()
-
-        # if the last word is a number, set the ID to that number
-        if parts[-1].isdigit():
-            id_num = int(parts[-1])
-            # remove the ID from the input string
-            del parts[-1]
-            text = " ".join(parts)
-        else:
-            id_num = 1
-
-        # fetch the definitions
-        page = http.get_json(define_url, term=text, referer="http://m.urbandictionary.com")
-
-        if page['result_type'] == 'no_results':
-            return 'Not found.'
-    else:
-        # get a random definition!
-        page = http.get_json(random_url, referer="http://m.urbandictionary.com")
-        id_num = None
-
-    definitions = page['list']
-
-    if id_num:
-        # try getting the requested definition
-        try:
-            definition = definitions[id_num - 1]
-
-            def_text = " ".join(definition['definition'].split())  # remove excess spaces
-            def_text = formatting.truncate_str(def_text, 200)
-        except IndexError:
-            return 'Not found.'
-
-        url = definition['permalink']
-
-        output = "[{}/{}] {} :: {}".format(id_num, len(definitions), def_text, url)
-
-    else:
-        definition = random.choice(definitions)
-
-        def_text = " ".join(definition['definition'].split())  # remove excess spaces
-        def_text = formatting.truncate_str(def_text, 200)
-
-        name = definition['word']
-        url = definition['permalink']
-        output = "\x02{}\x02: {} :: {}".format(name, def_text, url)
-
-    return output
diff --git a/modules/utility.py b/modules/utility.py
deleted file mode 100644
index 878d76b..0000000
--- a/modules/utility.py
+++ /dev/null
@@ -1,194 +0,0 @@
-import base64
-import codecs
-import hashlib
-import collections
-import re
-import binascii
-
-from util import hook, formatting
-
-colors = collections.OrderedDict([
-    ('red', '\x0304'),
-    ('orange', '\x0307'),
-    ('yellow', '\x0308'),
-    ('green', '\x0309'),
-    ('cyan', '\x0303'),
-    ('ltblue', '\x0310'),
-    ('rylblue', '\x0312'),
-    ('blue', '\x0302'),
-    ('magenta', '\x0306'),
-    ('pink', '\x0313'),
-    ('maroon', '\x0305')
-])
-
-# helper functions
-
-strip_re = re.compile("(\x03|\x02|\x1f|\x0f)(?:,?\d{1,2}(?:,\d{1,2})?)?")
-
-
-def strip(string):
-    return strip_re.sub('', string)
-
-
-# basic text tools
-
-
-## TODO: make this capitalize sentences correctly
-@hook.command("capitalise")
-@hook.command
-def capitalize(text):
-    """capitalize <string> -- Capitalizes <string>.
-    :type text: str
-    """
-    return ". ".join([sentence.capitalize() for sentence in text.split(". ")])
-
-
-@hook.command
-def upper(inp):
-    """upper <string> -- Convert string to uppercase."""
-    return inp.upper()
-
-
-@hook.command
-def lower(inp):
-    """lower <string> -- Convert string to lowercase."""
-    return inp.lower()
-
-
-@hook.command
-def titlecase(inp):
-    """title <string> -- Convert string to title case."""
-    return inp.title()
-
-
-@hook.command
-def swapcase(inp):
-    """swapcase <string> -- Swaps the capitalization of <string>."""
-    return inp.swapcase()
-
-
-# encoding
-
-
-@hook.command("rot13")
-def rot13_encode(text):
-    """rot13 <string> -- Encode <string> with rot13."""
-    encoder = codecs.getencoder("rot-13")
-    return encoder(text)[0]
-
-
-@hook.command("base64")
-def base64_encode(text):
-    """base64 <string> -- Encode <string> with base64."""
-    return base64.b64encode(text.encode()).decode()
-
-
-@hook.command(["debase64", "unbase64"])
-def base64_decode(text, notice):
-    """unbase64 <string> -- Decode <string> with base64."""
-    try:
-        return base64.b64decode(text.encode()).decode()
-    except binascii.Error:
-        notice("Invalid base64 string '{}'".format(text))
-
-
-@hook.command(["isbase64", "checkbase64"])
-def base64_check(text):
-    """isbase64 <string> -- Checks if <string> is a valid base64 encoded string"""
-    try:
-        base64.b64decode(text.encode())
-    except binascii.Error:
-        return "'{}' is not a valid base64 encoded string".format(text)
-    else:
-        return "'{}' is a valid base64 encoded string".format(text)
-
-
-@hook.command
-def unescape(text):
-    """unescape <string> -- Unicode unescapes <string>."""
-    decoder = codecs.getdecoder("unicode_escape")
-    return decoder(text)[0]
-
-
-@hook.command
-def escape(text):
-    """escape <string> -- Unicode escapes <string>."""
-    encoder = codecs.getencoder("unicode_escape")
-    return encoder(text)[0].decode()
-
-# length
-
-
-@hook.command
-def length(text):
-    """length <string> -- Gets the length of <string>"""
-    return "The length of that string is {} characters.".format(len(text))
-
-
-# reverse
-
-
-@hook.command
-def reverse(text):
-    """reverse <string> -- Reverses <string>."""
-    return text[::-1]
-
-
-# hashing
-
-
-@hook.command("hash")
-def hash_command(text):
-    """hash <string> -- Returns hashes of <string>."""
-    return ', '.join(x + ": " + getattr(hashlib, x)(text.encode("utf-8")).hexdigest()
-                     for x in ['md5', 'sha1', 'sha256'])
-
-
-# novelty
-
-
-@hook.command
-def munge(text):
-    """munge <text> -- Munges up <text>."""
-    return formatting.munge(text)
-
-
-# colors - based on code by Reece Selwood - <https://github.com/hitzler/homero>
-
-
-@hook.command
-def rainbow(text):
-    text = str(text)
-    text = strip(text)
-    col = list(colors.items())
-    out = ""
-    l = len(colors)
-    for i, t in enumerate(text):
-        if t == " ":
-            out += t
-        else:
-            out += col[i % l][1] + t
-    return out
-
-
-@hook.command
-def wrainbow(text):
-    text = str(text)
-    col = list(colors.items())
-    text = strip(text).split(' ')
-    out = []
-    l = len(colors)
-    for i, t in enumerate(text):
-        out.append(col[i % l][1] + t)
-    return ' '.join(out)
-
-
-@hook.command
-def usa(text):
-    text = strip(text)
-    c = [colors['red'], '\x0300', colors['blue']]
-    l = len(c)
-    out = ''
-    for i, t in enumerate(text):
-        out += c[i % l] + t
-    return out
diff --git a/modules/validate.py b/modules/validate.py
deleted file mode 100644
index 88022b7..0000000
--- a/modules/validate.py
+++ /dev/null
@@ -1,26 +0,0 @@
-"""
-Runs a given url through the w3c validator
-
-by Vladi
-"""
-
-from util import hook, http
-
-
-@hook.command('w3c')
-@hook.command
-def validate(inp):
-    """validate <url> -- Runs url through the w3c markup validator."""
-
-    if not inp.startswith('http://'):
-        inp = 'http://' + inp
-
-    url = 'http://validator.w3.org/check?uri=' + http.quote_plus(inp)
-    info = dict(http.open(url).info())
-
-    status = info['x-w3c-validator-status'].lower()
-    if status in ("valid", "invalid"):
-        error_count = info['x-w3c-validator-errors']
-        warning_count = info['x-w3c-validator-warnings']
-        return "{} was found to be {} with {} errors and {} warnings." \
-               " see: {}".format(inp, status, error_count, warning_count, url)
diff --git a/modules/valvesounds.py b/modules/valvesounds.py
deleted file mode 100644
index 1f5facc..0000000
--- a/modules/valvesounds.py
+++ /dev/null
@@ -1,92 +0,0 @@
-import json
-import urllib
-
-from util import hook, http, web
-
-
-def get_sound_info(game, search):
-    search = search.replace(" ", "+")
-    try:
-        data = http.get_json("http://p2sounds.blha303.com.au/search/%s/%s?format=json" % (game, search))
-    except urllib.error.HTTPError as e:
-        return "Error: " + json.loads(e.read())["error"]
-    items = []
-    for item in data["items"]:
-        if "music" in game:
-            textsplit = item["text"].split('"')
-            text = ""
-            for i in range(len(textsplit)):
-                if i % 2 != 0 and i < 6:
-                    if text:
-                        text += " / " + textsplit[i]
-                    else:
-                        text = textsplit[i]
-        else:
-            text = item["text"]
-        items.append("{} - {} {}".format(item["who"],
-                                         text if len(text) < 325 else text[:325] + "...",
-                                         item["listen"]))
-    if len(items) == 1:
-        return items[0]
-    else:
-        return "{} (and {} others: {})".format(items[0], len(items) - 1, web.haste("\n".join(items)))
-
-
-@hook.command
-def portal2(inp):
-    """portal2 <quote> - Look up Portal 2 quote.
-    Example: .portal2 demand to see life's manager"""
-    return get_sound_info("portal2", inp)
-
-
-@hook.command
-def portal2dlc(inp):
-    """portal2dlc <quote> - Look up Portal 2 DLC quote.
-    Example: .portal2dlc1 these exhibits are interactive"""
-    return get_sound_info("portal2dlc1", inp)
-
-
-@hook.command("portal2pti")
-@hook.command
-def portal2dlc2(inp):
-    """portal2dlc2 <quote> - Look up Portal 2 Perpetual Testing Inititive quote.
-    Example: .portal2 Cave here."""
-    return get_sound_info("portal2dlc2", inp)
-
-
-@hook.command
-def portal2music(inp):
-    """portal2music <title> - Look up Portal 2 music.
-    Example: .portal2music turret opera"""
-    return get_sound_info("portal2music", inp)
-
-
-@hook.command('portal1')
-@hook.command
-def portal(inp):
-    """portal <quote> - Look up Portal quote.
-    Example: .portal The last thing you want to do is hurt me"""
-    return get_sound_info("portal1", inp)
-
-
-@hook.command('portal1music')
-@hook.command
-def portalmusic(inp):
-    """portalmusic <title> - Look up Portal music.
-    Example: .portalmusic still alive"""
-    return get_sound_info("portal1music", inp)
-
-
-@hook.command('tf2sound')
-@hook.command
-def tf2(inp):
-    """tf2 [who - ]<quote> - Look up TF2 quote.
-    Example: .tf2 may i borrow your earpiece"""
-    return get_sound_info("tf2", inp)
-
-
-@hook.command
-def tf2music(inp):
-    """tf2music title - Look up TF2 music lyrics.
-    Example: .tf2music rocket jump waltz"""
-    return get_sound_info("tf2music", inp)
diff --git a/modules/vimeo.py b/modules/vimeo.py
deleted file mode 100644
index 0a55549..0000000
--- a/modules/vimeo.py
+++ /dev/null
@@ -1,20 +0,0 @@
-from util import hook, http, timeformat
-
-
-@hook.regex(r'vimeo.com/([0-9]+)')
-def vimeo_url(match):
-    """vimeo <url> -- returns information on the Vimeo video at <url>"""
-    info = http.get_json('http://vimeo.com/api/v2/video/%s.json'
-                         % match.group(1))
-
-    if info:
-        info[0]["duration"] = timeformat.format_time(info[0]["duration"])
-        info[0]["stats_number_of_likes"] = format(
-            info[0]["stats_number_of_likes"], ",d")
-        info[0]["stats_number_of_plays"] = format(
-            info[0]["stats_number_of_plays"], ",d")
-        return ("\x02%(title)s\x02 - length \x02%(duration)s\x02 - "
-                "\x02%(stats_number_of_likes)s\x02 likes - "
-                "\x02%(stats_number_of_plays)s\x02 plays - "
-                "\x02%(user_name)s\x02 on \x02%(upload_date)s\x02"
-                % info[0])
diff --git a/modules/weather.py b/modules/weather.py
deleted file mode 100644
index b56e2b4..0000000
--- a/modules/weather.py
+++ /dev/null
@@ -1,100 +0,0 @@
-from util import hook, http, web
-
-base_url = "http://api.wunderground.com/api/{}/{}/q/{}.json"
-
-
-@hook.command(autohelp=None)
-def weather(inp, reply=None, db=None, nick=None, bot=None, notice=None):
-    """weather <location> [dontsave] -- Gets weather data
-    for <location> from Wunderground."""
-
-    api_key = bot.config.get("api_keys", {}).get("wunderground")
-
-    if not api_key:
-        return "Error: No wunderground API details."
-
-    # initialise weather DB
-    db.execute("create table if not exists weather(nick primary key, loc)")
-
-    # if there is no input, try getting the users last location from the DB
-    if not inp:
-        location = db.execute("select loc from weather where nick=lower(:nick)",
-                              {"nick": nick}).fetchone()
-        print(location)
-        if not location:
-            # no location saved in the database, send the user help text
-            notice(weather.__doc__)
-            return
-        loc = location[0]
-
-        # no need to save a location, we already have it
-        dontsave = True
-    else:
-        # see if the input ends with "dontsave"
-        dontsave = inp.endswith(" dontsave")
-
-        # remove "dontsave" from the input string after checking for it
-        if dontsave:
-            loc = inp[:-9].strip().lower()
-        else:
-            loc = inp
-
-    location = http.quote_plus(loc)
-
-    request_url = base_url.format(api_key, "geolookup/forecast/conditions", location)
-    response = http.get_json(request_url)
-
-    if 'location' not in response:
-        try:
-            location_id = response['response']['results'][0]['zmw']
-        except KeyError:
-            return "Could not get weather for that location."
-
-        # get the weather again, using the closest match
-        request_url = base_url.format(api_key, "geolookup/forecast/conditions", "zmw:" + location_id)
-        response = http.get_json(request_url)
-
-    if response['location']['state']:
-        place_name = "\x02{}\x02, \x02{}\x02 (\x02{}\x02)".format(response['location']['city'],
-                                                                  response['location']['state'],
-                                                                  response['location']['country'])
-    else:
-        place_name = "\x02{}\x02 (\x02{}\x02)".format(response['location']['city'],
-                                                      response['location']['country'])
-
-    forecast_today = response["forecast"]["simpleforecast"]["forecastday"][0]
-    forecast_tomorrow = response["forecast"]["simpleforecast"]["forecastday"][1]
-
-    # put all the stuff we want to use in a dictionary for easy formatting of the output
-    weather_data = {
-        "place": place_name,
-        "conditions": response['current_observation']['weather'],
-        "temp_f": response['current_observation']['temp_f'],
-        "temp_c": response['current_observation']['temp_c'],
-        "humidity": response['current_observation']['relative_humidity'],
-        "wind_kph": response['current_observation']['wind_kph'],
-        "wind_mph": response['current_observation']['wind_mph'],
-        "wind_direction": response['current_observation']['wind_dir'],
-        "today_conditions": forecast_today['conditions'],
-        "today_high_f": forecast_today['high']['fahrenheit'],
-        "today_high_c": forecast_today['high']['celsius'],
-        "today_low_f": forecast_today['low']['fahrenheit'],
-        "today_low_c": forecast_today['low']['celsius'],
-        "tomorrow_conditions": forecast_tomorrow['conditions'],
-        "tomorrow_high_f": forecast_tomorrow['high']['fahrenheit'],
-        "tomorrow_high_c": forecast_tomorrow['high']['celsius'],
-        "tomorrow_low_f": forecast_tomorrow['low']['fahrenheit'],
-        "tomorrow_low_c": forecast_tomorrow['low']['celsius'],
-        "url": web.isgd(response["current_observation"]['forecast_url'] + "?apiref=e535207ff4757b18")
-    }
-
-    reply("{place} - \x02Current:\x02 {conditions}, {temp_f}F/{temp_c}C, {humidity}, "
-          "Wind: {wind_kph}KPH/{wind_mph}MPH {wind_direction}, \x02Today:\x02 {today_conditions}, "
-          "High: {today_high_f}F/{today_high_c}C, Low: {today_low_f}F/{today_low_c}C. "
-          "\x02Tomorrow:\x02 {tomorrow_conditions}, High: {tomorrow_high_f}F/{tomorrow_high_c}C, "
-          "Low: {tomorrow_low_f}F/{tomorrow_low_c}C - {url}".format(**weather_data))
-
-    if location and not dontsave:
-        db.execute("insert or replace into weather(nick, loc) values (:nick, :loc)",
-                   {"nick": nick.lower(), "loc": loc})
-        db.commit()
diff --git a/modules/wikipedia.py b/modules/wikipedia.py
deleted file mode 100644
index e28dd27..0000000
--- a/modules/wikipedia.py
+++ /dev/null
@@ -1,49 +0,0 @@
-"""Searches wikipedia and returns first sentence of article
-Scaevolus 2009"""
-
-import re
-
-from util import hook, http, formatting
-
-
-api_prefix = "http://en.wikipedia.org/w/api.php"
-search_url = api_prefix + "?action=opensearch&format=xml"
-
-paren_re = re.compile('\s*\(.*\)$')
-
-
-@hook.command('w')
-@hook.command
-def wiki(inp):
-    """wiki <phrase> -- Gets first sentence of Wikipedia article on <phrase>."""
-
-    x = http.get_xml(search_url, search=inp)
-
-    ns = '{http://opensearch.org/searchsuggest2}'
-    items = x.findall(ns + 'Section/' + ns + 'Item')
-
-    if not items:
-        if x.find('error') is not None:
-            return 'error: %(code)s: %(info)s' % x.find('error').attrib
-        else:
-            return 'No results found.'
-
-    def extract(item):
-        return [item.find(ns + x).text for x in
-                ('Text', 'Description', 'Url')]
-
-    title, desc, url = extract(items[0])
-
-    if 'may refer to' in desc:
-        title, desc, url = extract(items[1])
-
-    title = paren_re.sub('', title)
-
-    if title.lower() not in desc.lower():
-        desc = title + desc
-
-    desc = ' '.join(desc.split())  # remove excess spaces
-
-    desc = formatting.truncate_str(desc, 200)
-
-    return '{} :: {}'.format(desc, http.quote(url, ':/'))
diff --git a/modules/wolframalpha.py b/modules/wolframalpha.py
deleted file mode 100644
index a439897..0000000
--- a/modules/wolframalpha.py
+++ /dev/null
@@ -1,55 +0,0 @@
-import re
-
-from util import hook, http, formatting, web
-
-
-@hook.command(["wa", "calc", "math", "wolframalpha"])
-def wolframalpha(text, bot):
-    """wa <query> -- Computes <query> using Wolfram Alpha."""
-    api_key = bot.config.get("api_keys", {}).get("wolframalpha", None)
-
-    if not api_key:
-        return "error: missing api key"
-
-    url = 'http://api.wolframalpha.com/v2/query?format=plaintext'
-
-    result = http.get_xml(url, input=text, appid=api_key)
-
-    # get the URL for a user to view this query in a browser
-    query_url = "http://www.wolframalpha.com/input/?i=" + \
-                http.quote_plus(text.encode('utf-8'))
-    short_url = web.try_isgd(query_url)
-
-    pod_texts = []
-    for pod in result.xpath("//pod[@primary='true']"):
-        title = pod.attrib['title']
-        if pod.attrib['id'] == 'Input':
-            continue
-
-        results = []
-        for subpod in pod.xpath('subpod/plaintext/text()'):
-            subpod = subpod.strip().replace('\\n', '; ')
-            subpod = re.sub(r'\s+', ' ', subpod)
-            if subpod:
-                results.append(subpod)
-        if results:
-            pod_texts.append(title + ': ' + ', '.join(results))
-
-    ret = ' - '.join(pod_texts)
-
-    if not pod_texts:
-        return 'No results.'
-
-    ret = re.sub(r'\\(.)', r'\1', ret)
-
-    def unicode_sub(match):
-        return chr(int(match.group(1), 16))
-
-    ret = re.sub(r'\\:([0-9a-z]{4})', unicode_sub, ret)
-
-    ret = formatting.truncate_str(ret, 250)
-
-    if not ret:
-        return 'No results.'
-
-    return "{} - {}".format(ret, short_url)
diff --git a/modules/xkcd.py b/modules/xkcd.py
deleted file mode 100644
index 6ec286c..0000000
--- a/modules/xkcd.py
+++ /dev/null
@@ -1,43 +0,0 @@
-import re
-
-from util import hook, http
-
-
-xkcd_re = (r'(.*:)//(www.xkcd.com|xkcd.com)(.*)', re.I)
-months = {1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August',
-          9: 'September', 10: 'October', 11: 'November', 12: 'December'}
-
-
-def xkcd_info(xkcd_id, url=False):
-    """ takes an XKCD entry ID and returns a formatted string """
-    data = http.get_json("http://www.xkcd.com/" + xkcd_id + "/info.0.json")
-    date = "{} {} {}".format(data['day'], months[int(data['month'])], data['year'])
-    if url:
-        url = " | http://xkcd.com/" + xkcd_id.replace("/", "")
-    return "xkcd: \x02{}\x02 ({}){}".format(data['title'], date, url if url else "")
-
-
-def xkcd_search(term):
-    search_term = http.quote_plus(term)
-    soup = http.get_soup("http://www.ohnorobot.com/index.pl?s={}&Search=Search&"
-                         "comic=56&e=0&n=0&b=0&m=0&d=0&t=0".format(search_term))
-    result = soup.find('li')
-    if result:
-        url = result.find('div', {'class': 'tinylink'}).text
-        xkcd_id = url[:-1].split("/")[-1]
-        print(xkcd_id)
-        return xkcd_info(xkcd_id, url=True)
-    else:
-        return "No results found!"
-
-
-@hook.regex(*xkcd_re)
-def xkcd_url(match):
-    xkcd_id = match.group(3).split(" ")[0].split("/")[1]
-    return xkcd_info(xkcd_id)
-
-
-@hook.command
-def xkcd(inp):
-    """xkcd <search term> - Search for xkcd comic matching <search term>"""
-    return xkcd_search(inp)
diff --git a/modules/yahooanswers.py b/modules/yahooanswers.py
deleted file mode 100644
index 55b07c6..0000000
--- a/modules/yahooanswers.py
+++ /dev/null
@@ -1,16 +0,0 @@
-from util import hook, web, formatting
-
-
-@hook.command
-def answer(text):
-    """answer <query> -- find the answer to a question on Yahoo! Answers"""
-
-    query = "SELECT Subject, ChosenAnswer, Link FROM answers.search WHERE query=@query LIMIT 1"
-    result = web.query(query, {"query": text.strip()}).one()
-
-    short_url = web.try_isgd(result["Link"])
-
-    # we split the answer and .join() it to remove newlines/extra spaces
-    answer_text = formatting.truncate_str(' '.join(result["ChosenAnswer"].split()), 80)
-
-    return '\x02{}\x02 "{}" - {}'.format(result["Subject"], answer_text, short_url)
diff --git a/modules/youtube.py b/modules/youtube.py
deleted file mode 100644
index 6fbdaa9..0000000
--- a/modules/youtube.py
+++ /dev/null
@@ -1,137 +0,0 @@
-import re
-import time
-
-from util import hook, http, timeformat
-
-
-youtube_re = (r'(?:youtube.*?(?:v=|/v/)|youtu\.be/|yooouuutuuube.*?id=)'
-              '([-_a-zA-Z0-9]+)', re.I)
-
-base_url = 'http://gdata.youtube.com/feeds/api/'
-api_url = base_url + 'videos/{}?v=2&alt=jsonc'
-search_api_url = base_url + 'videos?v=2&alt=jsonc&max-results=1'
-video_url = "http://youtu.be/%s"
-
-
-def plural(num=0, text=''):
-    return "{:,} {}{}".format(num, text, "s"[num == 1:])
-
-
-def get_video_description(video_id):
-    request = http.get_json(api_url.format(video_id))
-
-    if request.get('error'):
-        return
-
-    data = request['data']
-
-    out = '\x02{}\x02'.format(data['title'])
-
-    if not data.get('duration'):
-        return out
-
-    length = data['duration']
-    out += ' - length \x02{}\x02'.format(timeformat.format_time(length, simple=True))
-
-    if 'ratingCount' in data:
-        # format
-        likes = plural(int(data['likeCount']), "like")
-        dislikes = plural(data['ratingCount'] - int(data['likeCount']), "dislike")
-
-        percent = 100 * float(data['likeCount']) / float(data['ratingCount'])
-        out += ' - {}, {} (\x02{:.1f}\x02%)'.format(likes,
-                                                    dislikes, percent)
-
-    if 'viewCount' in data:
-        views = data['viewCount']
-        out += ' - \x02{:,}\x02 view{}'.format(views, "s"[views == 1:])
-
-    try:
-        uploader = http.get_json(base_url + "users/{}?alt=json".format(data["uploader"]))["entry"]["author"][0]["name"][
-            "$t"]
-    except:
-        uploader = data["uploader"]
-
-    upload_time = time.strptime(data['uploaded'], "%Y-%m-%dT%H:%M:%S.000Z")
-    out += ' - \x02{}\x02 on \x02{}\x02'.format(uploader,
-                                                time.strftime("%Y.%m.%d", upload_time))
-
-    if 'contentRating' in data:
-        out += ' - \x034NSFW\x02'
-
-    return out
-
-
-@hook.regex(*youtube_re)
-def youtube_url(match):
-    return get_video_description(match.group(1))
-
-
-@hook.command('you')
-@hook.command('yt')
-@hook.command('y')
-@hook.command
-def youtube(inp):
-    """youtube <query> -- Returns the first YouTube search result for <query>."""
-    request = http.get_json(search_api_url, q=inp)
-
-    if 'error' in request:
-        return 'error performing search'
-
-    if request['data']['totalItems'] == 0:
-        return 'no results found'
-
-    video_id = request['data']['items'][0]['id']
-
-    return get_video_description(video_id) + " - " + video_url % video_id
-
-
-@hook.command('ytime')
-@hook.command
-def youtime(inp):
-    """youtime <query> -- Gets the total run time of the first YouTube search result for <query>."""
-    request = http.get_json(search_api_url, q=inp)
-
-    if 'error' in request:
-        return 'error performing search'
-
-    if request['data']['totalItems'] == 0:
-        return 'no results found'
-
-    video_id = request['data']['items'][0]['id']
-    request = http.get_json(api_url.format(video_id))
-
-    if request.get('error'):
-        return
-    data = request['data']
-
-    if not data.get('duration'):
-        return
-
-    length = data['duration']
-    views = data['viewCount']
-    total = int(length * views)
-
-    length_text = timeformat.format_time(length, simple=True)
-    total_text = timeformat.format_time(total, accuracy=8)
-
-    return 'The video \x02{}\x02 has a length of {} and has been viewed {:,} times for ' \
-           'a total run time of {}!'.format(data['title'], length_text, views,
-                                            total_text)
-
-
-ytpl_re = (r'(.*:)//(www.youtube.com/playlist|youtube.com/playlist)(:[0-9]+)?(.*)', re.I)
-
-
-@hook.regex(*ytpl_re)
-def ytplaylist_url(match):
-    location = match.group(4).split("=")[-1]
-    try:
-        soup = http.get_soup("https://www.youtube.com/playlist?list=" + location)
-    except Exception:
-        return "\x034\x02Invalid response."
-    title = soup.find('title').text.split('-')[0].strip()
-    author = soup.find('img', {'class': 'channel-header-profile-image'})['title']
-    num_videos = soup.find('ul', {'class': 'header-stats'}).findAll('li')[0].text.split(' ')[0]
-    views = soup.find('ul', {'class': 'header-stats'}).findAll('li')[1].text.split(' ')[0]
-    return "\x02{}\x02 - \x02{}\x02 views - \x02{}\x02 videos - \x02{}\x02".format(title, views, num_videos, author)
-- 
1.9.3

